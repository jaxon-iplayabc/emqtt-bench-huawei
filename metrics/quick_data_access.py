# coding: utf-8
"""
å¿«é€Ÿæ•°æ®è®¿é—®è„šæœ¬
æä¾›ç®€å•çš„å‘½ä»¤è¡Œæ¥å£æ¥è®¿é—®æµ‹è¯•æ•°æ®
ä½œè€…: Jaxon
æ—¥æœŸ: 2024-12-19
"""
import sys
import json
from pathlib import Path
from typing import List, Dict, Any

from test_data_manager import TestDataManager

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("""
ğŸ“Š å¿«é€Ÿæ•°æ®è®¿é—®å·¥å…·

ç”¨æ³•:
  python quick_data_access.py <å‘½ä»¤> [å‚æ•°]

å‘½ä»¤:
  list                    - åˆ—å‡ºæ‰€æœ‰æµ‹è¯•è®°å½•
  show <test_id>          - æ˜¾ç¤ºç‰¹å®šæµ‹è¯•è¯¦æƒ…
  export <format>         - å¯¼å‡ºæ•°æ® (json/csv/excel)
  stats                   - æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
  cleanup <days>          - æ¸…ç†æ—§æ•°æ®
  help                    - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  python quick_data_access.py list
  python quick_data_access.py show 1
  python quick_data_access.py export json
  python quick_data_access.py stats
  python quick_data_access.py cleanup 30
""")

def list_tests():
    """åˆ—å‡ºæ‰€æœ‰æµ‹è¯•"""
    data_manager = TestDataManager()
    all_tests = data_manager.get_all_tests()
    
    if not all_tests:
        print("âš ï¸ æš‚æ— æµ‹è¯•æ•°æ®")
        return
    
    print(f"\nğŸ“‹ æµ‹è¯•è®°å½• (å…± {len(all_tests)} æ¡)")
    print("-" * 80)
    print(f"{'ID':<4} {'æµ‹è¯•åç§°':<20} {'ç±»å‹':<15} {'å¼€å§‹æ—¶é—´':<20} {'æŒç»­æ—¶é—´':<10} {'çŠ¶æ€':<8}")
    print("-" * 80)
    
    for test in all_tests:
        status = "âœ…" if test['success'] else "âŒ"
        start_time = test['start_time'][:19] if len(test['start_time']) > 19 else test['start_time']
        print(f"{test['id']:<4} {test['test_name']:<20} {test['test_type']:<15} {start_time:<20} {test['duration']:<10.1f} {status:<8}")

def show_test(test_id: int):
    """æ˜¾ç¤ºæµ‹è¯•è¯¦æƒ…"""
    data_manager = TestDataManager()
    test_data = data_manager.load_test_data(test_id)
    
    if not test_data:
        print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•ID {test_id}")
        return
    
    print(f"\nğŸ“Š æµ‹è¯•è¯¦æƒ… - {test_data.test_name}")
    print("=" * 60)
    print(f"æµ‹è¯•åç§°: {test_data.test_name}")
    print(f"æµ‹è¯•ç±»å‹: {test_data.test_type}")
    print(f"å¼€å§‹æ—¶é—´: {test_data.start_time}")
    print(f"ç»“æŸæ—¶é—´: {test_data.end_time}")
    print(f"æŒç»­æ—¶é—´: {test_data.duration:.1f} ç§’")
    print(f"ç«¯å£: {test_data.port}")
    print(f"æˆåŠŸçŠ¶æ€: {'âœ… æˆåŠŸ' if test_data.success else 'âŒ å¤±è´¥'}")
    
    if test_data.error_message:
        print(f"é”™è¯¯ä¿¡æ¯: {test_data.error_message}")
    
    if test_data.performance_summary:
        print(f"\nğŸ“ˆ æ€§èƒ½æ‘˜è¦:")
        for metric_name, stats in test_data.performance_summary.items():
            print(f"  {metric_name}: æ•°é‡={stats['count']}, æœ€å°å€¼={stats['min']:.2f}, æœ€å¤§å€¼={stats['max']:.2f}, å¹³å‡å€¼={stats['avg']:.2f}")
    
    print(f"\nğŸ“Š åŸå§‹æŒ‡æ ‡æ•°æ®: {len(test_data.raw_metrics)} æ¡")

def export_data(format_type: str):
    """å¯¼å‡ºæ•°æ®"""
    data_manager = TestDataManager()
    all_tests = data_manager.get_all_tests()
    
    if not all_tests:
        print("âš ï¸ æš‚æ— æµ‹è¯•æ•°æ®å¯å¯¼å‡º")
        return
    
    # è·å–æ‰€æœ‰æµ‹è¯•ID
    test_ids = [test['id'] for test in all_tests]
    
    try:
        export_file = data_manager.export_test_data(test_ids, format_type)
        print(f"âœ… æ•°æ®å·²å¯¼å‡ºåˆ°: {export_file}")
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

def show_stats():
    """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
    data_manager = TestDataManager()
    all_tests = data_manager.get_all_tests()
    
    if not all_tests:
        print("âš ï¸ æš‚æ— æµ‹è¯•æ•°æ®")
        return
    
    total_tests = len(all_tests)
    successful_tests = len([t for t in all_tests if t['success']])
    failed_tests = total_tests - successful_tests
    success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
    
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡")
    print("=" * 40)
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"æˆåŠŸæµ‹è¯•: {successful_tests}")
    print(f"å¤±è´¥æµ‹è¯•: {failed_tests}")
    print(f"æˆåŠŸç‡: {success_rate:.1f}%")
    
    # æŒ‰æµ‹è¯•ç±»å‹ç»Ÿè®¡
    test_types = {}
    for test in all_tests:
        test_type = test['test_type']
        if test_type not in test_types:
            test_types[test_type] = {'total': 0, 'success': 0}
        test_types[test_type]['total'] += 1
        if test['success']:
            test_types[test_type]['success'] += 1
    
    if test_types:
        print(f"\nğŸ“ˆ æŒ‰æµ‹è¯•ç±»å‹ç»Ÿè®¡:")
        for test_type, stats in test_types.items():
            success_rate = stats['success'] / stats['total'] * 100
            print(f"  {test_type}: {stats['total']} æ¬¡æµ‹è¯•, æˆåŠŸç‡ {success_rate:.1f}%")

def cleanup_data(days: int):
    """æ¸…ç†æ—§æ•°æ®"""
    data_manager = TestDataManager()
    
    try:
        data_manager.cleanup_old_data(days)
        print(f"âœ… å·²æ¸…ç† {days} å¤©å‰çš„æ•°æ®")
    except Exception as e:
        print(f"âŒ æ¸…ç†å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        show_help()
        return
    
    command = sys.argv[1].lower()
    
    if command == "help":
        show_help()
    elif command == "list":
        list_tests()
    elif command == "show":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾›æµ‹è¯•ID")
            return
        try:
            test_id = int(sys.argv[2])
            show_test(test_id)
        except ValueError:
            print("âŒ æµ‹è¯•IDå¿…é¡»æ˜¯æ•°å­—")
    elif command == "export":
        format_type = sys.argv[2] if len(sys.argv) > 2 else "json"
        if format_type not in ["json", "csv", "excel"]:
            print("âŒ æ”¯æŒçš„æ ¼å¼: json, csv, excel")
            return
        export_data(format_type)
    elif command == "stats":
        show_stats()
    elif command == "cleanup":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾›ä¿ç•™å¤©æ•°")
            return
        try:
            days = int(sys.argv[2])
            cleanup_data(days)
        except ValueError:
            print("âŒ å¤©æ•°å¿…é¡»æ˜¯æ•°å­—")
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
        show_help()

if __name__ == "__main__":
    main()
