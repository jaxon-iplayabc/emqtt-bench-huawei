#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
eMQTT-Bench è‡ªåŠ¨æ•°æ®æ”¶é›†å’ŒæŠ¥å‘Šç”Ÿæˆå™¨
ç”¨æˆ·è¿è¡Œmain.pyæ—¶ç›´æ¥æ‰§è¡Œæ•°æ®æ”¶é›†ä»»åŠ¡ï¼Œå®Œæˆæˆ–ä¸­æ–­æ—¶è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š
ä½œè€…: Jaxon
æ—¥æœŸ: 2024-12-19
"""

import sys
import os
import signal
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def get_huawei_template_path() -> str:
    """è·å–åä¸ºäº‘æ¨¡æ¿æ–‡ä»¶çš„ç»å¯¹è·¯å¾„"""
    # è·å–main.pyæ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
    main_dir = Path(__file__).parent
    project_root = main_dir
    template_path = project_root / "huawei_cloud_payload_template.json"
    return str(template_path.absolute())

from emqtt_test_manager import EMQTTTestManager, TestConfig, TestResult
from metrics_collector import PrometheusMetricsCollector, MetricsAnalyzer
from continuous_metrics_collector import ContinuousMetricsCollector
from enhanced_markdown_generator import EnhancedMarkdownGenerator
from test_data_manager import TestDataManager, TestData
from test_specific_filter import TestSpecificFilter
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.prompt import Confirm, IntPrompt, Prompt
from rich.table import Table
import json
import re

console = Console()

class AutoDataCollector:
    """è‡ªåŠ¨æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self):
        self.test_manager = EMQTTTestManager()
        self.metrics_collector = PrometheusMetricsCollector()
        self.metrics_analyzer = MetricsAnalyzer()
        self.continuous_collector = ContinuousMetricsCollector()  # æ–°å¢æŒç»­æ”¶é›†å™¨
        self.enhanced_generator = EnhancedMarkdownGenerator()  # æ–°å¢å¢å¼ºç‰ˆæŠ¥å‘Šç”Ÿæˆå™¨
        self.data_manager = TestDataManager()  # æ–°å¢æµ‹è¯•æ•°æ®ç®¡ç†å™¨
        self.test_filter = TestSpecificFilter()  # æ–°å¢æµ‹è¯•ç‰¹å®šè¿‡æ»¤å™¨
        self.test_results: List[TestResult] = []
        self.continuous_data_files: List[str] = []  # å­˜å‚¨æŒç»­æ•°æ®æ–‡ä»¶è·¯å¾„
        self.running = True
        self.start_time = datetime.now()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        # å®šä¹‰æ— æ•ˆæ•°æ®è¿‡æ»¤è§„åˆ™
        self.invalid_data_patterns = {
            # é›¶å€¼æŒ‡æ ‡ï¼ˆå¯¹æµ‹è¯•æ— æ„ä¹‰çš„æŒ‡æ ‡ï¼‰
            'zero_value_metrics': [
                'connection_idle', 'recv', 'connect_fail', 'pub_fail', 'pub_overrun',
                'connect_retried', 'sub_fail', 'reconnect_succ', 'sub', 'publish_latency',
                'pub_succ', 'connection_timeout', 'connection_refused', 'unreachable', 'pub'
            ],
            # Erlang VMç³»ç»ŸæŒ‡æ ‡ï¼ˆä¸MQTTæµ‹è¯•æ€§èƒ½æ— å…³ï¼‰
            'erlang_vm_metrics': [
                'erlang_vm_memory_', 'erlang_vm_msacc_', 'erlang_vm_statistics_',
                'erlang_vm_dirty_', 'erlang_vm_ets_', 'erlang_vm_logical_',
                'erlang_vm_port_', 'erlang_vm_process_', 'erlang_vm_schedulers_',
                'erlang_vm_smp_', 'erlang_vm_thread_', 'erlang_vm_time_',
                'erlang_vm_wordsize_', 'erlang_vm_atom_', 'erlang_vm_allocators'
            ],
            # ç›´æ–¹å›¾æ¡¶æ•°æ®ï¼ˆé€šå¸¸åŒ…å«å¤§é‡é›¶å€¼æ¡¶ï¼‰
            'histogram_buckets': [
                '_bucket', '_count', '_sum'
            ],
            # é‡å¤çš„help_text
            'redundant_help_text': [
                'connection_idle connection_idle', 'recv recv', 'connect_fail connect_fail',
                'pub_fail pub_fail', 'pub_overrun pub_overrun', 'connect_retried connect_retried',
                'connect_succ connect_succ', 'sub_fail sub_fail', 'reconnect_succ reconnect_succ',
                'sub sub', 'publish_latency publish_latency', 'pub_succ pub_succ',
                'connection_timeout connection_timeout', 'connection_refused connection_refused',
                'unreachable unreachable', 'pub pub'
            ]
        }
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        console.print("\n[yellow]æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢æ‰€æœ‰æŒ‡æ ‡æ”¶é›†å¹¶ç”ŸæˆæŠ¥å‘Š...[/yellow]")
        self.running = False
        
        # åœæ­¢æ‰€æœ‰æŒç»­æŒ‡æ ‡æ”¶é›†
        self.continuous_collector.stop_all_collections()
        
        # ä¿å­˜æ‰€æœ‰æµ‹è¯•çš„æŒç»­æ•°æ®
        summaries = self.continuous_collector.get_all_summaries()
        for test_name, summary in summaries.items():
            if summary.get('total_collections', 0) > 0:
                self.continuous_collector.save_test_data(test_name)
        
        self.generate_final_report()
        sys.exit(0)
    
    def run_automatic_collection(self):
        """è¿è¡Œè‡ªåŠ¨æ•°æ®æ”¶é›†"""
        console.print("ğŸš€ [bold blue]eMQTT-Bench è‡ªåŠ¨æ•°æ®æ”¶é›†å™¨[/bold blue]")
        console.print("=" * 60)
        console.print("âœ¨ [yellow]è‡ªåŠ¨æ‰§è¡Œæµ‹è¯•ã€æ”¶é›†æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š[/yellow]")
        console.print("ğŸ’¡ [dim]æŒ‰ Ctrl+C å¯éšæ—¶ä¸­æ–­å¹¶ç”ŸæˆæŠ¥å‘Š[/dim]")
        console.print("")

        try:
            # 1. åŠ è½½æˆ–åˆ›å»ºé…ç½®
            config = self._setup_configuration()

            # 2. æ˜¾ç¤ºé…ç½®æ‘˜è¦
            self._show_config_summary(config)

            # 3. ç¡®è®¤å¼€å§‹æ”¶é›†
            if not Confirm.ask("æ˜¯å¦å¼€å§‹è‡ªåŠ¨æ•°æ®æ”¶é›†?", default=True):
                console.print("[yellow]ç”¨æˆ·å–æ¶ˆæ“ä½œ[/yellow]")
                return

            # 4. é€‰æ‹©æµ‹è¯•é¡¹
            selected_tests = self._select_test_items(config)

            # 5. æ‰§è¡Œæµ‹è¯•å’Œæ•°æ®æ”¶é›†
            self._execute_tests_and_collect_data(config, selected_tests)

            # 5. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            self.generate_final_report()

        except KeyboardInterrupt:
            console.print("\n[yellow]ç”¨æˆ·ä¸­æ–­æ•°æ®æ”¶é›†[/yellow]")
            self.generate_final_report()
        except Exception as e:
            console.print(f"\n[red]âŒ æ•°æ®æ”¶é›†å¤±è´¥: {e}[/red]")
            self.generate_final_report()
            sys.exit(1)
    
    def _setup_configuration(self) -> TestConfig:
        """è®¾ç½®é…ç½®"""
        console.print(Panel.fit("[bold blue]ğŸ“‹ é…ç½®è®¾ç½®[/bold blue]"))
        
        # å°è¯•åŠ è½½ç°æœ‰é…ç½®
        config_manager = self.test_manager.config_manager
        config = config_manager.load_config()
        
        # æ˜¾ç¤ºå½“å‰é…ç½®å†…å®¹
        self._display_current_config(config)
        
        # è¯¢é—®æ˜¯å¦ä½¿ç”¨å½“å‰é…ç½®
        if Confirm.ask("æ˜¯å¦ä½¿ç”¨ä»¥ä¸Šé…ç½®?", default=True):
            console.print("[green]âœ… ä½¿ç”¨å½“å‰é…ç½®[/green]")
            
            # å¦‚æœä½¿ç”¨åä¸ºäº‘è®¤è¯ï¼Œæ£€æŸ¥å¿…è¦çš„åä¸ºäº‘å‚æ•°
            if config.use_huawei_auth:
                missing_params = []
                if not hasattr(config, 'huawei_ak') or not config.huawei_ak:
                    missing_params.append("åä¸ºäº‘è®¿é—®å¯†é’¥ID (AK)")
                if not hasattr(config, 'huawei_sk') or not config.huawei_sk:
                    missing_params.append("åä¸ºäº‘è®¿é—®å¯†é’¥Secret (SK)")
                if not hasattr(config, 'huawei_endpoint') or not config.huawei_endpoint:
                    missing_params.append("åä¸ºäº‘IoTDAç«¯ç‚¹")
                
                if missing_params:
                    console.print(f"\n[yellow]âš ï¸ æ£€æµ‹åˆ°ç¼ºå°‘åä¸ºäº‘å‚æ•°: {', '.join(missing_params)}[/yellow]")
                    console.print("[cyan]ğŸ“ è¯·è¡¥å……åä¸ºäº‘è®¤è¯å‚æ•°:[/cyan]")
                    
                    config.huawei_ak = Prompt.ask("åä¸ºäº‘è®¿é—®å¯†é’¥ID (AK)", default=getattr(config, 'huawei_ak', ''))
                    config.huawei_sk = Prompt.ask("åä¸ºäº‘è®¿é—®å¯†é’¥Secret (SK)", default=getattr(config, 'huawei_sk', ''), password=True)
                    config.huawei_endpoint = Prompt.ask("åä¸ºäº‘IoTDAç«¯ç‚¹", default=getattr(config, 'huawei_endpoint', ''))
                    config.huawei_region = Prompt.ask("åä¸ºäº‘åŒºåŸŸID", default=getattr(config, 'huawei_region', 'cn-north-4'))
                    config.broadcast_topic = Prompt.ask("å¹¿æ’­ä¸»é¢˜", default=getattr(config, 'broadcast_topic', '$oc/broadcast/test'))
                    config.broadcast_interval = IntPrompt.ask("å¹¿æ’­å‘é€é—´éš”(ç§’)", default=getattr(config, 'broadcast_interval', 5))
                    
                    # è¯¢é—®æ˜¯å¦ä¿å­˜æ›´æ–°çš„é…ç½®
                    if Confirm.ask("æ˜¯å¦ä¿å­˜æ›´æ–°çš„é…ç½®?", default=True):
                        try:
                            config_manager.save_config(config)
                            console.print("[green]âœ… é…ç½®å·²æ›´æ–°å¹¶ä¿å­˜[/green]")
                        except Exception as e:
                            console.print(f"[red]âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}[/red]")
        else:
            # å¿«é€Ÿé…ç½®è°ƒæ•´
            console.print("\n[yellow]å¿«é€Ÿé…ç½®è°ƒæ•´:[/yellow]")
            config.host = Prompt.ask("MQTTæœåŠ¡å™¨åœ°å€", default=config.host)
            config.port = IntPrompt.ask("MQTTç«¯å£", default=config.port)
            config.client_count = IntPrompt.ask("å®¢æˆ·ç«¯æ•°é‡", default=config.client_count)
            config.test_duration = IntPrompt.ask("æµ‹è¯•æŒç»­æ—¶é—´(ç§’)", default=config.test_duration)
            config.prometheus_port = IntPrompt.ask("Prometheusèµ·å§‹ç«¯å£", default=config.prometheus_port)
            
            # MQTTé…ç½®
            console.print("\n[cyan]ğŸ“¡ MQTTé…ç½®:[/cyan]")
            config.qos = IntPrompt.ask("QoSç­‰çº§ (0=æœ€å¤šä¸€æ¬¡, 1=è‡³å°‘ä¸€æ¬¡, 2=æ°å¥½ä¸€æ¬¡)", default=config.qos)
            
            # æ˜¾ç¤ºQoSè¯´æ˜
            qos_descriptions = {
                0: "æœ€å¤šä¸€æ¬¡ (Fire and Forget) - ä¸ä¿è¯æ¶ˆæ¯é€è¾¾",
                1: "è‡³å°‘ä¸€æ¬¡ (At Least Once) - ä¿è¯æ¶ˆæ¯é€è¾¾ï¼Œå¯èƒ½é‡å¤",
                2: "æ°å¥½ä¸€æ¬¡ (Exactly Once) - ä¿è¯æ¶ˆæ¯é€è¾¾ä¸”ä¸é‡å¤"
            }
            console.print(f"[dim]ğŸ’¡ å½“å‰QoS: {qos_descriptions.get(config.qos, 'æœªçŸ¥')}[/dim]")
            
            # åä¸ºäº‘è®¤è¯é…ç½®
            console.print("\n[cyan]ğŸ” åä¸ºäº‘IoTè®¤è¯é…ç½®:[/cyan]")
            config.use_huawei_auth = Confirm.ask("æ˜¯å¦ä½¿ç”¨åä¸ºäº‘IoTè®¤è¯?", default=config.use_huawei_auth)
            
            if config.use_huawei_auth:
                console.print("[yellow]ğŸ“ åä¸ºäº‘è®¤è¯å‚æ•°è®¾ç½®:[/yellow]")
                config.device_prefix = Prompt.ask("è®¾å¤‡IDå‰ç¼€", default=config.device_prefix)
                config.huawei_secret = Prompt.ask("è®¾å¤‡å¯†é’¥", default=config.huawei_secret, password=True)
                
                # åä¸ºäº‘å¹¿æ’­æµ‹è¯•å‚æ•°
                console.print("\n[yellow]ğŸ“¡ åä¸ºäº‘å¹¿æ’­æµ‹è¯•å‚æ•°:[/yellow]")
                console.print("[dim]ğŸ’¡ è¿™äº›å‚æ•°ç”¨äºå‘é€å¹¿æ’­æ¶ˆæ¯ï¼Œè®©è®¾å¤‡èƒ½å¤Ÿæ¥æ”¶å¹¿æ’­ä¿¡æ¯[/dim]")
                
                config.huawei_ak = Prompt.ask("åä¸ºäº‘è®¿é—®å¯†é’¥ID (AK)", default=getattr(config, 'huawei_ak', ''))
                config.huawei_sk = Prompt.ask("åä¸ºäº‘è®¿é—®å¯†é’¥Secret (SK)", default=getattr(config, 'huawei_sk', ''), password=True)
                config.huawei_endpoint = Prompt.ask("åä¸ºäº‘IoTDAç«¯ç‚¹", default=getattr(config, 'huawei_endpoint', ''))
                config.huawei_region = Prompt.ask("åä¸ºäº‘åŒºåŸŸID", default=getattr(config, 'huawei_region', 'cn-north-4'))
                config.broadcast_topic = Prompt.ask("å¹¿æ’­ä¸»é¢˜", default=getattr(config, 'broadcast_topic', '$oc/broadcast/test'))
                config.broadcast_interval = IntPrompt.ask("å¹¿æ’­å‘é€é—´éš”(ç§’)", default=getattr(config, 'broadcast_interval', 5))
                
                # æ˜¾ç¤ºåä¸ºäº‘é…ç½®è¯´æ˜
                console.print("\n[dim]ğŸ’¡ åä¸ºäº‘é…ç½®è¯´æ˜:[/dim]")
                console.print("[dim]  â€¢ è®¾å¤‡IDå‰ç¼€: ç”¨äºç”Ÿæˆè®¾å¤‡IDï¼Œå¦‚ 'speaker' ä¼šç”Ÿæˆ speaker_000000001, speaker_000000002 ç­‰[/dim]")
                console.print("[dim]  â€¢ è®¾å¤‡å¯†é’¥: åä¸ºäº‘IoTå¹³å°ä¸­è®¾å¤‡çš„å¯†é’¥ï¼Œç”¨äºè®¾å¤‡è®¤è¯[/dim]")
                console.print("[dim]  â€¢ åä¸ºäº‘AK/SK: ç”¨äºè°ƒç”¨åä¸ºäº‘IoTDA APIå‘é€å¹¿æ’­æ¶ˆæ¯ï¼Œè®©è®¾å¤‡æ¥æ”¶å¹¿æ’­ä¿¡æ¯[/dim]")
                console.print("[dim]  â€¢ åä¸ºäº‘ç«¯ç‚¹: åä¸ºäº‘IoTDAæœåŠ¡çš„APIç«¯ç‚¹åœ°å€ï¼Œç”¨äºå‘é€å¹¿æ’­æ¶ˆæ¯[/dim]")
                console.print("[dim]  â€¢ å¹¿æ’­ä¸»é¢˜: è®¾å¤‡è®¢é˜…çš„ä¸»é¢˜ï¼Œç”¨äºæ¥æ”¶å¹¿æ’­æ¶ˆæ¯[/dim]")
                console.print("[dim]  â€¢ ç¡®ä¿è®¾å¤‡å·²åœ¨åä¸ºäº‘IoTå¹³å°æ³¨å†Œï¼Œä¸”å…·æœ‰è®¢é˜…æƒé™[/dim]")
            else:
                console.print("[yellow]â„¹ï¸ å°†ä½¿ç”¨æ ‡å‡†MQTTè¿æ¥ï¼ˆæ— éœ€åä¸ºäº‘è®¤è¯ï¼‰[/yellow]")
            
            # éªŒè¯eMQTT-Benchè·¯å¾„
            console.print("\n[cyan]ğŸ”§ eMQTT-Benché…ç½®:[/cyan]")
            while True:
                emqtt_path = Prompt.ask("eMQTT-Benchè·¯å¾„", default=config.emqtt_bench_path)
                if emqtt_path.startswith('.') or emqtt_path.startswith('/') :
                    if self._validate_emqtt_bench_path(emqtt_path):
                        config.emqtt_bench_path = emqtt_path
                        break
                    else:
                        console.print(f"[red]âŒ è·¯å¾„æ— æ•ˆ: {emqtt_path}[/red]")
                        console.print("[yellow]è¯·ç¡®ä¿è·¯å¾„æŒ‡å‘æœ‰æ•ˆçš„eMQTT-Benchå¯æ‰§è¡Œæ–‡ä»¶[/yellow]")
                else:
                    config.emqtt_bench_path = emqtt_path
                    break
            
            # æ˜¾ç¤ºä¿®æ”¹åçš„é…ç½®
            console.print("\n[yellow]ä¿®æ”¹åçš„é…ç½®:[/yellow]")
            self._display_current_config(config)
            
            # è¯¢é—®æ˜¯å¦ä¿å­˜é…ç½®
            if Confirm.ask("æ˜¯å¦ä¿å­˜ä¿®æ”¹åçš„é…ç½®?", default=True):
                try:
                    config_manager.save_config(config)
                    console.print("[green]âœ… é…ç½®å·²ä¿å­˜åˆ° emqtt_test_config.json[/green]")
                except Exception as e:
                    console.print(f"[red]âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}[/red]")
            else:
                console.print("[yellow]âš ï¸ é…ç½®æœªä¿å­˜ï¼Œä¸‹æ¬¡è¿è¡Œæ—¶å°†ä½¿ç”¨é»˜è®¤é…ç½®[/yellow]")
        
        return config
    
    def _display_current_config(self, config: TestConfig):
        """æ˜¾ç¤ºå½“å‰é…ç½®å†…å®¹"""
        console.print("\n[cyan]ğŸ“‹ å½“å‰é…ç½®å†…å®¹:[/cyan]")
        
        # åˆ›å»ºé…ç½®è¡¨æ ¼
        from rich.table import Table
        config_table = Table(show_header=True, header_style="bold magenta")
        config_table.add_column("é…ç½®é¡¹", style="cyan", width=20)
        config_table.add_column("å€¼", style="green", width=30)
        config_table.add_column("è¯´æ˜", style="dim", width=40)
        
        config_table.add_row("MQTTæœåŠ¡å™¨", f"{config.host}:{config.port}", "MQTTæœåŠ¡å™¨åœ°å€å’Œç«¯å£")
        config_table.add_row("å®¢æˆ·ç«¯æ•°é‡", str(config.client_count), "åŒæ—¶è¿æ¥çš„å®¢æˆ·ç«¯æ•°é‡")
        config_table.add_row("æ¶ˆæ¯é—´éš”", f"{config.msg_interval}ms", "æ¶ˆæ¯å‘é€é—´éš”æ—¶é—´")
        config_table.add_row("æµ‹è¯•æŒç»­æ—¶é—´", f"{config.test_duration}ç§’", "æ¯ä¸ªæµ‹è¯•çš„æŒç»­æ—¶é—´")
        config_table.add_row("Prometheusç«¯å£", str(config.prometheus_port), "PrometheusæŒ‡æ ‡èµ·å§‹ç«¯å£")
        config_table.add_row("åä¸ºäº‘è®¤è¯", "æ˜¯" if config.use_huawei_auth else "å¦", "æ˜¯å¦ä½¿ç”¨åä¸ºäº‘IoTè®¤è¯")
        
        if config.use_huawei_auth:
            config_table.add_row("è®¾å¤‡å‰ç¼€", config.device_prefix, "åä¸ºäº‘è®¾å¤‡IDå‰ç¼€")
            config_table.add_row("è®¾å¤‡å¯†é’¥", "***" if config.huawei_secret else "æœªé…ç½®", "åä¸ºäº‘è®¾å¤‡å¯†é’¥")
            
            # åä¸ºäº‘å¹¿æ’­å‚æ•°
            huawei_ak = getattr(config, 'huawei_ak', '')
            huawei_sk = getattr(config, 'huawei_sk', '')
            huawei_endpoint = getattr(config, 'huawei_endpoint', '')
            
            if huawei_ak:
                config_table.add_row("åä¸ºäº‘AK", huawei_ak[:8] + "..." if len(huawei_ak) > 8 else huawei_ak, "åä¸ºäº‘è®¿é—®å¯†é’¥ID")
            else:
                config_table.add_row("åä¸ºäº‘AK", "æœªé…ç½®", "åä¸ºäº‘è®¿é—®å¯†é’¥ID")
            
            if huawei_sk:
                config_table.add_row("åä¸ºäº‘SK", "***", "åä¸ºäº‘è®¿é—®å¯†é’¥Secret")
            else:
                config_table.add_row("åä¸ºäº‘SK", "æœªé…ç½®", "åä¸ºäº‘è®¿é—®å¯†é’¥Secret")
            
            config_table.add_row("åä¸ºäº‘ç«¯ç‚¹", huawei_endpoint or "æœªé…ç½®", "åä¸ºäº‘IoTDAç«¯ç‚¹")
            config_table.add_row("åä¸ºäº‘åŒºåŸŸ", getattr(config, 'huawei_region', 'cn-north-4'), "åä¸ºäº‘åŒºåŸŸID")
            config_table.add_row("å¹¿æ’­ä¸»é¢˜", getattr(config, 'broadcast_topic', '$oc/broadcast/test'), "å¹¿æ’­æ¶ˆæ¯ä¸»é¢˜")
            config_table.add_row("å¹¿æ’­é—´éš”", f"{getattr(config, 'broadcast_interval', 5)}ç§’", "å¹¿æ’­å‘é€é—´éš”")
        
        # çªå‡ºæ˜¾ç¤ºeMQTT-Benchè·¯å¾„
        config_table.add_row("ğŸ“¡ QoSç­‰çº§", str(config.qos), "MQTTæ¶ˆæ¯è´¨é‡ç­‰çº§")
        config_table.add_row("ğŸ”§ eMQTT-Benchè·¯å¾„", config.emqtt_bench_path, "eMQTT-Benchå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„")
        
        console.print(config_table)
        console.print("")
    
    def _select_test_items(self, config: TestConfig) -> List[Dict[str, Any]]:
        """é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•é¡¹"""
        console.print(Panel.fit("[bold blue]ğŸ§ª æµ‹è¯•é¡¹é€‰æ‹©[/bold blue]"))
        
        # æ ¹æ®åä¸ºäº‘è®¤è¯çŠ¶æ€å®šä¹‰æµ‹è¯•é¡¹
        if config.use_huawei_auth:
            # åä¸ºäº‘æµ‹è¯•æ¨¡å¼ï¼šæ˜¾ç¤ºåä¸ºäº‘çš„å››ç§æµ‹è¯•ç±»å‹
            available_tests = [
                {
                    "name": "åä¸ºäº‘è¿æ¥æµ‹è¯•",
                    "description": "æµ‹è¯•åä¸ºäº‘IoTå¹³å°è¿æ¥åŠŸèƒ½",
                    "command": self._build_huawei_connection_test_command(config),
                    "port": config.prometheus_port,
                    "duration": config.test_duration,
                    "enabled": True
                },
                {
                    "name": "åä¸ºäº‘å‘å¸ƒæµ‹è¯•",
                    "description": "æµ‹è¯•åä¸ºäº‘IoTå¹³å°æ¶ˆæ¯å‘å¸ƒåŠŸèƒ½",
                    "command": self._build_huawei_publish_test_command(config),
                    "port": config.prometheus_port + 1,
                    "duration": config.test_duration,
                    "enabled": True
                },
                {
                    "name": "åä¸ºäº‘è®¢é˜…æµ‹è¯•",
                    "description": "æµ‹è¯•åä¸ºäº‘IoTå¹³å°æ¶ˆæ¯è®¢é˜…åŠŸèƒ½ï¼ˆåŒæ—¶å¯åŠ¨å¹¿æ’­å‘é€å™¨ï¼‰",
                    "command": self._build_huawei_subscribe_test_command(config),
                    "port": config.prometheus_port + 2,
                    "duration": config.test_duration,
                    "enabled": True
                },
                {
                    "name": "åä¸ºäº‘å¹¿æ’­æµ‹è¯•",
                    "description": "æµ‹è¯•åä¸ºäº‘IoTå¹³å°å¹¿æ’­æ¶ˆæ¯åŠŸèƒ½ï¼ˆå‘é€+è®¢é˜…ï¼‰",
                    "command": self._build_huawei_broadcast_test_command(config),
                    "port": config.prometheus_port + 3,
                    "duration": config.test_duration,
                    "enabled": True
                }
            ]
        else:
            # æ ‡å‡†MQTTæµ‹è¯•æ¨¡å¼ï¼šæ˜¾ç¤ºæ ‡å‡†çš„ä¸‰ç§æµ‹è¯•ç±»å‹
            available_tests = [
                {
                    "name": "è¿æ¥æµ‹è¯•",
                    "description": "æµ‹è¯•MQTTå®¢æˆ·ç«¯è¿æ¥åŠŸèƒ½",
                    "command": self._build_connection_test_command(config),
                    "port": config.prometheus_port,
                    "duration": config.test_duration,
                    "enabled": True
                },
                {
                    "name": "å‘å¸ƒæµ‹è¯•", 
                    "description": "æµ‹è¯•MQTTæ¶ˆæ¯å‘å¸ƒåŠŸèƒ½",
                    "command": self._build_publish_test_command(config),
                    "port": config.prometheus_port + 1,
                    "duration": config.test_duration,
                    "enabled": True
                },
                {
                    "name": "è®¢é˜…æµ‹è¯•",
                    "description": "æµ‹è¯•MQTTæ¶ˆæ¯è®¢é˜…åŠŸèƒ½",
                    "command": self._build_subscribe_test_command(config),
                    "port": config.prometheus_port + 2,
                    "duration": config.test_duration,
                    "enabled": True
                }
            ]
        
        # æ˜¾ç¤ºæµ‹è¯•æ¨¡å¼è¯´æ˜
        if config.use_huawei_auth:
            console.print("\n[green]â˜ï¸ åä¸ºäº‘æµ‹è¯•æ¨¡å¼[/green]")
            console.print("[dim]ä½¿ç”¨åä¸ºäº‘IoTå¹³å°è®¤è¯å’Œè®¾å¤‡ç®¡ç†åŠŸèƒ½[/dim]")
        else:
            console.print("\n[blue]ğŸ”— æ ‡å‡†MQTTæµ‹è¯•æ¨¡å¼[/blue]")
            console.print("[dim]ä½¿ç”¨æ ‡å‡†MQTTåè®®è¿›è¡Œæµ‹è¯•[/dim]")
        
        # æ˜¾ç¤ºæµ‹è¯•é¡¹é€‰æ‹©èœå•
        console.print("\n[cyan]ğŸ“‹ å¯ç”¨çš„æµ‹è¯•é¡¹:[/cyan]")
        
        from rich.table import Table
        test_table = Table(show_header=True, header_style="bold magenta")
        test_table.add_column("åºå·", style="cyan", width=6)
        test_table.add_column("æµ‹è¯•åç§°", style="green", width=15)
        test_table.add_column("æè¿°", style="dim", width=40)
        test_table.add_column("ç«¯å£", style="yellow", width=8)
        test_table.add_column("çŠ¶æ€", style="blue", width=8)
        
        for i, test in enumerate(available_tests, 1):
            status = "âœ… å¯ç”¨" if test["enabled"] else "âŒ ç¦ç”¨"
            test_table.add_row(
                str(i),
                test["name"],
                test["description"],
                str(test["port"]),
                status
            )
        
        console.print(test_table)
        console.print("")
        
        # è¯¢é—®ç”¨æˆ·é€‰æ‹©
        console.print("[yellow]è¯·é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•é¡¹:[/yellow]")
        console.print("  [cyan]1.[/cyan] è¿è¡Œæ‰€æœ‰æµ‹è¯•")
        console.print("  [cyan]2.[/cyan] è‡ªå®šä¹‰é€‰æ‹©æµ‹è¯•é¡¹")
        if config.use_huawei_auth:
            console.print("  [cyan]3.[/cyan] å¿«é€Ÿæµ‹è¯•ï¼ˆä»…åä¸ºäº‘è¿æ¥æµ‹è¯•ï¼‰")
            console.print("  [cyan]4.[/cyan] åä¸ºäº‘å¹¿æ’­æµ‹è¯•ï¼ˆå‘é€+è®¢é˜…ï¼‰")
        else:
            console.print("  [cyan]3.[/cyan] å¿«é€Ÿæµ‹è¯•ï¼ˆä»…è¿æ¥æµ‹è¯•ï¼‰")
        
        while True:
            if config.use_huawei_auth:
                choice = Prompt.ask("è¯·é€‰æ‹© (1-4)", default="1")
            else:
                choice = Prompt.ask("è¯·é€‰æ‹© (1-3)", default="1")
            
            if choice == "1":
                console.print("[green]âœ… å°†è¿è¡Œæ‰€æœ‰æµ‹è¯•é¡¹[/green]")
                return available_tests
                
            elif choice == "2":
                return self._custom_select_tests(available_tests)
                
            elif choice == "3":
                if config.use_huawei_auth:
                    console.print("[green]âœ… å°†è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆä»…åä¸ºäº‘è¿æ¥æµ‹è¯•ï¼‰[/green]")
                else:
                    console.print("[green]âœ… å°†è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆä»…è¿æ¥æµ‹è¯•ï¼‰[/green]")
                return [available_tests[0]]  # åªè¿”å›è¿æ¥æµ‹è¯•
                
            elif choice == "4" and config.use_huawei_auth:
                console.print("[green]âœ… å°†è¿è¡Œåä¸ºäº‘å¹¿æ’­æµ‹è¯•ï¼ˆå‘é€+è®¢é˜…ï¼‰[/green]")
                return [available_tests[3]]  # åªè¿”å›åä¸ºäº‘å¹¿æ’­æµ‹è¯•
                
            else:
                if config.use_huawei_auth:
                    console.print("[red]âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-4[/red]")
                else:
                    console.print("[red]âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-3[/red]")
    
    def _custom_select_tests(self, available_tests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è‡ªå®šä¹‰é€‰æ‹©æµ‹è¯•é¡¹"""
        console.print("\n[yellow]è‡ªå®šä¹‰é€‰æ‹©æµ‹è¯•é¡¹:[/yellow]")
        
        # é‡æ–°æ˜¾ç¤ºæµ‹è¯•é¡¹åˆ—è¡¨
        console.print("\n[cyan]ğŸ“‹ å¯é€‰æ‹©çš„æµ‹è¯•é¡¹:[/cyan]")
        
        from rich.table import Table
        selection_table = Table(show_header=True, header_style="bold magenta")
        selection_table.add_column("åºå·", style="cyan", width=6)
        selection_table.add_column("æµ‹è¯•åç§°", style="green", width=15)
        selection_table.add_column("æè¿°", style="dim", width=40)
        selection_table.add_column("ç«¯å£", style="yellow", width=8)
        
        for i, test in enumerate(available_tests, 1):
            selection_table.add_row(
                str(i),
                test["name"],
                test["description"],
                str(test["port"])
            )
        
        console.print(selection_table)
        console.print("")
        
        console.print("[yellow]è¯·è¾“å…¥è¦è¿è¡Œçš„æµ‹è¯•é¡¹åºå·:[/yellow]")
        console.print("  â€¢ å•ä¸ªæµ‹è¯•: [cyan]1[/cyan]")
        console.print("  â€¢ å¤šä¸ªæµ‹è¯•: [cyan]1,3,4[/cyan]")
        console.print("  â€¢ è¿è¡Œæ‰€æœ‰: [cyan]all[/cyan]")
        console.print("")
        
        while True:
            selection = Prompt.ask("æµ‹è¯•é¡¹é€‰æ‹©", default="all")
            
            if selection.lower() == "all":
                console.print("[green]âœ… å°†è¿è¡Œæ‰€æœ‰æµ‹è¯•é¡¹[/green]")
                return available_tests
            
            try:
                # è§£æç”¨æˆ·è¾“å…¥
                indices = [int(x.strip()) for x in selection.split(",")]
                selected_tests = []
                
                for idx in indices:
                    if 1 <= idx <= len(available_tests):
                        selected_tests.append(available_tests[idx - 1])
                    else:
                        console.print(f"[red]âŒ æ— æ•ˆåºå·: {idx} (æœ‰æ•ˆèŒƒå›´: 1-{len(available_tests)})[/red]")
                        break
                else:
                    # æ‰€æœ‰åºå·éƒ½æœ‰æ•ˆ
                    if selected_tests:
                        console.print(f"[green]âœ… å·²é€‰æ‹© {len(selected_tests)} ä¸ªæµ‹è¯•é¡¹:[/green]")
                        for i, test in enumerate(selected_tests, 1):
                            console.print(f"  {i}. {test['name']} (ç«¯å£: {test['port']})")
                        return selected_tests
                    else:
                        console.print("[red]âŒ æœªé€‰æ‹©ä»»ä½•æµ‹è¯•é¡¹[/red]")
                        
            except ValueError:
                console.print("[red]âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—åºå·æˆ– 'all'[/red]")
                console.print("[dim]ç¤ºä¾‹: 1 æˆ– 1,3,4 æˆ– all[/dim]")
    
    def _validate_emqtt_bench_path(self, path: str) -> bool:
        """éªŒè¯eMQTT-Benchè·¯å¾„æ˜¯å¦æœ‰æ•ˆ"""
        try:
            import os
            from pathlib import Path
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(path):
                return False
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
            if not os.path.isfile(path):
                return False
            
            # æ£€æŸ¥æ˜¯å¦å¯æ‰§è¡Œ
            if not os.access(path, os.X_OK):
                return False
            
            # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«emqtt_bench
            filename = os.path.basename(path)
            if 'emqtt_bench' not in filename:
                return False
            
            return True
            
        except Exception:
            return False
    
    def _check_port_availability(self, port: int) -> bool:
        """æ£€æŸ¥ç«¯å£æ˜¯å¦å¯ç”¨"""
        import socket
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.settimeout(1)
                result = s.connect_ex(('localhost', port))
                return result != 0  # ç«¯å£å¯ç”¨è¿”å›True
        except Exception:
            return False
    
    def _find_available_port(self, start_port: int, max_attempts: int = 10) -> int:
        """æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
        for i in range(max_attempts):
            port = start_port + i
            if self._check_port_availability(port):
                return port
        return start_port  # å¦‚æœæ‰¾ä¸åˆ°å¯ç”¨ç«¯å£ï¼Œè¿”å›åŸå§‹ç«¯å£
    
    def _kill_process_on_port(self, port: int) -> bool:
        """ç»ˆæ­¢å ç”¨æŒ‡å®šç«¯å£çš„è¿›ç¨‹"""
        try:
            import subprocess
            # æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹
            result = subprocess.run(
                f"lsof -ti:{port}",
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0 and result.stdout.strip():
                pids = result.stdout.strip().split('\n')
                for pid in pids:
                    if pid.strip():
                        try:
                            subprocess.run(f"kill -9 {pid.strip()}", shell=True)
                            console.print(f"[yellow]âš ï¸ å·²ç»ˆæ­¢å ç”¨ç«¯å£ {port} çš„è¿›ç¨‹ PID: {pid.strip()}[/yellow]")
                        except Exception as e:
                            console.print(f"[red]âŒ æ— æ³•ç»ˆæ­¢è¿›ç¨‹ {pid}: {e}[/red]")
                return True
            return False
        except Exception as e:
            console.print(f"[red]âŒ æ£€æŸ¥ç«¯å£å ç”¨å¤±è´¥: {e}[/red]")
            return False
    
    def _show_config_summary(self, config: TestConfig):
        """æ˜¾ç¤ºé…ç½®æ‘˜è¦"""
        table = Table(title="ğŸ“Š æ•°æ®æ”¶é›†é…ç½®")
        table.add_column("é…ç½®é¡¹", style="cyan")
        table.add_column("å€¼", style="green")
        
        table.add_row("MQTTæœåŠ¡å™¨", f"{config.host}:{config.port}")
        table.add_row("å®¢æˆ·ç«¯æ•°é‡", str(config.client_count))
        table.add_row("æ¶ˆæ¯é—´éš”", f"{config.msg_interval}ms")
        table.add_row("æµ‹è¯•æŒç»­æ—¶é—´", f"{config.test_duration}ç§’")
        table.add_row("Prometheusç«¯å£", str(config.prometheus_port))
        table.add_row("åä¸ºäº‘è®¤è¯", "æ˜¯" if config.use_huawei_auth else "å¦")
        
        console.print(table)
        console.print("")
    
    def _execute_tests_and_collect_data(self, config: TestConfig, selected_tests: List[Dict[str, Any]]):
        """æ‰§è¡Œæµ‹è¯•å¹¶æ”¶é›†æ•°æ®"""
        console.print(Panel.fit("[bold blue]ğŸ”„ å¼€å§‹æ‰§è¡Œæµ‹è¯•å’Œæ•°æ®æ”¶é›†[/bold blue]"))
        
        # æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æµ‹è¯•
        console.print(f"\n[cyan]ğŸ“‹ å°†æ‰§è¡Œ {len(selected_tests)} ä¸ªæµ‹è¯•é¡¹:[/cyan]")
        for i, test in enumerate(selected_tests, 1):
            console.print(f"  {i}. {test['name']} (ç«¯å£: {test['port']})")
        console.print("")
        
        # ä½¿ç”¨é€‰ä¸­çš„æµ‹è¯•ä»»åŠ¡
        test_tasks = selected_tests
        
        # æ‰§è¡Œæµ‹è¯•ä»»åŠ¡
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TimeElapsedColumn(),
            console=console
        ) as progress:
            
            for i, task in enumerate(test_tasks):
                if not self.running:
                    break
                    
                task_progress = progress.add_task(
                    f"æ‰§è¡Œ {task['name']}...", 
                    total=task['duration']
                )
                
                # æ‰§è¡Œæµ‹è¯•
                result = self._execute_single_test(task, progress, task_progress)
                if result:
                    self.test_results.append(result)
                    # ä¿å­˜æµ‹è¯•æ•°æ®
                    self._save_test_data(result, task)
                
                progress.update(task_progress, completed=task['duration'])
                console.print(f"[green]âœ… {task['name']} å®Œæˆ[/green]")
        
        console.print(f"\n[green]ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼å…±å®Œæˆ {len(self.test_results)} ä¸ªæµ‹è¯•[/green]")
    
    def _save_test_data(self, result: TestResult, task: Dict[str, Any]):
        """ä¿å­˜æµ‹è¯•æ•°æ®"""
        try:
            # è¯»å–æŒ‡æ ‡æ•°æ®
            raw_metrics = []
            if result.metrics_file:
                import json
                with open(result.metrics_file, 'r', encoding='utf-8') as f:
                    raw_metrics = json.load(f)
            
            # ç”Ÿæˆæ€§èƒ½æ‘˜è¦ï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼‰
            performance_summary = self._generate_performance_summary(raw_metrics)
            
            # è·å–é…ç½®ä¿¡æ¯
            config = self.test_manager.config_manager.config
            config_dict = {
                'host': config.host,
                'port': config.port,
                'client_count': config.client_count,
                'msg_interval': config.msg_interval,
                'test_duration': config.test_duration,
                'qos': config.qos,
                'use_huawei_auth': config.use_huawei_auth,
                'device_prefix': getattr(config, 'device_prefix', ''),
                'huawei_secret': getattr(config, 'huawei_secret', ''),
                'huawei_ak': getattr(config, 'huawei_ak', ''),
                'huawei_sk': getattr(config, 'huawei_sk', ''),
                'huawei_endpoint': getattr(config, 'huawei_endpoint', ''),
                'broadcast_topic': getattr(config, 'broadcast_topic', ''),
                'broadcast_interval': getattr(config, 'broadcast_interval', 5)
            }
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®å¯¹è±¡ï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼‰
            test_data = TestData(
                test_name=result.test_name,
                test_type=task.get('description', 'Unknown'),
                start_time=result.start_time.isoformat(),
                end_time=result.end_time.isoformat(),
                duration=result.duration,
                port=result.port,
                success=result.success,
                error_message=result.error_message,
                metrics_file=result.metrics_file,
                continuous_data_file=None,  # æŒç»­æ•°æ®æ–‡ä»¶è·¯å¾„
                config=config_dict,
                raw_metrics=raw_metrics,  # ä½¿ç”¨åŸå§‹æ•°æ®
                performance_summary=performance_summary
            )
            
            # ä¿å­˜åˆ°æ•°æ®ç®¡ç†å™¨
            saved_file = self.data_manager.save_test_data(test_data)
            console.print(f"[blue]ğŸ’¾ æµ‹è¯•æ•°æ®å·²ä¿å­˜: {saved_file}[/blue]")
            
        except Exception as e:
            console.print(f"[yellow]âš ï¸ ä¿å­˜æµ‹è¯•æ•°æ®å¤±è´¥: {e}[/yellow]")
    
    def _filter_invalid_metrics(self, raw_metrics: List[Dict[str, Any]], test_name: str) -> List[Dict[str, Any]]:
        """è¿‡æ»¤æ— æ•ˆçš„æŒ‡æ ‡æ•°æ®"""
        if not raw_metrics:
            return []
        
        console.print(f"[blue]ğŸ” å¼€å§‹è¿‡æ»¤ {test_name} çš„æ— æ•ˆæ•°æ®...[/blue]")
        
        filtered_metrics = []
        removed_count = 0
        
        for metric in raw_metrics:
            metric_name = metric.get('name', '')
            metric_value = metric.get('value', 0)
            help_text = metric.get('help_text', '')
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿‡æ»¤æ­¤æŒ‡æ ‡
            should_remove = False
            removal_reason = ""
            
            # 1. æ£€æŸ¥é›¶å€¼æŒ‡æ ‡
            if metric_name in self.invalid_data_patterns['zero_value_metrics'] and metric_value == 0:
                should_remove = True
                removal_reason = "é›¶å€¼æŒ‡æ ‡"
            
            # 2. æ£€æŸ¥Erlang VMç³»ç»ŸæŒ‡æ ‡
            elif any(metric_name.startswith(pattern) for pattern in self.invalid_data_patterns['erlang_vm_metrics']):
                should_remove = True
                removal_reason = "Erlang VMç³»ç»ŸæŒ‡æ ‡"
            
            # 3. æ£€æŸ¥ç›´æ–¹å›¾æ¡¶æ•°æ®ï¼ˆä¿ç•™æœ‰æ„ä¹‰çš„æ¡¶ï¼‰
            elif any(pattern in metric_name for pattern in self.invalid_data_patterns['histogram_buckets']):
                # åªä¿ç•™éé›¶å€¼çš„æ¡¶æ•°æ®
                if metric_value == 0:
                    should_remove = True
                    removal_reason = "é›¶å€¼ç›´æ–¹å›¾æ¡¶"
            
            # 4. æ£€æŸ¥é‡å¤çš„help_text
            elif help_text in self.invalid_data_patterns['redundant_help_text']:
                should_remove = True
                removal_reason = "é‡å¤çš„help_text"
            
            # 5. æ£€æŸ¥æ˜¯å¦æœ‰å®é™…æ„ä¹‰çš„æŒ‡æ ‡ï¼ˆä¿ç•™å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼‰
            if not should_remove:
                # ä¿ç•™å…³é”®æ€§èƒ½æŒ‡æ ‡
                key_metrics = [
                    'connect_succ', 'pub_succ', 'recv', 'publish_latency',
                    'mqtt_client_connect_duration', 'mqtt_client_handshake_duration',
                    'e2e_latency', 'mqtt_client_subscribe_duration'
                ]
                
                # å¦‚æœæ˜¯æŒ‡æ ‡åç§°åŒ…å«å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼Œæˆ–è€…å€¼ä¸ä¸º0ï¼Œåˆ™ä¿ç•™
                if (any(key_metric in metric_name for key_metric in key_metrics) or 
                    metric_value != 0 or 
                    'duration' in metric_name or 
                    'latency' in metric_name):
                    filtered_metrics.append(metric)
                else:
                    should_remove = True
                    removal_reason = "æ— å®é™…æ„ä¹‰çš„æŒ‡æ ‡"
            
            if should_remove:
                removed_count += 1
                if removed_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªè¢«ç§»é™¤çš„æŒ‡æ ‡
                    console.print(f"[dim]  âŒ ç§»é™¤ {metric_name}: {removal_reason} (å€¼: {metric_value})[/dim]")
            else:
                filtered_metrics.append(metric)
        
        console.print(f"[green]âœ… æ•°æ®è¿‡æ»¤å®Œæˆ: ä¿ç•™ {len(filtered_metrics)} ä¸ªæŒ‡æ ‡ï¼Œç§»é™¤ {removed_count} ä¸ªæ— æ•ˆæŒ‡æ ‡[/green]")
        
        return filtered_metrics
    
    def _save_filtered_data(self, test_result: TestResult, filtered_metrics: List[Dict[str, Any]]) -> str:
        """ä¿å­˜è¿‡æ»¤åçš„æ•°æ®åˆ°æ–°æ–‡ä»¶"""
        try:
            # åˆ›å»ºè¿‡æ»¤åçš„æ•°æ®ç»“æ„
            filtered_data = {
                "test_name": test_result.test_name,
                "test_type": getattr(test_result, 'test_type', 'Unknown'),
                "start_time": test_result.start_time.isoformat(),
                "end_time": test_result.end_time.isoformat(),
                "duration": test_result.duration,
                "port": test_result.port,
                "success": test_result.success,
                "error_message": test_result.error_message,
                "filtered_metrics": filtered_metrics,
                "filter_info": {
                    "original_count": len(getattr(test_result, 'raw_metrics', [])),
                    "filtered_count": len(filtered_metrics),
                    "removed_count": len(getattr(test_result, 'raw_metrics', [])) - len(filtered_metrics),
                    "filter_timestamp": datetime.now().isoformat()
                }
            }
            
            # ç”Ÿæˆè¿‡æ»¤åçš„æ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filtered_filename = f"filtered_{test_result.test_name}_{timestamp}.json"
            filtered_path = os.path.join("test_data", "filtered_data", filtered_filename)
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(filtered_path), exist_ok=True)
            
            # ä¿å­˜è¿‡æ»¤åçš„æ•°æ®
            with open(filtered_path, 'w', encoding='utf-8') as f:
                json.dump(filtered_data, f, indent=2, ensure_ascii=False)
            
            console.print(f"[green]ğŸ’¾ è¿‡æ»¤åçš„æ•°æ®å·²ä¿å­˜: {filtered_path}[/green]")
            return filtered_path
            
        except Exception as e:
            console.print(f"[red]âŒ ä¿å­˜è¿‡æ»¤æ•°æ®å¤±è´¥: {e}[/red]")
            return ""
    
    def _generate_performance_summary(self, raw_metrics: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æ‘˜è¦"""
        if not raw_metrics:
            return {}
        
        # æŒ‰æŒ‡æ ‡åç§°åˆ†ç»„
        metrics_by_name = {}
        for metric in raw_metrics:
            name = metric.get('name', '')
            if name not in metrics_by_name:
                metrics_by_name[name] = []
            metrics_by_name[name].append(metric.get('value', 0))
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        summary = {}
        for name, values in metrics_by_name.items():
            if values:
                summary[name] = {
                    'count': len(values),
                    'min': min(values),
                    'max': max(values),
                    'avg': sum(values) / len(values),
                    'latest': values[-1] if values else 0
                }
        
        return summary
    
    def _auto_filter_all_test_data(self):
        """è‡ªåŠ¨è¿‡æ»¤æ‰€æœ‰æµ‹è¯•æ•°æ®"""
        try:
            console.print("[blue]ğŸ” æ£€æŸ¥éœ€è¦è¿‡æ»¤çš„æµ‹è¯•æ•°æ®...[/blue]")
            
            # ç»Ÿè®¡è¿‡æ»¤ä¿¡æ¯
            total_tests = len(self.test_results)
            filtered_tests = 0
            total_original_metrics = 0
            total_filtered_metrics = 0
            total_removed_metrics = 0
            
            # å¤„ç†æ¯ä¸ªæµ‹è¯•ç»“æœ
            for result in self.test_results:
                if result.success and result.metrics_file:
                    console.print(f"[blue]ğŸ“Š å¤„ç†æµ‹è¯•: {result.test_name}[/blue]")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨è¿‡æ»¤åçš„æ–‡ä»¶
                    import glob
                    existing_files = glob.glob(f"test_data/filtered_data/filtered_{result.test_name}_*.json")
                    if existing_files:
                        console.print(f"[yellow]âš ï¸ è¿‡æ»¤æ–‡ä»¶å·²å­˜åœ¨: {existing_files[0]}[/yellow]")
                        console.print(f"[dim]è·³è¿‡é‡å¤è¿‡æ»¤: {result.test_name}[/dim]")
                        continue
                    
                    try:
                        # è¯»å–åŸå§‹æŒ‡æ ‡æ•°æ®
                        import json
                        with open(result.metrics_file, 'r', encoding='utf-8') as f:
                            raw_metrics = json.load(f)
                        
                        # ä½¿ç”¨æ–°çš„æµ‹è¯•ç‰¹å®šè¿‡æ»¤å™¨
                        filtered_metrics = self.test_filter.filter_test_data(result.test_name, raw_metrics)
                        
                        # ä¿å­˜è¿‡æ»¤åçš„æ•°æ®
                        filtered_file = self._save_filtered_data(result, filtered_metrics)
                        
                        if filtered_file:
                            filtered_tests += 1
                            original_count = len(raw_metrics)
                            filtered_count = len(filtered_metrics)
                            removed_count = original_count - filtered_count
                            
                            total_original_metrics += original_count
                            total_filtered_metrics += filtered_count
                            total_removed_metrics += removed_count
                            
                            reduction_percent = (removed_count / original_count * 100) if original_count > 0 else 0
                            
                            console.print(f"[green]âœ… {result.test_name} è¿‡æ»¤å®Œæˆ[/green]")
                            console.print(f"[dim]  â€¢ åŸå§‹æŒ‡æ ‡: {original_count}[/dim]")
                            console.print(f"[dim]  â€¢ è¿‡æ»¤åæŒ‡æ ‡: {filtered_count}[/dim]")
                            console.print(f"[dim]  â€¢ ç§»é™¤æŒ‡æ ‡: {removed_count} ({reduction_percent:.1f}%)[/dim]")
                            console.print(f"[dim]  â€¢ ä¿å­˜ä½ç½®: {filtered_file}[/dim]")
                        else:
                            console.print(f"[yellow]âš ï¸ {result.test_name} è¿‡æ»¤å¤±è´¥[/yellow]")
                            
                    except Exception as e:
                        console.print(f"[red]âŒ å¤„ç† {result.test_name} æ—¶å‡ºé”™: {e}[/red]")
            
            # æ˜¾ç¤ºæ€»ä½“è¿‡æ»¤ç»Ÿè®¡
            if filtered_tests > 0:
                total_reduction_percent = (total_removed_metrics / total_original_metrics * 100) if total_original_metrics > 0 else 0
                
                console.print(f"\n[green]ğŸ“Š æ•°æ®è¿‡æ»¤å®Œæˆç»Ÿè®¡:[/green]")
                console.print(f"[dim]  â€¢ å¤„ç†æµ‹è¯•æ•°é‡: {filtered_tests}/{total_tests}[/dim]")
                console.print(f"[dim]  â€¢ åŸå§‹æŒ‡æ ‡æ€»æ•°: {total_original_metrics}[/dim]")
                console.print(f"[dim]  â€¢ è¿‡æ»¤åæŒ‡æ ‡æ€»æ•°: {total_filtered_metrics}[/dim]")
                console.print(f"[dim]  â€¢ ç§»é™¤æŒ‡æ ‡æ€»æ•°: {total_removed_metrics}[/dim]")
                console.print(f"[dim]  â€¢ æ€»ä½“å‡å°‘æ¯”ä¾‹: {total_reduction_percent:.1f}%[/dim]")
                console.print(f"[dim]  â€¢ è¿‡æ»¤æ•°æ®ä¿å­˜ä½ç½®: test_data/filtered_data/[/dim]")
            else:
                console.print(f"[yellow]âš ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿‡æ»¤çš„æµ‹è¯•æ•°æ®[/yellow]")
                
        except Exception as e:
            console.print(f"[red]âŒ è‡ªåŠ¨æ•°æ®è¿‡æ»¤å¤±è´¥: {e}[/red]")
    
    def _auto_filter_continuous_metrics(self):
        """è‡ªåŠ¨è¿‡æ»¤æŒç»­æŒ‡æ ‡æ–‡ä»¶"""
        try:
            console.print("[blue]ğŸ” æ£€æŸ¥éœ€è¦è¿‡æ»¤çš„æŒç»­æŒ‡æ ‡æ–‡ä»¶...[/blue]")
            
            # ä½¿ç”¨æµ‹è¯•ç‰¹å®šè¿‡æ»¤å™¨å¤„ç†æŒç»­æŒ‡æ ‡æ–‡ä»¶
            # æ ¹æ®å½“å‰å·¥ä½œç›®å½•ç¡®å®šæ­£ç¡®çš„reportsç›®å½•
            if os.path.basename(os.getcwd()) == "metrics":
                reports_dir = "reports"
            else:
                reports_dir = "metrics/reports"
            filtered_files = self.test_filter.auto_filter_all_continuous_files(reports_dir)
            
            if filtered_files:
                console.print(f"[green]âœ… æŒç»­æŒ‡æ ‡è¿‡æ»¤å®Œæˆ![/green]")
                console.print(f"[blue]ğŸ“Š è¿‡æ»¤ç»Ÿè®¡:[/blue]")
                console.print(f"[dim]  â€¢ å¤„ç†æ–‡ä»¶æ•°: {len(filtered_files)}[/dim]")
                console.print(f"[dim]  â€¢ è¿‡æ»¤åæ–‡ä»¶ä¿å­˜åœ¨: metrics/reports/filtered/[/dim]")
                
                # æ˜¾ç¤ºè¿‡æ»¤åçš„æ–‡ä»¶åˆ—è¡¨
                for file_path in filtered_files:
                    console.print(f"[dim]  â€¢ {os.path.basename(file_path)}[/dim]")
            else:
                console.print("[yellow]âš ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿‡æ»¤çš„æŒç»­æŒ‡æ ‡æ–‡ä»¶[/yellow]")
                
        except Exception as e:
            console.print(f"[red]âŒ æŒç»­æŒ‡æ ‡è¿‡æ»¤å¤±è´¥: {e}[/red]")
            import traceback
            console.print(f"[dim]è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}[/dim]")
    
    def _build_connection_test_command(self, config: TestConfig) -> str:
        """æ„å»ºè¿æ¥æµ‹è¯•å‘½ä»¤"""
        cmd = f"{config.emqtt_bench_path} conn -h {config.host} -p {config.port} -c {config.client_count} -i 10"
        
        if config.use_huawei_auth:
            cmd += f" --prefix '{config.device_prefix}' -P '{config.huawei_secret}' --huawei-auth"
        
        cmd += f" --prometheus --restapi {config.prometheus_port} --qoe true"
        return cmd
    
    def _build_publish_test_command(self, config: TestConfig) -> str:
        """æ„å»ºå‘å¸ƒæµ‹è¯•å‘½ä»¤"""
        cmd = f"{config.emqtt_bench_path} pub -h {config.host} -p {config.port} -c {config.client_count} -i 10 -I {config.msg_interval} -q {config.qos}"
        
        if config.use_huawei_auth:
            template_path = get_huawei_template_path()
            cmd += f" -t '$oc/devices/%d/sys/properties/report' --prefix '{config.device_prefix}' -P '{config.huawei_secret}' --huawei-auth --message 'template://{template_path}'"
        else:
            cmd += " -t 'test/publish/%i'"
        
        cmd += f" --prometheus --restapi {config.prometheus_port + 1} --qoe true"
        return cmd
    
    def _build_subscribe_test_command(self, config: TestConfig) -> str:
        """æ„å»ºè®¢é˜…æµ‹è¯•å‘½ä»¤"""
        cmd = f"{config.emqtt_bench_path} sub -h {config.host} -p {config.port} -c {config.client_count} -i 10 -t 'test/subscribe/%i' -q {config.qos}"
        cmd += f" --prometheus --restapi {config.prometheus_port + 2} --qoe true"
        return cmd
    
    def _build_huawei_connection_test_command(self, config: TestConfig) -> str:
        """æ„å»ºåä¸ºäº‘è¿æ¥æµ‹è¯•å‘½ä»¤"""
        # ä¼˜åŒ–åä¸ºäº‘è¿æ¥æµ‹è¯•å‚æ•°
        cmd = f"{config.emqtt_bench_path} conn -h {config.host} -p {config.port} -c {config.client_count} -i 1"
        cmd += f" --prefix '{config.device_prefix}' -P '{config.huawei_secret}' --huawei-auth"
        cmd += f" --prometheus --restapi {config.prometheus_port} --qoe true"
        return cmd
    
    def _build_huawei_publish_test_command(self, config: TestConfig) -> str:
        """æ„å»ºåä¸ºäº‘å‘å¸ƒæµ‹è¯•å‘½ä»¤"""
        # ä¼˜åŒ–åä¸ºäº‘å‘å¸ƒæµ‹è¯•å‚æ•°
        cmd = f"{config.emqtt_bench_path} pub -h {config.host} -p {config.port} -c {config.client_count} -i 10 -I {config.msg_interval} "
        cmd += f" -t '$oc/devices/%d/sys/properties/report' --prefix '{config.device_prefix}' -P '{config.huawei_secret}' --huawei-auth"
        template_path = get_huawei_template_path()
        cmd += f" --message 'template://{template_path}' --prometheus --restapi {config.prometheus_port + 1} --qoe true"
        return cmd
    
    def _build_huawei_subscribe_test_command(self, config: TestConfig) -> str:
        """æ„å»ºåä¸ºäº‘è®¢é˜…æµ‹è¯•å‘½ä»¤ï¼ˆé›†æˆå¹¿æ’­å‘é€å’Œè®¢é˜…æµ‹è¯•ï¼‰"""
        # åä¸ºäº‘è®¢é˜…æµ‹è¯•éœ€è¦åŒæ—¶è¿è¡Œå¹¿æ’­å‘é€å’Œè®¢é˜…æµ‹è¯•
        # è¿”å›ä¸€ä¸ªç‰¹æ®Šçš„å‘½ä»¤æ ‡è¯†ï¼Œç”¨äºåœ¨_execute_single_testä¸­å¤„ç†
        return f"huawei_subscribe_test:{config.prometheus_port + 2}"
    
    def _build_huawei_broadcast_test_command(self, config: TestConfig) -> str:
        """æ„å»ºåä¸ºäº‘å¹¿æ’­æµ‹è¯•å‘½ä»¤ï¼ˆé›†æˆå¹¿æ’­å‘é€å’Œè®¢é˜…æµ‹è¯•ï¼‰"""
        # è¿™ä¸ªæµ‹è¯•å°†åŒæ—¶è¿è¡Œå¹¿æ’­å‘é€å’Œè®¢é˜…æµ‹è¯•
        # è¿”å›ä¸€ä¸ªç‰¹æ®Šçš„å‘½ä»¤æ ‡è¯†ï¼Œç”¨äºåœ¨_execute_single_testä¸­å¤„ç†
        return f"huawei_broadcast_test:{config.prometheus_port + 3}"
    
    def _execute_huawei_broadcast_test(self, task: Dict[str, Any], progress, task_progress) -> TestResult:
        """æ‰§è¡Œåä¸ºäº‘å¹¿æ’­æµ‹è¯•ï¼ˆé›†æˆå¹¿æ’­å‘é€å’Œè®¢é˜…æµ‹è¯•ï¼‰"""
        start_time = datetime.now()
        metrics_file = ""
        success = False
        error_message = ""
        
        try:
            console.print(f"[blue]ğŸš€ å¼€å§‹åä¸ºäº‘å¹¿æ’­æµ‹è¯•...[/blue]")
            
            # è·å–é…ç½®
            config = self.test_manager.config_manager.config
            
            # éªŒè¯åä¸ºäº‘å¹¿æ’­å‚æ•°
            missing_params = []
            if not hasattr(config, 'huawei_ak') or not config.huawei_ak:
                missing_params.append("åä¸ºäº‘è®¿é—®å¯†é’¥ID (AK)")
            if not hasattr(config, 'huawei_sk') or not config.huawei_sk:
                missing_params.append("åä¸ºäº‘è®¿é—®å¯†é’¥Secret (SK)")
            if not hasattr(config, 'huawei_endpoint') or not config.huawei_endpoint:
                missing_params.append("åä¸ºäº‘IoTDAç«¯ç‚¹")
            
            if missing_params:
                error_message = f"ç¼ºå°‘å¿…éœ€çš„åä¸ºäº‘å¹¿æ’­å‚æ•°: {', '.join(missing_params)}"
                console.print(f"[red]âŒ {error_message}[/red]")
                console.print("[yellow]ğŸ’¡ è¯·é‡æ–°è¿è¡Œé…ç½®ï¼Œç¡®ä¿æä¾›æ‰€æœ‰å¿…éœ€çš„åä¸ºäº‘å‚æ•°[/yellow]")
                return TestResult(
                    test_name=task['name'],
                    start_time=start_time,
                    end_time=datetime.now(),
                    duration=0,
                    port=task['port'],
                    metrics_file="",
                    success=False,
                    error_message=error_message
                )
            
            # æ˜¾ç¤ºä½¿ç”¨çš„å‚æ•°ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
            console.print(f"[blue]ğŸ“‹ ä½¿ç”¨åä¸ºäº‘å‚æ•°:[/blue]")
            console.print(f"[dim]  â€¢ AK: {config.huawei_ak[:8]}...[/dim]")
            console.print(f"[dim]  â€¢ SK: {'*' * len(config.huawei_sk)}[/dim]")
            console.print(f"[dim]  â€¢ ç«¯ç‚¹: {config.huawei_endpoint}[/dim]")
            console.print(f"[dim]  â€¢ åŒºåŸŸ: {getattr(config, 'huawei_region', 'cn-north-4')}[/dim]")
            console.print(f"[dim]  â€¢ å¹¿æ’­ä¸»é¢˜: {getattr(config, 'broadcast_topic', '$oc/broadcast/test')}[/dim]")
            
            # å…ˆå¯åŠ¨è®¢é˜…æµ‹è¯•ï¼Œç¡®ä¿è®¾å¤‡å·²ç»è®¢é˜…å¹¿æ’­ä¸»é¢˜
            console.print("[blue]ğŸ“¥ å¯åŠ¨è®¢é˜…æµ‹è¯•...[/blue]")
            subscribe_process = self._start_subscribe_test(config, task['port'])
            
            if not subscribe_process:
                error_message = "è®¢é˜…æµ‹è¯•å¯åŠ¨å¤±è´¥"
                console.print(f"[red]âŒ {error_message}[/red]")
                return TestResult(
                    test_name=task['name'],
                    start_time=start_time,
                    end_time=datetime.now(),
                    duration=0,
                    port=task['port'],
                    metrics_file="",
                    success=False,
                    error_message=error_message
                )
            
            # ç­‰å¾…è®¢é˜…æµ‹è¯•ç¨³å®šï¼Œç¡®ä¿è®¾å¤‡å·²ç»æˆåŠŸè®¢é˜…å¹¿æ’­ä¸»é¢˜
            console.print("[blue]â³ ç­‰å¾…è®¢é˜…æµ‹è¯•ç¨³å®š...[/blue]")
            time.sleep(5)  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿è®¢é˜…æˆåŠŸ
            
            # å¯åŠ¨å¹¿æ’­å‘é€å™¨
            console.print("[blue]ğŸ“¡ å¯åŠ¨å¹¿æ’­å‘é€å™¨...[/blue]")
            broadcast_process = self._start_broadcast_sender(config)
            
            if not broadcast_process:
                error_message = "å¹¿æ’­å‘é€å™¨å¯åŠ¨å¤±è´¥"
                console.print(f"[red]âŒ {error_message}[/red]")
                self._cleanup_process(subscribe_process)
                return TestResult(
                    test_name=task['name'],
                    start_time=start_time,
                    end_time=datetime.now(),
                    duration=0,
                    port=task['port'],
                    metrics_file="",
                    success=False,
                    error_message=error_message
                )
            
            # ç­‰å¾…å¹¿æ’­å‘é€å™¨ç¨³å®š
            console.print("[blue]â³ ç­‰å¾…å¹¿æ’­å‘é€å™¨ç¨³å®š...[/blue]")
            time.sleep(3)
            
            # å¯åŠ¨æŒç»­æŒ‡æ ‡æ”¶é›†
            console.print(f"[blue]ğŸ” å¯åŠ¨ {task['name']} æŒç»­æŒ‡æ ‡æ”¶é›†...[/blue]")
            self.continuous_collector.start_collection(
                test_name=task['name'],
                port=task['port'],
                interval=1.0
            )
            
            # ç­‰å¾…æµ‹è¯•å®Œæˆ
            console.print(f"[blue]â³ ç­‰å¾…æµ‹è¯•å®Œæˆ ({task['duration']}ç§’)...[/blue]")
            for i in range(task['duration']):
                if not self.running:
                    break
                
                # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                if broadcast_process.poll() is not None or subscribe_process.poll() is not None:
                    console.print("[yellow]âš ï¸ æ£€æµ‹åˆ°è¿›ç¨‹æå‰é€€å‡º[/yellow]")
                    break
                
                time.sleep(1)
                progress.update(task_progress, advance=1)
            
            # åœæ­¢æŒç»­æŒ‡æ ‡æ”¶é›†
            console.print(f"[blue]â¹ï¸ åœæ­¢ {task['name']} æŒç»­æŒ‡æ ‡æ”¶é›†...[/blue]")
            self.continuous_collector.stop_collection(task['name'])
            
            # ä¿å­˜æŒç»­æ”¶é›†çš„æ•°æ®
            continuous_data_file = self.continuous_collector.save_test_data(task['name'])
            if continuous_data_file:
                console.print(f"[green]ğŸ’¾ å·²ä¿å­˜ {task['name']} æŒç»­æŒ‡æ ‡æ•°æ®: {continuous_data_file}[/green]")
                self.continuous_data_files.append(continuous_data_file)
            
            # æ”¶é›†æŒ‡æ ‡
            metrics_file = self._collect_metrics(task['port'], task['name'])
            
            # æ¸…ç†è¿›ç¨‹
            console.print("[blue]ğŸ§¹ æ¸…ç†æµ‹è¯•è¿›ç¨‹...[/blue]")
            self._cleanup_process(broadcast_process)
            self._cleanup_process(subscribe_process)
            
            success = True
            console.print(f"[green]âœ… {task['name']} æµ‹è¯•å®Œæˆ[/green]")
            
        except Exception as e:
            error_message = str(e)
            console.print(f"[red]âŒ {task['name']} æ‰§è¡Œå¼‚å¸¸: {error_message}[/red]")
            success = False
        
        end_time = datetime.now()
        return TestResult(
            test_name=task['name'],
            start_time=start_time,
            end_time=end_time,
            duration=(end_time - start_time).total_seconds(),
            port=task['port'],
            metrics_file=metrics_file,
            success=success,
            error_message=error_message if not success else None
        )
    
    def _start_broadcast_sender(self, config):
        """å¯åŠ¨å¹¿æ’­å‘é€å™¨"""
        try:
            import subprocess
            import sys
            
            # æ„å»ºå¹¿æ’­å‘é€å‘½ä»¤
            cmd = [
                sys.executable, "broadcast.py",
                "--ak", config.huawei_ak,
                "--sk", config.huawei_sk,
                "--endpoint", config.huawei_endpoint,
                "--region", getattr(config, 'huawei_region', 'cn-north-4'),
                "--topic", getattr(config, 'broadcast_topic', '$oc/broadcast/test'),
                "--interval", str(getattr(config, 'broadcast_interval', 5)),
                "--duration", str(config.test_duration)
            ]
            
            console.print(f"[dim]å¹¿æ’­å‘é€å‘½ä»¤: {' '.join(cmd)}[/dim]")
            
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            console.print(f"[green]âœ… å¹¿æ’­å‘é€å™¨å·²å¯åŠ¨ (PID: {process.pid})[/green]")
            return process
            
        except Exception as e:
            console.print(f"[red]âŒ å¯åŠ¨å¹¿æ’­å‘é€å™¨å¤±è´¥: {e}[/red]")
            return None
    
    def _start_subscribe_test(self, config, port: int):
        """å¯åŠ¨åä¸ºäº‘è®¢é˜…æµ‹è¯•ï¼ˆä½¿ç”¨emqtt_benchå·¥å…·ï¼‰"""
        try:
            import subprocess
            import sys
            
            # æ„å»ºåä¸ºäº‘è®¢é˜…æµ‹è¯•å‘½ä»¤ï¼Œä½¿ç”¨emqtt_benchå·¥å…·
            cmd = f"{config.emqtt_bench_path} sub -h {config.host} -p {config.port} -c {config.client_count} -i 1 -q {config.qos}"
            cmd += f" -t '$oc/broadcast/test' --prefix '{config.device_prefix}' -P '{config.huawei_secret}' --huawei-auth"
            cmd += f" --prometheus --restapi {port} --qoe true"
            
            console.print(f"[dim]åä¸ºäº‘è®¢é˜…æµ‹è¯•å‘½ä»¤: {cmd}[/dim]")
            
            process = subprocess.Popen(
                cmd,
                shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            console.print(f"[green]âœ… åä¸ºäº‘è®¢é˜…æµ‹è¯•å·²å¯åŠ¨ (PID: {process.pid})[/green]")
            console.print(f"[dim]  æœåŠ¡å™¨: {config.host}:{config.port}[/dim]")
            console.print(f"[dim]  è®¾å¤‡å‰ç¼€: {config.device_prefix}[/dim]")
            console.print(f"[dim]  è®¢é˜…ä¸»é¢˜: $oc/broadcast/test[/dim]")
            console.print(f"[dim]  ç›‘å¬ç«¯å£: {port}[/dim]")
            
            return process
            
        except Exception as e:
            console.print(f"[red]âŒ å¯åŠ¨åä¸ºäº‘è®¢é˜…æµ‹è¯•å¤±è´¥: {e}[/red]")
            return None
    
    def _cleanup_process(self, process):
        """æ¸…ç†è¿›ç¨‹"""
        if process and process.poll() is None:
            try:
                process.terminate()
                process.wait(timeout=5)
                console.print(f"[green]âœ… è¿›ç¨‹ {process.pid} å·²ç»ˆæ­¢[/green]")
            except Exception as timeout_error:
                if "TimeoutExpired" in str(type(timeout_error)):
                    process.kill()
                    console.print(f"[yellow]âš ï¸ è¿›ç¨‹ {process.pid} å·²å¼ºåˆ¶ç»ˆæ­¢[/yellow]")
                else:
                    console.print(f"[red]âŒ æ¸…ç†è¿›ç¨‹å¤±è´¥: {timeout_error}[/red]")
    
    def _execute_huawei_subscribe_test(self, task: Dict[str, Any], progress, task_progress) -> TestResult:
        """æ‰§è¡Œåä¸ºäº‘è®¢é˜…æµ‹è¯•ï¼ˆé›†æˆå¹¿æ’­å‘é€å’Œè®¢é˜…æµ‹è¯•ï¼‰"""
        start_time = datetime.now()
        metrics_file = ""
        success = False
        error_message = ""
        
        try:
            console.print(f"[blue]ğŸš€ å¼€å§‹åä¸ºäº‘è®¢é˜…æµ‹è¯•...[/blue]")
            
            # è·å–é…ç½®
            config = self.test_manager.config_manager.config
            
            # éªŒè¯åä¸ºäº‘å¹¿æ’­å‚æ•°
            missing_params = []
            if not hasattr(config, 'huawei_ak') or not config.huawei_ak:
                missing_params.append("åä¸ºäº‘è®¿é—®å¯†é’¥ID (AK)")
            if not hasattr(config, 'huawei_sk') or not config.huawei_sk:
                missing_params.append("åä¸ºäº‘è®¿é—®å¯†é’¥Secret (SK)")
            if not hasattr(config, 'huawei_endpoint') or not config.huawei_endpoint:
                missing_params.append("åä¸ºäº‘IoTDAç«¯ç‚¹")
            
            if missing_params:
                error_message = f"ç¼ºå°‘å¿…éœ€çš„åä¸ºäº‘å¹¿æ’­å‚æ•°: {', '.join(missing_params)}"
                console.print(f"[red]âŒ {error_message}[/red]")
                console.print("[yellow]ğŸ’¡ è¯·é‡æ–°è¿è¡Œé…ç½®ï¼Œç¡®ä¿æä¾›æ‰€æœ‰å¿…éœ€çš„åä¸ºäº‘å‚æ•°[/yellow]")
                return TestResult(
                    test_name=task['name'],
                    start_time=start_time,
                    end_time=datetime.now(),
                    duration=0,
                    port=task['port'],
                    metrics_file="",
                    success=False,
                    error_message=error_message
                )
            
            # æ˜¾ç¤ºä½¿ç”¨çš„å‚æ•°ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
            console.print(f"[blue]ğŸ“‹ ä½¿ç”¨åä¸ºäº‘å‚æ•°:[/blue]")
            console.print(f"[dim]  â€¢ AK: {config.huawei_ak[:8]}...[/dim]")
            console.print(f"[dim]  â€¢ SK: {'*' * len(config.huawei_sk)}[/dim]")
            console.print(f"[dim]  â€¢ ç«¯ç‚¹: {config.huawei_endpoint}[/dim]")
            console.print(f"[dim]  â€¢ åŒºåŸŸ: {getattr(config, 'huawei_region', 'cn-north-4')}[/dim]")
            console.print(f"[dim]  â€¢ å¹¿æ’­ä¸»é¢˜: {getattr(config, 'broadcast_topic', '$oc/broadcast/test')}[/dim]")
            
            # å…ˆå¯åŠ¨è®¢é˜…æµ‹è¯•ï¼Œç¡®ä¿è®¾å¤‡å·²ç»è®¢é˜…å¹¿æ’­ä¸»é¢˜
            console.print("[blue]ğŸ“¥ å¯åŠ¨è®¢é˜…æµ‹è¯•...[/blue]")
            subscribe_process = self._start_subscribe_test(config, task['port'])
            
            if not subscribe_process:
                error_message = "è®¢é˜…æµ‹è¯•å¯åŠ¨å¤±è´¥"
                console.print(f"[red]âŒ {error_message}[/red]")
                return TestResult(
                    test_name=task['name'],
                    start_time=start_time,
                    end_time=datetime.now(),
                    duration=0,
                    port=task['port'],
                    metrics_file="",
                    success=False,
                    error_message=error_message
                )
            
            # ç­‰å¾…è®¢é˜…æµ‹è¯•ç¨³å®šï¼Œç¡®ä¿è®¾å¤‡å·²ç»æˆåŠŸè®¢é˜…å¹¿æ’­ä¸»é¢˜
            console.print("[blue]â³ ç­‰å¾…è®¢é˜…æµ‹è¯•ç¨³å®š...[/blue]")
            time.sleep(5)  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿è®¢é˜…æˆåŠŸ
            
            # å¯åŠ¨å¹¿æ’­å‘é€å™¨
            console.print("[blue]ğŸ“¡ å¯åŠ¨å¹¿æ’­å‘é€å™¨...[/blue]")
            broadcast_process = self._start_broadcast_sender(config)
            
            if not broadcast_process:
                error_message = "å¹¿æ’­å‘é€å™¨å¯åŠ¨å¤±è´¥"
                console.print(f"[red]âŒ {error_message}[/red]")
                self._cleanup_process(subscribe_process)
                return TestResult(
                    test_name=task['name'],
                    start_time=start_time,
                    end_time=datetime.now(),
                    duration=0,
                    port=task['port'],
                    metrics_file="",
                    success=False,
                    error_message=error_message
                )
            
            # ç­‰å¾…å¹¿æ’­å‘é€å™¨ç¨³å®š
            console.print("[blue]â³ ç­‰å¾…å¹¿æ’­å‘é€å™¨ç¨³å®š...[/blue]")
            time.sleep(3)
            
            # å¯åŠ¨æŒç»­æŒ‡æ ‡æ”¶é›†
            console.print(f"[blue]ğŸ” å¯åŠ¨ {task['name']} æŒç»­æŒ‡æ ‡æ”¶é›†...[/blue]")
            self.continuous_collector.start_collection(
                test_name=task['name'],
                port=task['port'],
                interval=1.0
            )
            
            # ç­‰å¾…æµ‹è¯•å®Œæˆ
            console.print(f"[blue]â³ ç­‰å¾…æµ‹è¯•å®Œæˆ ({task['duration']}ç§’)...[/blue]")
            for i in range(task['duration']):
                if not self.running:
                    break
                
                # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                if broadcast_process.poll() is not None or subscribe_process.poll() is not None:
                    console.print("[yellow]âš ï¸ æ£€æµ‹åˆ°è¿›ç¨‹æå‰é€€å‡º[/yellow]")
                    break
                
                time.sleep(1)
                progress.update(task_progress, advance=1)
            
            # åœæ­¢æŒç»­æŒ‡æ ‡æ”¶é›†
            console.print(f"[blue]â¹ï¸ åœæ­¢ {task['name']} æŒç»­æŒ‡æ ‡æ”¶é›†...[/blue]")
            self.continuous_collector.stop_collection(task['name'])
            
            # ä¿å­˜æŒç»­æ”¶é›†çš„æ•°æ®
            continuous_data_file = self.continuous_collector.save_test_data(task['name'])
            if continuous_data_file:
                console.print(f"[green]ğŸ’¾ å·²ä¿å­˜ {task['name']} æŒç»­æŒ‡æ ‡æ•°æ®: {continuous_data_file}[/green]")
                self.continuous_data_files.append(continuous_data_file)
            
            # æ”¶é›†æŒ‡æ ‡
            metrics_file = self._collect_metrics(task['port'], task['name'])
            
            # æ¸…ç†è¿›ç¨‹
            console.print("[blue]ğŸ§¹ æ¸…ç†æµ‹è¯•è¿›ç¨‹...[/blue]")
            self._cleanup_process(broadcast_process)
            self._cleanup_process(subscribe_process)
            
            success = True
            console.print(f"[green]âœ… {task['name']} æµ‹è¯•å®Œæˆ[/green]")
            
        except Exception as e:
            error_message = str(e)
            console.print(f"[red]âŒ {task['name']} æ‰§è¡Œå¼‚å¸¸: {error_message}[/red]")
            success = False
        
        end_time = datetime.now()
        return TestResult(
            test_name=task['name'],
            start_time=start_time,
            end_time=end_time,
            duration=(end_time - start_time).total_seconds(),
            port=task['port'],
            metrics_file=metrics_file,
            success=success,
            error_message=error_message if not success else None
        )
    
    def _execute_single_test(self, task: Dict[str, Any], progress, task_progress) -> TestResult:
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•"""
        start_time = datetime.now()
        metrics_file = ""
        process = None
        success = False
        error_message = ""
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºåä¸ºäº‘å¹¿æ’­æµ‹è¯•
        if task['command'].startswith('huawei_broadcast_test:'):
            return self._execute_huawei_broadcast_test(task, progress, task_progress)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºåä¸ºäº‘è®¢é˜…æµ‹è¯•
        if task['command'].startswith('huawei_subscribe_test:'):
            return self._execute_huawei_subscribe_test(task, progress, task_progress)
        
        try:
            # æ£€æŸ¥ç«¯å£å¯ç”¨æ€§
            if not self._check_port_availability(task['port']):
                console.print(f"[yellow]âš ï¸ ç«¯å£ {task['port']} è¢«å ç”¨ï¼Œå°è¯•é‡Šæ”¾...[/yellow]")
                if self._kill_process_on_port(task['port']):
                    time.sleep(2)  # ç­‰å¾…è¿›ç¨‹å®Œå…¨ç»ˆæ­¢
                    if not self._check_port_availability(task['port']):
                        # å¦‚æœç«¯å£ä»ç„¶è¢«å ç”¨ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–ç«¯å£
                        new_port = self._find_available_port(task['port'])
                        if new_port != task['port']:
                            console.print(f"[yellow]âš ï¸ ä½¿ç”¨æ›¿ä»£ç«¯å£: {new_port}[/yellow]")
                            # æ›´æ–°å‘½ä»¤ä¸­çš„ç«¯å£
                            task['command'] = task['command'].replace(f"--restapi {task['port']}", f"--restapi {new_port}")
                            task['port'] = new_port
                        else:
                            error_message = f"æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œç«¯å£ {task['port']} è¢«å ç”¨"
                            console.print(f"[red]âŒ {error_message}[/red]")
                            success = False
                            end_time = datetime.now()
                            return TestResult(
                                test_name=task['name'],
                                start_time=start_time,
                                end_time=end_time,
                                duration=(end_time - start_time).total_seconds(),
                                port=task['port'],
                                metrics_file="",
                                success=False,
                                error_message=error_message
                            )
            
            # å¯åŠ¨æµ‹è¯•è¿›ç¨‹
            process = self.test_manager.process_manager.start_process(
                task['command'], 
                task['name']
            )
            
            # ç­‰å¾…è¿›ç¨‹å¯åŠ¨å¹¶ç¨³å®š
            time.sleep(3)
            
            # å¯åŠ¨æŒç»­æŒ‡æ ‡æ”¶é›†
            console.print(f"[blue]ğŸ” å¯åŠ¨ {task['name']} æŒç»­æŒ‡æ ‡æ”¶é›†...[/blue]")
            self.continuous_collector.start_collection(
                test_name=task['name'],
                port=task['port'],
                interval=1.0  # æ¯ç§’æ”¶é›†ä¸€æ¬¡
            )
            
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œ
            if process.poll() is not None:
                # è¿›ç¨‹å·²ç»é€€å‡ºï¼Œè·å–é”™è¯¯ä¿¡æ¯
                stdout, stderr = process.communicate()
                error_output = stderr.decode('utf-8', errors='ignore') if stderr else ""
                stdout_output = stdout.decode('utf-8', errors='ignore') if stdout else ""
                
                # åˆ†æé”™è¯¯ä¿¡æ¯
                if "eaddrinuse" in error_output.lower():
                    error_message = f"ç«¯å£ {task['port']} è¢«å ç”¨ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–è¿›ç¨‹åœ¨ä½¿ç”¨è¯¥ç«¯å£"
                elif "malformed_username_or_password" in error_output.lower():
                    error_message = "åä¸ºäº‘è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥è®¾å¤‡IDå’Œå¯†é’¥é…ç½®"
                elif "connection" in error_output.lower() and "error" in error_output.lower():
                    error_message = f"è¿æ¥é”™è¯¯: {error_output.strip()}"
                else:
                    error_message = f"è¿›ç¨‹å¼‚å¸¸é€€å‡º: {error_output.strip() or stdout_output.strip()}"
                
                console.print(f"[red]âŒ {task['name']} è¿›ç¨‹å¼‚å¸¸é€€å‡º: {error_message}[/red]")
                success = False
            else:
                # è¿›ç¨‹æ­£å¸¸è¿è¡Œï¼Œæ”¶é›†æŒ‡æ ‡æ•°æ®
                metrics_file = self._collect_metrics(task['port'], task['name'])
                
                # ç»§ç»­ç­‰å¾…æµ‹è¯•å®Œæˆï¼ŒåŒæ—¶ç›‘æ§è¿›ç¨‹çŠ¶æ€
                remaining_time = max(0, task['duration'] - 3)
                for i in range(int(remaining_time)):
                    if not self.running:
                        self.test_manager.process_manager.terminate_process(process)
                        break
                    
                    # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                    if process.poll() is not None:
                        # è¿›ç¨‹æå‰é€€å‡º
                        stdout, stderr = process.communicate()
                        error_output = stderr.decode('utf-8', errors='ignore') if stderr else ""
                        if error_output:
                            error_message = f"è¿›ç¨‹æå‰é€€å‡º: {error_output.strip()}"
                            console.print(f"[red]âŒ {task['name']} è¿›ç¨‹æå‰é€€å‡º: {error_message}[/red]")
                        success = False
                        break
                    
                    time.sleep(1)
                    progress.update(task_progress, advance=1)
                
                # åœæ­¢æŒç»­æŒ‡æ ‡æ”¶é›†
                console.print(f"[blue]â¹ï¸ åœæ­¢ {task['name']} æŒç»­æŒ‡æ ‡æ”¶é›†...[/blue]")
                self.continuous_collector.stop_collection(task['name'])
                
                # ä¿å­˜æŒç»­æ”¶é›†çš„æ•°æ®
                continuous_data_file = self.continuous_collector.save_test_data(task['name'])
                if continuous_data_file:
                    console.print(f"[green]ğŸ’¾ å·²ä¿å­˜ {task['name']} æŒç»­æŒ‡æ ‡æ•°æ®: {continuous_data_file}[/green]")
                    self.continuous_data_files.append(continuous_data_file)
                
                # å¦‚æœè¿›ç¨‹ä»åœ¨è¿è¡Œï¼Œè®¤ä¸ºæµ‹è¯•æˆåŠŸ
                if process.poll() is None:
                    success = True
                    console.print(f"[green]âœ… {task['name']} æµ‹è¯•å®Œæˆ[/green]")
                else:
                    # è¿›ç¨‹å·²é€€å‡ºï¼Œæ£€æŸ¥é€€å‡ºç 
                    return_code = process.returncode
                    if return_code != 0:
                        stdout, stderr = process.communicate()
                        error_output = stderr.decode('utf-8', errors='ignore') if stderr else ""
                        error_message = f"è¿›ç¨‹å¼‚å¸¸é€€å‡º (é€€å‡ºç : {return_code}): {error_output.strip()}"
                        console.print(f"[red]âŒ {task['name']} æµ‹è¯•å¤±è´¥: {error_message}[/red]")
                        success = False
                    else:
                        success = True
                        console.print(f"[green]âœ… {task['name']} æµ‹è¯•æˆåŠŸå®Œæˆ[/green]")
            
            end_time = datetime.now()
            
            return TestResult(
                test_name=task['name'],
                start_time=start_time,
                end_time=end_time,
                duration=(end_time - start_time).total_seconds(),
                port=task['port'],
                metrics_file=metrics_file,
                success=success,
                error_message=error_message if not success else None
            )
            
        except Exception as e:
            end_time = datetime.now()
            error_message = str(e)
            console.print(f"[red]âŒ {task['name']} æ‰§è¡Œå¼‚å¸¸: {error_message}[/red]")
            
            return TestResult(
                test_name=task['name'],
                start_time=start_time,
                end_time=end_time,
                duration=(end_time - start_time).total_seconds(),
                port=task['port'],
                metrics_file=metrics_file,
                success=False,
                error_message=error_message
            )
        finally:
            # ç¡®ä¿è¿›ç¨‹åœ¨æµ‹è¯•å®Œæˆåè¢«æ­£ç¡®æ¸…ç†
            if process is not None:
                try:
                    if process.poll() is None:  # è¿›ç¨‹ä»åœ¨è¿è¡Œ
                        console.print(f"[yellow]ğŸ§¹ æ¸…ç†æµ‹è¯•è¿›ç¨‹ {process.pid} å’Œç«¯å£ {task['port']}...[/yellow]")
                        self.test_manager.process_manager.terminate_process(process)
                        
                        # ç­‰å¾…è¿›ç¨‹å®Œå…¨ç»ˆæ­¢
                        time.sleep(2)
                        
                        # éªŒè¯ç«¯å£æ˜¯å¦å·²é‡Šæ”¾
                        if not self._check_port_availability(task['port']):
                            console.print(f"[yellow]âš ï¸ ç«¯å£ {task['port']} ä»è¢«å ç”¨ï¼Œå°è¯•å¼ºåˆ¶æ¸…ç†...[/yellow]")
                            self._kill_process_on_port(task['port'])
                            time.sleep(1)
                            
                            # å†æ¬¡éªŒè¯
                            if self._check_port_availability(task['port']):
                                console.print(f"[green]âœ… ç«¯å£ {task['port']} å·²æˆåŠŸé‡Šæ”¾[/green]")
                            else:
                                console.print(f"[red]âŒ ç«¯å£ {task['port']} ä»è¢«å ç”¨ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ¸…ç†[/red]")
                        else:
                            console.print(f"[green]âœ… ç«¯å£ {task['port']} å·²æˆåŠŸé‡Šæ”¾[/green]")
                    else:
                        console.print(f"[green]âœ… æµ‹è¯•è¿›ç¨‹å·²è‡ªç„¶é€€å‡º[/green]")
                except Exception as cleanup_error:
                    console.print(f"[red]âŒ æ¸…ç†è¿›ç¨‹æ—¶å‘ç”Ÿé”™è¯¯: {cleanup_error}[/red]")
                    # å°è¯•å¼ºåˆ¶æ¸…ç†ç«¯å£
                    try:
                        self._kill_process_on_port(task['port'])
                    except Exception:
                        pass
    
    def _collect_metrics(self, port: int, test_name: str) -> str:
        """æ”¶é›†æŒ‡æ ‡æ•°æ®"""
        max_retries = 3
        retry_delay = 2
        
        for attempt in range(max_retries):
            try:
                console.print(f"[blue]ğŸ” å°è¯•æ”¶é›† {test_name} æŒ‡æ ‡ (å°è¯• {attempt + 1}/{max_retries})...[/blue]")
                
                # ç­‰å¾…æŒ‡æ ‡ç¨³å®š
                time.sleep(retry_delay)
                
                # æ”¶é›†æŒ‡æ ‡
                metrics = self.metrics_collector.fetch_metrics(port)
                
                if metrics:
                    # ç¡®ä¿reportsç›®å½•å­˜åœ¨
                    import os
                    os.makedirs("reports", exist_ok=True)
                    
                    # ä¿å­˜æŒ‡æ ‡æ–‡ä»¶åˆ°reportsæ–‡ä»¶å¤¹
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    metrics_file = f"metrics_{test_name.lower().replace(' ', '_')}_{timestamp}.json"
                    metrics_path = os.path.join("reports", metrics_file)
                    
                    # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
                    metrics_data = []
                    for metric in metrics:
                        metrics_data.append({
                            'timestamp': metric.timestamp,
                            'name': metric.name,
                            'value': metric.value,
                            'labels': metric.labels,
                            'help_text': metric.help_text,
                            'metric_type': metric.metric_type
                        })
                    
                    # ä¿å­˜åˆ°æ–‡ä»¶
                    import json
                    with open(metrics_path, 'w', encoding='utf-8') as f:
                        json.dump(metrics_data, f, indent=2, ensure_ascii=False)
                    
                    console.print(f"[green]âœ… æŒ‡æ ‡å·²ä¿å­˜: {metrics_path} (æ”¶é›†åˆ° {len(metrics)} ä¸ªæŒ‡æ ‡)[/green]")
                    return metrics_path
                else:
                    console.print(f"[yellow]âš ï¸ ç¬¬ {attempt + 1} æ¬¡å°è¯•æœªæ”¶é›†åˆ° {test_name} çš„æŒ‡æ ‡æ•°æ®[/yellow]")
                    if attempt < max_retries - 1:
                        console.print(f"[dim]ç­‰å¾… {retry_delay} ç§’åé‡è¯•...[/dim]")
                    
            except Exception as e:
                console.print(f"[red]âŒ ç¬¬ {attempt + 1} æ¬¡å°è¯•æ”¶é›† {test_name} æŒ‡æ ‡å¤±è´¥: {e}[/red]")
                if attempt < max_retries - 1:
                    console.print(f"[dim]ç­‰å¾… {retry_delay} ç§’åé‡è¯•...[/dim]")
        
        console.print(f"[red]âŒ ç»è¿‡ {max_retries} æ¬¡å°è¯•ï¼Œæ— æ³•æ”¶é›† {test_name} çš„æŒ‡æ ‡æ•°æ®[/red]")
        return ""
    
    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        console.print("\n" + "="*80)
        console.print("ğŸ“Š [bold blue]eMQTT-Bench æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ[/bold blue]")
        console.print("="*80)
        console.print("ğŸ¯ [dim]æ­£åœ¨ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«æ‰€æœ‰å…³é”®æŒ‡æ ‡å’Œæ€§èƒ½è¯„ä¼°...[/dim]")
        console.print("")
        
        try:
            # åˆ›å»ºæ—¶é—´æˆ³æŠ¥å‘Šç›®å½•
            timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
            self.current_report_dir = f"reports/{timestamp}"
            os.makedirs(self.current_report_dir, exist_ok=True)
            console.print(f"[blue]ğŸ“ åˆ›å»ºæŠ¥å‘Šç›®å½•: {self.current_report_dir}[/blue]")
            
            # è‡ªåŠ¨æ‰§è¡Œæ•°æ®è¿‡æ»¤æ“ä½œ
            console.print("[blue]ğŸ§¹ è‡ªåŠ¨æ‰§è¡Œæ•°æ®è¿‡æ»¤æ“ä½œ...[/blue]")
            self._auto_filter_all_test_data()
            
            # è‡ªåŠ¨è¿‡æ»¤æŒç»­æŒ‡æ ‡æ–‡ä»¶
            console.print("[blue]ğŸ§¹ è‡ªåŠ¨è¿‡æ»¤æŒç»­æŒ‡æ ‡æ–‡ä»¶...[/blue]")
            self._auto_filter_continuous_metrics()
            
            # ç”ŸæˆHTMLæŠ¥å‘Š
            console.print("[blue]ğŸ“„ ç”ŸæˆHTMLå¯è§†åŒ–æŠ¥å‘Š...[/blue]")
            html_report_file = self._generate_html_report()
            
            # ç”ŸæˆMarkdownè¯¦ç»†åˆ†ææŠ¥å‘Š
            console.print("[blue]ğŸ“ ç”ŸæˆMarkdownè¯¦ç»†åˆ†ææŠ¥å‘Š...[/blue]")
            markdown_report_file = self._generate_markdown_report()
            
            # ç”Ÿæˆå¢å¼ºç‰ˆæŒç»­æ•°æ®åˆ†ææŠ¥å‘Š
            if self.continuous_data_files:
                console.print("[blue]ğŸ“Š ç”Ÿæˆå¢å¼ºç‰ˆæŒç»­æ•°æ®åˆ†ææŠ¥å‘Š...[/blue]")
                enhanced_report_file = self.enhanced_generator.generate_continuous_analysis_report(
                    continuous_data_files=self.continuous_data_files,
                    test_results=self.test_results,
                    start_time=self.start_time
                )
                console.print(f"[green]âœ… å¢å¼ºç‰ˆæŒç»­æ•°æ®åˆ†ææŠ¥å‘Š: {enhanced_report_file}[/green]")
            else:
                console.print("[yellow]âš ï¸ æ— æŒç»­æ•°æ®æ–‡ä»¶ï¼Œè·³è¿‡å¢å¼ºç‰ˆæŠ¥å‘Šç”Ÿæˆ[/yellow]")
            
            # ç”Ÿæˆæ•°æ®ç®¡ç†æŠ¥å‘Š
            console.print("[blue]ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®ç®¡ç†æŠ¥å‘Š...[/blue]")
            data_report_file = self.data_manager.generate_data_report(report_dir=self.current_report_dir)
            console.print(f"[green]âœ… æµ‹è¯•æ•°æ®ç®¡ç†æŠ¥å‘Š: {data_report_file}[/green]")
            
            # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
            self._show_report_summary()
            
            # æ˜¾ç¤ºæŠ¥å‘Šç”Ÿæˆå®Œæˆä¿¡æ¯
            console.print("\n" + "="*80)
            console.print("ğŸ‰ [bold green]æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼[/bold green]")
            console.print("="*80)
            
            # åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶æ±‡æ€»è¡¨æ ¼
            report_summary_table = Table(title="ğŸ“‹ ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶", show_header=True, header_style="bold magenta")
            report_summary_table.add_column("æŠ¥å‘Šç±»å‹", style="cyan", width=20)
            report_summary_table.add_column("æ–‡ä»¶è·¯å¾„", style="green", width=50)
            report_summary_table.add_column("çŠ¶æ€", style="yellow", width=10)
            
            report_summary_table.add_row("HTMLå¯è§†åŒ–æŠ¥å‘Š", html_report_file, "âœ… å·²ç”Ÿæˆ")
            report_summary_table.add_row("Markdownè¯¦ç»†åˆ†æ", markdown_report_file, "âœ… å·²ç”Ÿæˆ")
            report_summary_table.add_row("æµ‹è¯•æ•°æ®ç®¡ç†æŠ¥å‘Š", data_report_file, "âœ… å·²ç”Ÿæˆ")
            
            console.print(report_summary_table)
            
            # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
            console.print(f"\n[bold]ğŸ“Š æ•°æ®ç»Ÿè®¡æ‘˜è¦:[/bold]")
            console.print(f"   ğŸ“ æŒ‡æ ‡æ–‡ä»¶æ•°é‡: [blue]{len([r for r in self.test_results if r.metrics_file])} ä¸ª[/blue]")
            console.print(f"   ğŸ“‚ æŠ¥å‘Šä¿å­˜ä½ç½®: [blue]{self.current_report_dir}/ æ–‡ä»¶å¤¹[/blue]")
            console.print(f"   ğŸ’¾ æµ‹è¯•æ•°æ®ä¿å­˜ä½ç½®: [blue]test_data/ æ–‡ä»¶å¤¹[/blue]")
            console.print(f"   ğŸ§¹ è¿‡æ»¤æ•°æ®ä¿å­˜ä½ç½®: [blue]test_data/filtered_data/ æ–‡ä»¶å¤¹[/blue]")
            console.print(f"   â±ï¸ æ€»è€—æ—¶: [blue]{(datetime.now() - self.start_time).total_seconds():.1f} ç§’[/blue]")
            
            # æ˜¾ç¤ºä½¿ç”¨å»ºè®®
            console.print(f"\n[bold]ğŸ’¡ ä½¿ç”¨å»ºè®®:[/bold]")
            console.print(f"   ğŸŒ åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæŠ¥å‘ŠæŸ¥çœ‹å¯è§†åŒ–å›¾è¡¨")
            console.print(f"   ğŸ“ æŸ¥çœ‹MarkdownæŠ¥å‘Šè·å–è¯¦ç»†åˆ†æ")
            console.print(f"   ğŸ“Š ä½¿ç”¨æ•°æ®ç®¡ç†æŠ¥å‘Šäº†è§£æµ‹è¯•æ•°æ®è¯¦æƒ…")
            console.print(f"   ğŸ” æ‰€æœ‰åŸå§‹æ•°æ®å·²ä¿å­˜åœ¨test_dataç›®å½•ä¸­")
            
        except Exception as e:
            console.print(f"[red]âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}[/red]")
            # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
            import traceback
            console.print(f"[dim]è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}[/dim]")
    
    def _generate_html_report(self) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆHTMLæŠ¥å‘Š"""
        # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡æ•°æ®
        all_metrics_data = self._collect_all_metrics_data()
        
        # ä½¿ç”¨å¢å¼ºç‰ˆæŠ¥å‘Šç”Ÿæˆå™¨ï¼ŒæŒ‡å®šæŠ¥å‘Šä¿å­˜åˆ°æ—¶é—´æˆ³ç›®å½•
        from enhanced_report_generator import EnhancedReportGenerator
        report_generator = EnhancedReportGenerator(
            test_results=self.test_results,
            all_metrics_data=all_metrics_data,
            start_time=self.start_time,
            reports_dir=self.current_report_dir
        )
        
        report_file = report_generator.generate_enhanced_report()
        return report_file
    
    def _generate_markdown_report(self) -> str:
        """ç”ŸæˆMarkdownè¯¦ç»†åˆ†ææŠ¥å‘Š"""
        # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡æ•°æ®
        all_metrics_data = self._collect_all_metrics_data()
        
        # ä½¿ç”¨MarkdownæŠ¥å‘Šç”Ÿæˆå™¨
        from simple_markdown_generator import MarkdownReportGenerator
        markdown_generator = MarkdownReportGenerator(
            test_results=self.test_results,
            all_metrics_data=all_metrics_data,
            start_time=self.start_time,
            reports_dir=self.current_report_dir
        )
        
        markdown_file = markdown_generator.generate_markdown_report()
        return markdown_file
    
    def _collect_all_metrics_data(self) -> Dict[str, Any]:
        """æ”¶é›†æ‰€æœ‰æµ‹è¯•çš„æŒ‡æ ‡æ•°æ®"""
        all_metrics_data = {}
        
        for result in self.test_results:
            if result.metrics_file and result.success:
                try:
                    import json
                    with open(result.metrics_file, 'r', encoding='utf-8') as f:
                        metrics_data = json.load(f)
                    
                    all_metrics_data[result.test_name] = {
                        'test_info': {
                            'port': result.port,
                            'duration': result.duration,
                            'start_time': result.start_time.isoformat(),
                            'end_time': result.end_time.isoformat(),
                            'metrics_file': result.metrics_file
                        },
                        'metrics': metrics_data
                    }
                except Exception as e:
                    console.print(f"[yellow]âš ï¸ æ— æ³•è¯»å– {result.metrics_file}: {e}[/yellow]")
                    all_metrics_data[result.test_name] = {
                        'test_info': {
                            'port': result.port,
                            'duration': result.duration,
                            'start_time': result.start_time.isoformat(),
                            'end_time': result.end_time.isoformat(),
                            'metrics_file': result.metrics_file
                        },
                        'metrics': []
                    }
            else:
                all_metrics_data[result.test_name] = {
                    'test_info': {
                        'port': result.port,
                        'duration': result.duration,
                        'start_time': result.start_time.isoformat(),
                        'end_time': result.end_time.isoformat(),
                        'metrics_file': result.metrics_file
                    },
                    'metrics': []
                }
        
        return all_metrics_data
    
    def _show_report_summary(self):
        """æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦"""
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r.success])
        failed_tests = total_tests - successful_tests
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        console.print("\n" + "="*80)
        console.print("ğŸ“Š [bold blue]æµ‹è¯•æ‰§è¡Œæ‘˜è¦[/bold blue]")
        console.print("="*80)
        
        # åŸºæœ¬æ‘˜è¦è¡¨æ ¼
        table = Table(title="ğŸ“Š æµ‹è¯•æ‰§è¡Œç»Ÿè®¡", show_header=True, header_style="bold magenta")
        table.add_column("ç»Ÿè®¡é¡¹ç›®", style="cyan", width=20)
        table.add_column("æ•°å€¼", style="green", width=15)
        table.add_column("çŠ¶æ€", style="yellow", width=15)
        table.add_column("è¯´æ˜", style="dim", width=30)
        
        table.add_row("æ€»æµ‹è¯•æ•°", str(total_tests), "ğŸ“Š æµ‹è¯•", "æ‰§è¡Œçš„æµ‹è¯•é¡¹ç›®æ€»æ•°")
        table.add_row("æˆåŠŸæµ‹è¯•", str(successful_tests), "âœ… æˆåŠŸ" if successful_tests > 0 else "âŒ æ— æˆåŠŸ", "æˆåŠŸå®Œæˆçš„æµ‹è¯•æ•°é‡")
        table.add_row("å¤±è´¥æµ‹è¯•", str(failed_tests), "âš ï¸ éœ€å…³æ³¨" if failed_tests > 0 else "âœ… æ— å¤±è´¥", "æ‰§è¡Œå¤±è´¥çš„æµ‹è¯•æ•°é‡")
        table.add_row("æˆåŠŸç‡", f"{success_rate:.1f}%", "ğŸŸ¢ ä¼˜ç§€" if success_rate >= 90 else "ğŸŸ¡ è‰¯å¥½" if success_rate >= 70 else "ğŸ”´ éœ€æ”¹è¿›", "æµ‹è¯•æ‰§è¡ŒæˆåŠŸç‡")
        table.add_row("æ€»è€—æ—¶", f"{(datetime.now() - self.start_time).total_seconds():.1f} ç§’", "â±ï¸ æ—¶é—´", "ä»å¼€å§‹åˆ°ç»“æŸçš„æ€»æ—¶é—´")
        table.add_row("æŒ‡æ ‡æ–‡ä»¶", str(len([r for r in self.test_results if r.metrics_file])), "ğŸ“ æ•°æ®", "æ”¶é›†åˆ°çš„æŒ‡æ ‡æ–‡ä»¶æ•°é‡")
        
        console.print(table)
        
        # è¯¦ç»†æµ‹è¯•ç»“æœå±•ç¤º
        if self.test_results:
            console.print("\n" + "="*80)
            console.print("ğŸ“‹ [bold blue]è¯¦ç»†æµ‹è¯•ç»“æœ[/bold blue]")
            console.print("="*80)
            
            # åˆ›å»ºè¯¦ç»†æµ‹è¯•ç»“æœè¡¨æ ¼
            detailed_table = Table(title="ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ", show_header=True, header_style="bold magenta")
            detailed_table.add_column("åºå·", style="cyan", width=6)
            detailed_table.add_column("æµ‹è¯•åç§°", style="green", width=20)
            detailed_table.add_column("çŠ¶æ€", style="yellow", width=10)
            detailed_table.add_column("ç«¯å£", style="blue", width=8)
            detailed_table.add_column("æŒç»­æ—¶é—´", style="magenta", width=12)
            detailed_table.add_column("æŒ‡æ ‡æ–‡ä»¶", style="red", width=15)
            
            for i, result in enumerate(self.test_results, 1):
                status_icon = "âœ… æˆåŠŸ" if result.success else "âŒ å¤±è´¥"
                metrics_status = "âœ… æœ‰" if result.metrics_file else "âŒ æ— "
                
                detailed_table.add_row(
                    str(i),
                    result.test_name,
                    status_icon,
                    str(result.port),
                    f"{result.duration:.1f}s",
                    metrics_status
                )
            
            console.print(detailed_table)
            
            # æ˜¾ç¤ºæ¯ä¸ªæµ‹è¯•çš„è¯¦ç»†ä¿¡æ¯
            for i, result in enumerate(self.test_results, 1):
                status_icon = "âœ…" if result.success else "âŒ"
                status_color = "green" if result.success else "red"
                
                console.print(f"\n[bold]{i}. {result.test_name}[/bold] {status_icon}")
                console.print(f"   [dim]ç«¯å£:[/dim] {result.port}")
                console.print(f"   [dim]æŒç»­æ—¶é—´:[/dim] {result.duration:.2f} ç§’")
                console.print(f"   [dim]å¼€å§‹æ—¶é—´:[/dim] {result.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
                console.print(f"   [dim]ç»“æŸæ—¶é—´:[/dim] {result.end_time.strftime('%Y-%m-%d %H:%M:%S')}")
                
                if result.metrics_file:
                    console.print(f"   [dim]æŒ‡æ ‡æ–‡ä»¶:[/dim] {result.metrics_file}")
                    
                    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                    self._show_test_metrics(result)
                else:
                    console.print(f"   [yellow]âš ï¸ æ— æŒ‡æ ‡æ–‡ä»¶[/yellow]")
                
                if result.error_message:
                    console.print(f"   [red]âŒ é”™è¯¯ä¿¡æ¯: {result.error_message}[/red]")
        
        # æ˜¾ç¤ºæµ‹è¯•é…ç½®ä¿¡æ¯
        self._show_test_configuration()
        
        # æŒ‡æ ‡æ•°æ®ç»Ÿè®¡
        self._show_metrics_summary()
        
        # æ·»åŠ æ€§èƒ½è¯„ä¼°å’Œå»ºè®®
        self._show_performance_assessment()

    def _show_test_metrics(self, result):
        """æ˜¾ç¤ºå•ä¸ªæµ‹è¯•çš„å…³é”®æŒ‡æ ‡"""
        try:
            import json
            with open(result.metrics_file, 'r', encoding='utf-8') as f:
                metrics_data = json.load(f)
            
            if not metrics_data:
                console.print(f"   [yellow]âš ï¸ æŒ‡æ ‡æ–‡ä»¶ä¸ºç©º[/yellow]")
                return
            
            # åˆ†ç±»æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
            connection_metrics = []
            mqtt_metrics = []
            performance_metrics = []
            error_metrics = []
            system_metrics = []
            throughput_metrics = []
            latency_metrics = []
            
            # å®šä¹‰å…³é”®æŒ‡æ ‡ä¼˜å…ˆçº§
            critical_metrics = [
                'connect_succ', 'connect_fail', 'pub_succ', 'pub_fail', 'sub_succ', 'sub_fail',
                'publish_latency', 'mqtt_client_connect_duration', 'mqtt_client_handshake_duration',
                'e2e_latency', 'mqtt_client_subscribe_duration', 'connection_idle', 'recv',
                'connect_retried', 'reconnect_succ', 'connection_timeout', 'connection_refused',
                'unreachable', 'pub_overrun'
            ]
            
            for metric in metrics_data:
                if isinstance(metric, dict):
                    name = metric.get('name', '')
                    value = metric.get('value', 0)
                    name_lower = name.lower()
                    
                    # æŒ‰ç±»åˆ«åˆ†ç±»æŒ‡æ ‡
                    if any(keyword in name_lower for keyword in ['connect', 'connection']):
                        connection_metrics.append((name, value))
                    elif any(keyword in name_lower for keyword in ['mqtt', 'publish', 'subscribe', 'message', 'pub', 'sub', 'handshake']):
                        mqtt_metrics.append((name, value))
                    elif any(keyword in name_lower for keyword in ['latency', 'duration', 'time']):
                        performance_metrics.append((name, value))
                        if 'latency' in name_lower:
                            latency_metrics.append((name, value))
                    elif any(keyword in name_lower for keyword in ['error', 'fail', 'exception', 'timeout', 'refused', 'unreachable']):
                        error_metrics.append((name, value))
                    elif any(keyword in name_lower for keyword in ['cpu', 'memory', 'disk', 'network', 'system', 'erlang']):
                        system_metrics.append((name, value))
                    elif any(keyword in name_lower for keyword in ['throughput', 'rate', 'succ', 'recv']):
                        throughput_metrics.append((name, value))
            
            # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡è¡¨æ ¼
            self._display_metrics_table(result.test_name, {
                'è¿æ¥æŒ‡æ ‡': connection_metrics,
                'MQTTæŒ‡æ ‡': mqtt_metrics,
                'æ€§èƒ½æŒ‡æ ‡': performance_metrics,
                'é”™è¯¯æŒ‡æ ‡': error_metrics,
                'ç³»ç»ŸæŒ‡æ ‡': system_metrics,
                'ååé‡æŒ‡æ ‡': throughput_metrics,
                'å»¶è¿ŸæŒ‡æ ‡': latency_metrics
            })
            
            # æ˜¾ç¤ºæ€»æŒ‡æ ‡æ•°
            total_metrics = len(metrics_data)
            console.print(f"   [dim]ğŸ“Š æ€»æŒ‡æ ‡æ•°: {total_metrics}[/dim]")
            
        except Exception as e:
            console.print(f"   [red]âŒ è¯»å–æŒ‡æ ‡æ–‡ä»¶å¤±è´¥: {e}[/red]")
    
    def _show_test_configuration(self):
        """æ˜¾ç¤ºæµ‹è¯•é…ç½®ä¿¡æ¯"""
        console.print("\n" + "="*60)
        console.print("âš™ï¸ [bold blue]æµ‹è¯•é…ç½®ä¿¡æ¯[/bold blue]")
        console.print("="*60)
        
        try:
            # è·å–é…ç½®ä¿¡æ¯
            config = self.test_manager.config_manager.config
            
            # åˆ›å»ºé…ç½®è¡¨æ ¼
            config_table = Table(title="ğŸ“‹ æµ‹è¯•é…ç½®è¯¦æƒ…", show_header=True, header_style="bold magenta")
            config_table.add_column("é…ç½®é¡¹", style="cyan", width=20)
            config_table.add_column("å€¼", style="green", width=30)
            config_table.add_column("è¯´æ˜", style="dim", width=40)
            
            # åŸºæœ¬é…ç½®
            config_table.add_row("MQTTæœåŠ¡å™¨", f"{config.host}:{config.port}", "MQTTæœåŠ¡å™¨åœ°å€å’Œç«¯å£")
            config_table.add_row("å®¢æˆ·ç«¯æ•°é‡", str(config.client_count), "åŒæ—¶è¿æ¥çš„å®¢æˆ·ç«¯æ•°é‡")
            config_table.add_row("æ¶ˆæ¯é—´éš”", f"{config.msg_interval}ms", "æ¶ˆæ¯å‘é€é—´éš”æ—¶é—´")
            config_table.add_row("æµ‹è¯•æŒç»­æ—¶é—´", f"{config.test_duration}ç§’", "æ¯ä¸ªæµ‹è¯•çš„æŒç»­æ—¶é—´")
            config_table.add_row("QoSç­‰çº§", str(config.qos), "MQTTæ¶ˆæ¯è´¨é‡ç­‰çº§")
            config_table.add_row("Prometheusç«¯å£", str(config.prometheus_port), "PrometheusæŒ‡æ ‡èµ·å§‹ç«¯å£")
            
            # åä¸ºäº‘é…ç½®
            config_table.add_row("åä¸ºäº‘è®¤è¯", "æ˜¯" if config.use_huawei_auth else "å¦", "æ˜¯å¦ä½¿ç”¨åä¸ºäº‘IoTè®¤è¯")
            
            if config.use_huawei_auth:
                config_table.add_row("è®¾å¤‡å‰ç¼€", config.device_prefix, "åä¸ºäº‘è®¾å¤‡IDå‰ç¼€")
                config_table.add_row("è®¾å¤‡å¯†é’¥", "***" if config.huawei_secret else "æœªé…ç½®", "åä¸ºäº‘è®¾å¤‡å¯†é’¥")
                
                # åä¸ºäº‘å¹¿æ’­å‚æ•°
                huawei_ak = getattr(config, 'huawei_ak', '')
                huawei_sk = getattr(config, 'huawei_sk', '')
                huawei_endpoint = getattr(config, 'huawei_endpoint', '')
                
                if huawei_ak:
                    config_table.add_row("åä¸ºäº‘AK", huawei_ak[:8] + "..." if len(huawei_ak) > 8 else huawei_ak, "åä¸ºäº‘è®¿é—®å¯†é’¥ID")
                else:
                    config_table.add_row("åä¸ºäº‘AK", "æœªé…ç½®", "åä¸ºäº‘è®¿é—®å¯†é’¥ID")
                
                if huawei_sk:
                    config_table.add_row("åä¸ºäº‘SK", "***", "åä¸ºäº‘è®¿é—®å¯†é’¥Secret")
                else:
                    config_table.add_row("åä¸ºäº‘SK", "æœªé…ç½®", "åä¸ºäº‘è®¿é—®å¯†é’¥Secret")
                
                config_table.add_row("åä¸ºäº‘ç«¯ç‚¹", huawei_endpoint or "æœªé…ç½®", "åä¸ºäº‘IoTDAç«¯ç‚¹")
                config_table.add_row("åä¸ºäº‘åŒºåŸŸ", getattr(config, 'huawei_region', 'cn-north-4'), "åä¸ºäº‘åŒºåŸŸID")
                config_table.add_row("å¹¿æ’­ä¸»é¢˜", getattr(config, 'broadcast_topic', '$oc/broadcast/test'), "å¹¿æ’­æ¶ˆæ¯ä¸»é¢˜")
                config_table.add_row("å¹¿æ’­é—´éš”", f"{getattr(config, 'broadcast_interval', 5)}ç§’", "å¹¿æ’­å‘é€é—´éš”")
            
            # eMQTT-Benché…ç½®
            config_table.add_row("eMQTT-Benchè·¯å¾„", config.emqtt_bench_path, "eMQTT-Benchå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„")
            
            console.print(config_table)
            
            # æ˜¾ç¤ºé…ç½®è¯´æ˜
            console.print(f"\n[bold]ğŸ“ é…ç½®è¯´æ˜:[/bold]")
            console.print(f"   â€¢ [cyan]QoSç­‰çº§:[/cyan] {self._get_qos_description(config.qos)}")
            console.print(f"   â€¢ [cyan]æµ‹è¯•æ¨¡å¼:[/cyan] {'åä¸ºäº‘IoTå¹³å°æµ‹è¯•' if config.use_huawei_auth else 'æ ‡å‡†MQTTæµ‹è¯•'}")
            console.print(f"   â€¢ [cyan]ç›‘æ§æ–¹å¼:[/cyan] Prometheus + REST API")
            console.print(f"   â€¢ [cyan]æ•°æ®æ”¶é›†:[/cyan] æŒç»­æŒ‡æ ‡æ”¶é›† + å®æ—¶åˆ†æ")
            
            # æ˜¾ç¤ºæµ‹è¯•ç¯å¢ƒä¿¡æ¯
            console.print(f"\n[bold]ğŸŒ æµ‹è¯•ç¯å¢ƒä¿¡æ¯:[/bold]")
            console.print(f"   â€¢ [cyan]å¼€å§‹æ—¶é—´:[/cyan] {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            console.print(f"   â€¢ [cyan]ç»“æŸæ—¶é—´:[/cyan] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            console.print(f"   â€¢ [cyan]æ€»è€—æ—¶:[/cyan] {(datetime.now() - self.start_time).total_seconds():.1f} ç§’")
            console.print(f"   â€¢ [cyan]æµ‹è¯•æ•°é‡:[/cyan] {len(self.test_results)} ä¸ª")
            console.print(f"   â€¢ [cyan]æˆåŠŸæ•°é‡:[/cyan] {len([r for r in self.test_results if r.success])} ä¸ª")
            
        except Exception as e:
            console.print(f"[red]âŒ æ˜¾ç¤ºé…ç½®ä¿¡æ¯å¤±è´¥: {e}[/red]")
    
    def _get_qos_description(self, qos: int) -> str:
        """è·å–QoSç­‰çº§æè¿°"""
        qos_descriptions = {
            0: "æœ€å¤šä¸€æ¬¡ (Fire and Forget) - ä¸ä¿è¯æ¶ˆæ¯é€è¾¾",
            1: "è‡³å°‘ä¸€æ¬¡ (At Least Once) - ä¿è¯æ¶ˆæ¯é€è¾¾ï¼Œå¯èƒ½é‡å¤",
            2: "æ°å¥½ä¸€æ¬¡ (Exactly Once) - ä¿è¯æ¶ˆæ¯é€è¾¾ä¸”ä¸é‡å¤"
        }
        return qos_descriptions.get(qos, "æœªçŸ¥QoSç­‰çº§")
    
    def _display_metrics_table(self, test_name: str, metrics_categories: Dict[str, List]):
        """æ˜¾ç¤ºæŒ‡æ ‡åˆ†ç±»è¡¨æ ¼"""
        # åˆ›å»ºæŒ‡æ ‡è¡¨æ ¼
        metrics_table = Table(title=f"ğŸ“Š {test_name} - è¯¦ç»†æŒ‡æ ‡åˆ†æ", show_header=True, header_style="bold magenta")
        metrics_table.add_column("æŒ‡æ ‡ç±»åˆ«", style="cyan", width=15)
        metrics_table.add_column("æŒ‡æ ‡åç§°", style="green", width=25)
        metrics_table.add_column("æ•°å€¼", style="yellow", width=12)
        metrics_table.add_column("çŠ¶æ€", style="blue", width=10)
        
        # å®šä¹‰çŠ¶æ€è¯„ä¼°å‡½æ•°
        def get_metric_status(name: str, value: float) -> str:
            name_lower = name.lower()
            if 'succ' in name_lower and value > 0:
                return "âœ… è‰¯å¥½"
            elif 'fail' in name_lower and value == 0:
                return "âœ… è‰¯å¥½"
            elif 'latency' in name_lower:
                if value <= 100:
                    return "âœ… ä¼˜ç§€"
                elif value <= 500:
                    return "âš ï¸ ä¸€èˆ¬"
                else:
                    return "âŒ è¾ƒå·®"
            elif 'duration' in name_lower:
                if value <= 50:
                    return "âœ… ä¼˜ç§€"
                elif value <= 200:
                    return "âš ï¸ ä¸€èˆ¬"
                else:
                    return "âŒ è¾ƒå·®"
            elif 'error' in name_lower or 'fail' in name_lower or 'timeout' in name_lower:
                if value == 0:
                    return "âœ… è‰¯å¥½"
                else:
                    return "âŒ éœ€å…³æ³¨"
            else:
                return "ğŸ“Š æ­£å¸¸"
        
        # å¡«å……è¡¨æ ¼æ•°æ®
        for category, metrics in metrics_categories.items():
            if metrics:
                # æŒ‰é‡è¦æ€§æ’åºï¼ˆå…³é”®æŒ‡æ ‡ä¼˜å…ˆï¼‰
                critical_metrics = [m for m in metrics if m[0] in [
                    'connect_succ', 'connect_fail', 'pub_succ', 'pub_fail', 'sub_succ', 'sub_fail',
                    'publish_latency', 'mqtt_client_connect_duration', 'mqtt_client_handshake_duration',
                    'e2e_latency', 'mqtt_client_subscribe_duration'
                ]]
                other_metrics = [m for m in metrics if m[0] not in [
                    'connect_succ', 'connect_fail', 'pub_succ', 'pub_fail', 'sub_succ', 'sub_fail',
                    'publish_latency', 'mqtt_client_connect_duration', 'mqtt_client_handshake_duration',
                    'e2e_latency', 'mqtt_client_subscribe_duration'
                ]]
                
                # å…ˆæ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                for name, value in critical_metrics[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªå…³é”®æŒ‡æ ‡
                    status = get_metric_status(name, value)
                    metrics_table.add_row(category, name, f"{value:.2f}", status)
                
                # å†æ˜¾ç¤ºå…¶ä»–é‡è¦æŒ‡æ ‡
                for name, value in other_metrics[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ªå…¶ä»–æŒ‡æ ‡
                    status = get_metric_status(name, value)
                    metrics_table.add_row(category, name, f"{value:.2f}", status)
        
        console.print(metrics_table)

    def _show_metrics_summary(self):
        """æ˜¾ç¤ºæŒ‡æ ‡æ•°æ®ç»Ÿè®¡æ‘˜è¦"""
        console.print("\n" + "="*60)
        console.print("ğŸ“ˆ [bold blue]æŒ‡æ ‡æ•°æ®ç»Ÿè®¡[/bold blue]")
        console.print("="*60)
        
        # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡æ•°æ®
        all_metrics_data = self._collect_all_metrics_data()
        
        if not all_metrics_data:
            console.print("[yellow]âš ï¸ æ— æŒ‡æ ‡æ•°æ®[/yellow]")
            return
        
        # ç»Ÿè®¡å„ç±»æŒ‡æ ‡
        total_metrics = 0
        mqtt_metrics_count = 0
        connection_metrics_count = 0
        performance_metrics_count = 0
        error_metrics_count = 0
        system_metrics_count = 0
        
        for test_name, test_data in all_metrics_data.items():
            metrics = test_data.get('metrics', [])
            total_metrics += len(metrics)
            
            for metric in metrics:
                if isinstance(metric, dict):
                    name = metric.get('name', '').lower()
                    
                    if any(keyword in name for keyword in ['mqtt', 'publish', 'subscribe', 'message', 'pub', 'sub', 'handshake']):
                        mqtt_metrics_count += 1
                    elif any(keyword in name for keyword in ['connect', 'connection']):
                        connection_metrics_count += 1
                    elif any(keyword in name for keyword in ['latency', 'throughput', 'rate', 'duration', 'time']):
                        performance_metrics_count += 1
                    elif any(keyword in name for keyword in ['error', 'fail', 'exception', 'timeout']):
                        error_metrics_count += 1
                    elif any(keyword in name for keyword in ['cpu', 'memory', 'disk', 'network', 'system']):
                        system_metrics_count += 1
        
        # æ˜¾ç¤ºç»Ÿè®¡è¡¨æ ¼
        metrics_table = Table(title="ğŸ“Š æŒ‡æ ‡åˆ†ç±»ç»Ÿè®¡")
        metrics_table.add_column("æŒ‡æ ‡ç±»å‹", style="cyan", width=15)
        metrics_table.add_column("æ•°é‡", style="green", width=10)
        metrics_table.add_column("å æ¯”", style="yellow", width=10)
        
        if total_metrics > 0:
            metrics_table.add_row("æ€»æŒ‡æ ‡æ•°", str(total_metrics), "100.0%")
            metrics_table.add_row("MQTTæŒ‡æ ‡", str(mqtt_metrics_count), f"{mqtt_metrics_count/total_metrics*100:.1f}%")
            metrics_table.add_row("è¿æ¥æŒ‡æ ‡", str(connection_metrics_count), f"{connection_metrics_count/total_metrics*100:.1f}%")
            metrics_table.add_row("æ€§èƒ½æŒ‡æ ‡", str(performance_metrics_count), f"{performance_metrics_count/total_metrics*100:.1f}%")
            metrics_table.add_row("é”™è¯¯æŒ‡æ ‡", str(error_metrics_count), f"{error_metrics_count/total_metrics*100:.1f}%")
            metrics_table.add_row("ç³»ç»ŸæŒ‡æ ‡", str(system_metrics_count), f"{system_metrics_count/total_metrics*100:.1f}%")
        
        console.print(metrics_table)
        
        # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡æ±‡æ€»
        console.print(f"\n[bold]ğŸ” å…³é”®æŒ‡æ ‡æ±‡æ€»:[/bold]")
        
        # åˆ›å»ºå…³é”®æŒ‡æ ‡æ±‡æ€»è¡¨æ ¼
        summary_table = Table(title="ğŸ“Š å…³é”®æŒ‡æ ‡æ±‡æ€»å¯¹æ¯”", show_header=True, header_style="bold magenta")
        summary_table.add_column("æµ‹è¯•åç§°", style="cyan", width=20)
        summary_table.add_column("è¿æ¥æˆåŠŸç‡", style="green", width=12)
        summary_table.add_column("å‘å¸ƒæˆåŠŸç‡", style="green", width=12)
        summary_table.add_column("è®¢é˜…æˆåŠŸç‡", style="green", width=12)
        summary_table.add_column("å¹³å‡å»¶è¿Ÿ(ms)", style="yellow", width=12)
        summary_table.add_column("é”™è¯¯ç‡", style="red", width=10)
        summary_table.add_column("æ•´ä½“çŠ¶æ€", style="blue", width=10)
        
        for test_name, test_data in all_metrics_data.items():
            metrics = test_data.get('metrics', [])
            if metrics:
                # æŸ¥æ‰¾å…³é”®æŒ‡æ ‡
                key_metrics = {}
                for metric in metrics:
                    if isinstance(metric, dict):
                        name = metric.get('name', '')
                        value = metric.get('value', 0)
                        key_metrics[name] = value
                
                # è®¡ç®—å…³é”®æŒ‡æ ‡
                connect_succ = key_metrics.get('connect_succ', 0)
                connect_fail = key_metrics.get('connect_fail', 0)
                pub_succ = key_metrics.get('pub_succ', 0)
                pub_fail = key_metrics.get('pub_fail', 0)
                sub_succ = key_metrics.get('sub_succ', 0)
                sub_fail = key_metrics.get('sub_fail', 0)
                publish_latency = key_metrics.get('publish_latency', 0)
                
                # è®¡ç®—æˆåŠŸç‡
                total_connects = connect_succ + connect_fail
                total_pubs = pub_succ + pub_fail
                total_subs = sub_succ + sub_fail
                
                connect_success_rate = (connect_succ / total_connects * 100) if total_connects > 0 else 0
                pub_success_rate = (pub_succ / total_pubs * 100) if total_pubs > 0 else 0
                sub_success_rate = (sub_succ / total_subs * 100) if total_subs > 0 else 0
                
                # è®¡ç®—é”™è¯¯ç‡
                total_errors = connect_fail + pub_fail + sub_fail
                total_operations = total_connects + total_pubs + total_subs
                error_rate = (total_errors / total_operations * 100) if total_operations > 0 else 0
                
                # è¯„ä¼°æ•´ä½“çŠ¶æ€
                if connect_success_rate >= 95 and pub_success_rate >= 95 and error_rate <= 5:
                    overall_status = "âœ… ä¼˜ç§€"
                elif connect_success_rate >= 90 and pub_success_rate >= 90 and error_rate <= 10:
                    overall_status = "âš ï¸ è‰¯å¥½"
                else:
                    overall_status = "âŒ éœ€å…³æ³¨"
                
                # æ·»åŠ åˆ°è¡¨æ ¼
                summary_table.add_row(
                    test_name,
                    f"{connect_success_rate:.1f}%" if total_connects > 0 else "N/A",
                    f"{pub_success_rate:.1f}%" if total_pubs > 0 else "N/A",
                    f"{sub_success_rate:.1f}%" if total_subs > 0 else "N/A",
                    f"{publish_latency:.1f}" if publish_latency > 0 else "N/A",
                    f"{error_rate:.1f}%",
                    overall_status
                )
        
        console.print(summary_table)
        
        # æ˜¾ç¤ºè¯¦ç»†çš„å…³é”®æŒ‡æ ‡
        console.print(f"\n[bold]ğŸ“‹ è¯¦ç»†å…³é”®æŒ‡æ ‡:[/bold]")
        for test_name, test_data in all_metrics_data.items():
            metrics = test_data.get('metrics', [])
            if metrics:
                # æŸ¥æ‰¾å…³é”®æŒ‡æ ‡
                key_metrics = {}
                for metric in metrics:
                    if isinstance(metric, dict):
                        name = metric.get('name', '')
                        value = metric.get('value', 0)
                        
                        # æ‰©å±•å…³é”®æŒ‡æ ‡åˆ—è¡¨
                        if name in [
                            'connect_succ', 'connect_fail', 'pub_succ', 'pub_fail', 'sub_succ', 'sub_fail',
                            'publish_latency', 'mqtt_client_connect_duration', 'mqtt_client_handshake_duration',
                            'e2e_latency', 'mqtt_client_subscribe_duration', 'connection_idle', 'recv',
                            'connect_retried', 'reconnect_succ', 'connection_timeout', 'connection_refused',
                            'unreachable', 'pub_overrun'
                        ]:
                            key_metrics[name] = value
                
                if key_metrics:
                    # æŒ‰ç±»åˆ«åˆ†ç»„æ˜¾ç¤º
                    connection_metrics = {k: v for k, v in key_metrics.items() if 'connect' in k.lower()}
                    mqtt_metrics = {k: v for k, v in key_metrics.items() if any(x in k.lower() for x in ['pub', 'sub', 'mqtt'])}
                    performance_metrics = {k: v for k, v in key_metrics.items() if any(x in k.lower() for x in ['latency', 'duration', 'time'])}
                    error_metrics = {k: v for k, v in key_metrics.items() if any(x in k.lower() for x in ['fail', 'error', 'timeout', 'refused', 'unreachable'])}
                    
                    console.print(f"   [bold]{test_name}:[/bold]")
                    if connection_metrics:
                        console.print(f"     [blue]ğŸ”— è¿æ¥:[/blue] {', '.join([f'{k}={v}' for k, v in connection_metrics.items()])}")
                    if mqtt_metrics:
                        console.print(f"     [green]ğŸ“¡ MQTT:[/green] {', '.join([f'{k}={v}' for k, v in mqtt_metrics.items()])}")
                    if performance_metrics:
                        console.print(f"     [yellow]âš¡ æ€§èƒ½:[/yellow] {', '.join([f'{k}={v}' for k, v in performance_metrics.items()])}")
                    if error_metrics:
                        console.print(f"     [red]ğŸš¨ é”™è¯¯:[/red] {', '.join([f'{k}={v}' for k, v in error_metrics.items()])}")

    def _show_performance_assessment(self):
        """æ˜¾ç¤ºæ€§èƒ½è¯„ä¼°å’Œå»ºè®®"""
        console.print("\n" + "="*60)
        console.print("ğŸ¯ [bold blue]æ€§èƒ½è¯„ä¼°å’Œå»ºè®®[/bold blue]")
        console.print("="*60)
        
        # æ”¶é›†æ‰€æœ‰æµ‹è¯•çš„æ€§èƒ½æ•°æ®
        all_metrics_data = self._collect_all_metrics_data()
        
        if not all_metrics_data:
            console.print("[yellow]âš ï¸ æ— æ€§èƒ½æ•°æ®å¯ä¾›è¯„ä¼°[/yellow]")
            return
        
        # è®¡ç®—æ•´ä½“æ€§èƒ½æŒ‡æ ‡
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r.success])
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        # åˆ†æå„é¡¹æ€§èƒ½æŒ‡æ ‡
        performance_analysis = self._analyze_performance_metrics(all_metrics_data)
        
        # æ˜¾ç¤ºæ€§èƒ½è¯„ä¼°è¡¨æ ¼
        assessment_table = Table(title="ğŸ“Š æ€§èƒ½è¯„ä¼°ç»“æœ", show_header=True, header_style="bold magenta")
        assessment_table.add_column("è¯„ä¼°é¡¹ç›®", style="cyan", width=20)
        assessment_table.add_column("å½“å‰å€¼", style="green", width=15)
        assessment_table.add_column("æ ‡å‡†å€¼", style="yellow", width=15)
        assessment_table.add_column("çŠ¶æ€", style="blue", width=12)
        assessment_table.add_column("å»ºè®®", style="red", width=25)
        
        # è¿æ¥æ€§èƒ½è¯„ä¼°
        avg_connect_latency = performance_analysis.get('avg_connect_latency', 0)
        if avg_connect_latency > 0:
            connect_status = "âœ… ä¼˜ç§€" if avg_connect_latency <= 100 else "âš ï¸ ä¸€èˆ¬" if avg_connect_latency <= 500 else "âŒ è¾ƒå·®"
            connect_advice = "ä¿æŒå½“å‰é…ç½®" if avg_connect_latency <= 100 else "æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ" if avg_connect_latency <= 500 else "ä¼˜åŒ–ç½‘ç»œé…ç½®"
            assessment_table.add_row("è¿æ¥å»¶è¿Ÿ", f"{avg_connect_latency:.1f}ms", "â‰¤100ms", connect_status, connect_advice)
        
        # å‘å¸ƒæ€§èƒ½è¯„ä¼°
        avg_pub_latency = performance_analysis.get('avg_pub_latency', 0)
        if avg_pub_latency > 0:
            pub_status = "âœ… ä¼˜ç§€" if avg_pub_latency <= 50 else "âš ï¸ ä¸€èˆ¬" if avg_pub_latency <= 200 else "âŒ è¾ƒå·®"
            pub_advice = "æ€§èƒ½è‰¯å¥½" if avg_pub_latency <= 50 else "è€ƒè™‘ä¼˜åŒ–QoS" if avg_pub_latency <= 200 else "æ£€æŸ¥æ¶ˆæ¯å¤§å°"
            assessment_table.add_row("å‘å¸ƒå»¶è¿Ÿ", f"{avg_pub_latency:.1f}ms", "â‰¤50ms", pub_status, pub_advice)
        
        # æˆåŠŸç‡è¯„ä¼°
        overall_success_rate = performance_analysis.get('overall_success_rate', success_rate)
        success_status = "âœ… ä¼˜ç§€" if overall_success_rate >= 95 else "âš ï¸ è‰¯å¥½" if overall_success_rate >= 90 else "âŒ éœ€å…³æ³¨"
        success_advice = "ç³»ç»Ÿç¨³å®š" if overall_success_rate >= 95 else "ç›‘æ§è¿è¡Œ" if overall_success_rate >= 90 else "æ£€æŸ¥é…ç½®"
        assessment_table.add_row("æ•´ä½“æˆåŠŸç‡", f"{overall_success_rate:.1f}%", "â‰¥95%", success_status, success_advice)
        
        # é”™è¯¯ç‡è¯„ä¼°
        error_rate = performance_analysis.get('error_rate', 0)
        error_status = "âœ… ä¼˜ç§€" if error_rate <= 1 else "âš ï¸ ä¸€èˆ¬" if error_rate <= 5 else "âŒ è¾ƒå·®"
        error_advice = "é”™è¯¯ç‡æ­£å¸¸" if error_rate <= 1 else "å…³æ³¨é”™è¯¯æ—¥å¿—" if error_rate <= 5 else "æ’æŸ¥é”™è¯¯åŸå› "
        assessment_table.add_row("é”™è¯¯ç‡", f"{error_rate:.1f}%", "â‰¤1%", error_status, error_advice)
        
        # ååé‡è¯„ä¼°
        avg_throughput = performance_analysis.get('avg_throughput', 0)
        if avg_throughput > 0:
            throughput_status = "âœ… ä¼˜ç§€" if avg_throughput >= 1000 else "âš ï¸ ä¸€èˆ¬" if avg_throughput >= 500 else "âŒ è¾ƒä½"
            throughput_advice = "ååé‡è‰¯å¥½" if avg_throughput >= 1000 else "å¯ä¼˜åŒ–å¹¶å‘" if avg_throughput >= 500 else "å¢åŠ å®¢æˆ·ç«¯æ•°"
            assessment_table.add_row("å¹³å‡ååé‡", f"{avg_throughput:.0f}/s", "â‰¥1000/s", throughput_status, throughput_advice)
        
        console.print(assessment_table)
        
        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
        self._show_optimization_recommendations(performance_analysis)
        
        # æ˜¾ç¤ºæ•´ä½“è¯„ä¼°ç»“è®º
        self._show_overall_assessment(performance_analysis, success_rate)
    
    def _analyze_performance_metrics(self, all_metrics_data: Dict[str, Any]) -> Dict[str, float]:
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        analysis = {
            'avg_connect_latency': 0,
            'avg_pub_latency': 0,
            'overall_success_rate': 0,
            'error_rate': 0,
            'avg_throughput': 0,
            'total_operations': 0,
            'total_errors': 0
        }
        
        total_connect_latency = 0
        total_pub_latency = 0
        total_operations = 0
        total_errors = 0
        total_success = 0
        test_count = 0
        
        for test_name, test_data in all_metrics_data.items():
            metrics = test_data.get('metrics', [])
            if not metrics:
                continue
                
            test_count += 1
            
            # æå–æŒ‡æ ‡å€¼
            key_metrics = {}
            for metric in metrics:
                if isinstance(metric, dict):
                    name = metric.get('name', '')
                    value = metric.get('value', 0)
                    key_metrics[name] = value
            
            # è®¡ç®—è¿æ¥å»¶è¿Ÿ
            connect_duration = key_metrics.get('mqtt_client_connect_duration', 0)
            if connect_duration > 0:
                total_connect_latency += connect_duration
            
            # è®¡ç®—å‘å¸ƒå»¶è¿Ÿ
            pub_latency = key_metrics.get('publish_latency', 0)
            if pub_latency > 0:
                total_pub_latency += pub_latency
            
            # è®¡ç®—æ“ä½œæ•°å’Œé”™è¯¯æ•°
            connect_succ = key_metrics.get('connect_succ', 0)
            connect_fail = key_metrics.get('connect_fail', 0)
            pub_succ = key_metrics.get('pub_succ', 0)
            pub_fail = key_metrics.get('pub_fail', 0)
            sub_succ = key_metrics.get('sub_succ', 0)
            sub_fail = key_metrics.get('sub_fail', 0)
            
            test_operations = connect_succ + connect_fail + pub_succ + pub_fail + sub_succ + sub_fail
            test_errors = connect_fail + pub_fail + sub_fail
            test_success = connect_succ + pub_succ + sub_succ
            
            total_operations += test_operations
            total_errors += test_errors
            total_success += test_success
        
        # è®¡ç®—å¹³å‡å€¼
        if test_count > 0:
            analysis['avg_connect_latency'] = total_connect_latency / test_count
            analysis['avg_pub_latency'] = total_pub_latency / test_count
        
        if total_operations > 0:
            analysis['overall_success_rate'] = (total_success / total_operations) * 100
            analysis['error_rate'] = (total_errors / total_operations) * 100
            analysis['avg_throughput'] = total_success / total_operations * 1000  # å‡è®¾æµ‹è¯•æŒç»­æ—¶é—´ä¸º1000ç§’
        
        analysis['total_operations'] = total_operations
        analysis['total_errors'] = total_errors
        
        return analysis
    
    def _show_optimization_recommendations(self, performance_analysis: Dict[str, float]):
        """æ˜¾ç¤ºä¼˜åŒ–å»ºè®®"""
        console.print(f"\n[bold]ğŸ’¡ ä¼˜åŒ–å»ºè®®:[/bold]")
        
        recommendations = []
        
        # åŸºäºæ€§èƒ½åˆ†æç”Ÿæˆå»ºè®®
        avg_connect_latency = performance_analysis.get('avg_connect_latency', 0)
        avg_pub_latency = performance_analysis.get('avg_pub_latency', 0)
        error_rate = performance_analysis.get('error_rate', 0)
        overall_success_rate = performance_analysis.get('overall_success_rate', 0)
        
        if avg_connect_latency > 500:
            recommendations.append("ğŸ”§ è¿æ¥å»¶è¿Ÿè¿‡é«˜ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œé…ç½®å’ŒæœåŠ¡å™¨æ€§èƒ½")
        
        if avg_pub_latency > 200:
            recommendations.append("ğŸ“¡ å‘å¸ƒå»¶è¿Ÿè¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–æ¶ˆæ¯å¤§å°å’ŒQoSè®¾ç½®")
        
        if error_rate > 5:
            recommendations.append("ğŸš¨ é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œç¨³å®šæ€§å’Œè®¤è¯é…ç½®")
        
        if overall_success_rate < 90:
            recommendations.append("âš ï¸ æ•´ä½“æˆåŠŸç‡åä½ï¼Œå»ºè®®æ£€æŸ¥MQTTæœåŠ¡å™¨é…ç½®")
        
        # é€šç”¨å»ºè®®
        recommendations.extend([
            "ğŸ“Š å»ºè®®å®šæœŸç›‘æ§å…³é”®æ€§èƒ½æŒ‡æ ‡",
            "ğŸ”„ è€ƒè™‘åœ¨ä¸åŒæ—¶é—´æ®µè¿›è¡Œå‹åŠ›æµ‹è¯•",
            "ğŸ“ˆ æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´å®¢æˆ·ç«¯æ•°é‡å’Œæ¶ˆæ¯é¢‘ç‡",
            "ğŸ›¡ï¸ ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šæ€§å’Œå®‰å…¨æ€§"
        ])
        
        for i, rec in enumerate(recommendations, 1):
            console.print(f"   {i}. {rec}")
    
    def _show_overall_assessment(self, performance_analysis: Dict[str, float], success_rate: float):
        """æ˜¾ç¤ºæ•´ä½“è¯„ä¼°ç»“è®º"""
        console.print(f"\n[bold]ğŸ¯ æ•´ä½“è¯„ä¼°ç»“è®º:[/bold]")
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        score = 0
        max_score = 100
        
        # æˆåŠŸç‡è¯„åˆ† (40åˆ†)
        if success_rate >= 95:
            score += 40
        elif success_rate >= 90:
            score += 30
        elif success_rate >= 80:
            score += 20
        else:
            score += 10
        
        # å»¶è¿Ÿè¯„åˆ† (30åˆ†)
        avg_connect_latency = performance_analysis.get('avg_connect_latency', 0)
        avg_pub_latency = performance_analysis.get('avg_pub_latency', 0)
        
        if avg_connect_latency <= 100 and avg_pub_latency <= 50:
            score += 30
        elif avg_connect_latency <= 500 and avg_pub_latency <= 200:
            score += 20
        else:
            score += 10
        
        # é”™è¯¯ç‡è¯„åˆ† (30åˆ†)
        error_rate = performance_analysis.get('error_rate', 0)
        if error_rate <= 1:
            score += 30
        elif error_rate <= 5:
            score += 20
        else:
            score += 10
        
        # æ˜¾ç¤ºè¯„åˆ†ç»“æœ
        if score >= 90:
            console.print(f"   [green]ğŸ† ç»¼åˆè¯„åˆ†: {score}/{max_score} - ä¼˜ç§€[/green]")
            console.print(f"   [green]ğŸ‰ ç³»ç»Ÿæ€§èƒ½è¡¨ç°ä¼˜ç§€ï¼Œå„é¡¹æŒ‡æ ‡å‡è¾¾åˆ°é¢„æœŸæ ‡å‡†[/green]")
        elif score >= 70:
            console.print(f"   [yellow]â­ ç»¼åˆè¯„åˆ†: {score}/{max_score} - è‰¯å¥½[/yellow]")
            console.print(f"   [yellow]ğŸ‘ ç³»ç»Ÿæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®å…³æ³¨éƒ¨åˆ†æŒ‡æ ‡ä¼˜åŒ–[/yellow]")
        elif score >= 50:
            console.print(f"   [orange]âš ï¸ ç»¼åˆè¯„åˆ†: {score}/{max_score} - ä¸€èˆ¬[/orange]")
            console.print(f"   [orange]ğŸ”§ ç³»ç»Ÿæ€§èƒ½éœ€è¦æ”¹è¿›ï¼Œå»ºè®®ä¼˜åŒ–é…ç½®å’Œç½‘ç»œç¯å¢ƒ[/orange]")
        else:
            console.print(f"   [red]âŒ ç»¼åˆè¯„åˆ†: {score}/{max_score} - éœ€å…³æ³¨[/red]")
            console.print(f"   [red]ğŸš¨ ç³»ç»Ÿæ€§èƒ½éœ€è¦é‡ç‚¹å…³æ³¨ï¼Œå»ºè®®å…¨é¢æ£€æŸ¥é…ç½®å’Œç½‘ç»œ[/red]")

def filter_existing_data():
    """è¿‡æ»¤ç°æœ‰çš„raw_dataæ–‡ä»¶"""
    console.print("ğŸ§¹ [bold blue]æ•°æ®è¿‡æ»¤å·¥å…·[/bold blue]")
    console.print("=" * 60)
    console.print("âœ¨ [yellow]è¿‡æ»¤ç°æœ‰raw_dataæ–‡ä»¶ä¸­çš„æ— æ•ˆæ•°æ®[/yellow]")
    console.print("")
    
    # åˆ›å»ºæ•°æ®æ”¶é›†å™¨å®ä¾‹
    collector = AutoDataCollector()
    
    # æŸ¥æ‰¾æ‰€æœ‰raw_dataæ–‡ä»¶
    raw_data_dir = "test_data/raw_data"
    if not os.path.exists(raw_data_dir):
        console.print(f"[red]âŒ ç›®å½•ä¸å­˜åœ¨: {raw_data_dir}[/red]")
        return
    
    raw_data_files = [f for f in os.listdir(raw_data_dir) if f.endswith('.json')]
    
    if not raw_data_files:
        console.print(f"[yellow]âš ï¸ åœ¨ {raw_data_dir} ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶[/yellow]")
        return
    
    console.print(f"[cyan]ğŸ“ æ‰¾åˆ° {len(raw_data_files)} ä¸ªraw_dataæ–‡ä»¶:[/cyan]")
    for i, file in enumerate(raw_data_files, 1):
        console.print(f"  {i}. {file}")
    console.print("")
    
    # è¯¢é—®æ˜¯å¦å¤„ç†æ‰€æœ‰æ–‡ä»¶
    if Confirm.ask("æ˜¯å¦è¿‡æ»¤æ‰€æœ‰raw_dataæ–‡ä»¶?", default=True):
        console.print("[green]âœ… å¼€å§‹è¿‡æ»¤æ‰€æœ‰æ–‡ä»¶...[/green]")
        
        for file in raw_data_files:
            file_path = os.path.join(raw_data_dir, file)
            console.print(f"\n[blue]ğŸ” å¤„ç†æ–‡ä»¶: {file}[/blue]")
            
            try:
                # è¯»å–åŸå§‹æ•°æ®
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æå–æµ‹è¯•ä¿¡æ¯
                test_name = data.get('test_name', 'Unknown')
                raw_metrics = data.get('raw_metrics', [])
                
                # è¿‡æ»¤æ•°æ®
                filtered_metrics = collector._filter_invalid_metrics(raw_metrics, test_name)
                
                # åˆ›å»ºè¿‡æ»¤åçš„æ•°æ®ç»“æ„
                filtered_data = {
                    "test_name": test_name,
                    "test_type": data.get('test_type', 'Unknown'),
                    "start_time": data.get('start_time', ''),
                    "end_time": data.get('end_time', ''),
                    "duration": data.get('duration', 0),
                    "port": data.get('port', 0),
                    "success": data.get('success', False),
                    "error_message": data.get('error_message', None),
                    "config": data.get('config', {}),
                    "filtered_metrics": filtered_metrics,
                    "filter_info": {
                        "original_count": len(raw_metrics),
                        "filtered_count": len(filtered_metrics),
                        "removed_count": len(raw_metrics) - len(filtered_metrics),
                        "filter_timestamp": datetime.now().isoformat(),
                        "source_file": file
                    }
                }
                
                # ä¿å­˜è¿‡æ»¤åçš„æ•°æ®
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filtered_filename = f"filtered_{test_name}_{timestamp}.json"
                filtered_path = os.path.join("test_data", "filtered_data", filtered_filename)
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(filtered_path), exist_ok=True)
                
                with open(filtered_path, 'w', encoding='utf-8') as f:
                    json.dump(filtered_data, f, indent=2, ensure_ascii=False)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                original_count = len(raw_metrics)
                filtered_count = len(filtered_metrics)
                removed_count = original_count - filtered_count
                reduction_percent = (removed_count / original_count * 100) if original_count > 0 else 0
                
                console.print(f"[green]âœ… è¿‡æ»¤å®Œæˆ: {file}[/green]")
                console.print(f"[dim]  â€¢ åŸå§‹æŒ‡æ ‡: {original_count}[/dim]")
                console.print(f"[dim]  â€¢ è¿‡æ»¤åæŒ‡æ ‡: {filtered_count}[/dim]")
                console.print(f"[dim]  â€¢ ç§»é™¤æŒ‡æ ‡: {removed_count} ({reduction_percent:.1f}%)[/dim]")
                console.print(f"[dim]  â€¢ ä¿å­˜ä½ç½®: {filtered_path}[/dim]")
                
            except Exception as e:
                console.print(f"[red]âŒ å¤„ç†æ–‡ä»¶ {file} å¤±è´¥: {e}[/red]")
        
        console.print(f"\n[green]ğŸ‰ æ•°æ®è¿‡æ»¤å®Œæˆï¼[/green]")
        console.print(f"[blue]ğŸ“ è¿‡æ»¤åçš„æ•°æ®ä¿å­˜åœ¨: test_data/filtered_data/[/blue]")
    else:
        console.print("[yellow]ç”¨æˆ·å–æ¶ˆæ“ä½œ[/yellow]")

def filter_continuous_metrics():
    """è¿‡æ»¤æŒç»­æŒ‡æ ‡æ–‡ä»¶çš„ä¸»å‡½æ•°"""
    console.print("[blue]ğŸ” å¼€å§‹è¿‡æ»¤æŒç»­æŒ‡æ ‡æ–‡ä»¶...[/blue]")
    
    # åˆ›å»ºæµ‹è¯•ç‰¹å®šè¿‡æ»¤å™¨å®ä¾‹
    test_filter = TestSpecificFilter()
    
    # è‡ªåŠ¨è¿‡æ»¤æ‰€æœ‰æŒç»­æŒ‡æ ‡æ–‡ä»¶
    filtered_files = test_filter.auto_filter_all_continuous_files("metrics/reports")
    
    if filtered_files:
        console.print(f"[green]âœ… æŒç»­æŒ‡æ ‡è¿‡æ»¤å®Œæˆ![/green]")
        console.print(f"[blue]ğŸ“Š è¿‡æ»¤ç»Ÿè®¡:[/blue]")
        console.print(f"[dim]  â€¢ å¤„ç†æ–‡ä»¶æ•°: {len(filtered_files)}[/dim]")
        console.print(f"[dim]  â€¢ è¿‡æ»¤åæ–‡ä»¶ä¿å­˜åœ¨: metrics/reports/filtered/[/dim]")
        
        # æ˜¾ç¤ºè¿‡æ»¤åçš„æ–‡ä»¶åˆ—è¡¨
        for file_path in filtered_files:
            console.print(f"[dim]  â€¢ {os.path.basename(file_path)}[/dim]")
    else:
        console.print("[yellow]âš ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿‡æ»¤çš„æŒç»­æŒ‡æ ‡æ–‡ä»¶[/yellow]")

def main():
    """ä¸»å‡½æ•°"""
    console.print("ğŸš€ [bold blue]eMQTT-Bench æ•°æ®æ”¶é›†å’Œè¿‡æ»¤å·¥å…·[/bold blue]")
    console.print("=" * 60)
    console.print("è¯·é€‰æ‹©æ“ä½œ:")
    console.print("  [cyan]1.[/cyan] è¿è¡Œè‡ªåŠ¨æ•°æ®æ”¶é›†ï¼ˆåŒ…å«æ•°æ®è¿‡æ»¤ï¼‰")
    console.print("  [cyan]2.[/cyan] ä»…è¿‡æ»¤ç°æœ‰raw_dataæ–‡ä»¶")
    console.print("  [cyan]3.[/cyan] è¿‡æ»¤æŒç»­æŒ‡æ ‡æ–‡ä»¶")
    console.print("")
    
    choice = Prompt.ask("è¯·é€‰æ‹© (1-3)", default="1")
    
    if choice == "1":
        collector = AutoDataCollector()
        collector.run_automatic_collection()
    elif choice == "2":
        filter_existing_data()
    elif choice == "3":
        filter_continuous_metrics()
    else:
        console.print("[red]âŒ æ— æ•ˆé€‰æ‹©[/red]")

if __name__ == "__main__":
    main()
