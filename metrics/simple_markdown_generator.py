#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆMarkdownæŠ¥å‘Šç”Ÿæˆå™¨
ä¸“æ³¨äºæ ¸å¿ƒåˆ†æåŠŸèƒ½ï¼Œä¸ºæ¯ç§æµ‹è¯•ç±»å‹æä¾›æ·±å…¥åˆ†æ
ä½œè€…: Jaxon
æ—¥æœŸ: 2024-12-19
"""

import os
import json
import statistics
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

class MarkdownReportGenerator:
    """Markdownè¯¦ç»†åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, test_results: List, all_metrics_data: Dict, start_time: datetime, reports_dir: str = "reports"):
        self.test_results = test_results
        self.all_metrics_data = all_metrics_data
        self.start_time = start_time
        self.report_timestamp = datetime.now()
        self.reports_dir = reports_dir
        
        # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
        os.makedirs(self.reports_dir, exist_ok=True)
    
    def generate_markdown_report(self) -> str:
        """ç”ŸæˆMarkdownè¯¦ç»†åˆ†ææŠ¥å‘Š"""
        timestamp = self.report_timestamp.strftime('%Y%m%d_%H%M%S')
        report_file = f"detailed_analysis_report_{timestamp}.md"
        report_path = os.path.join(self.reports_dir, report_file)
        
        # ç”ŸæˆMarkdownå†…å®¹
        markdown_content = self._generate_markdown_content()
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
            
        return report_path
    
    def _generate_markdown_content(self) -> str:
        """ç”ŸæˆMarkdownå†…å®¹"""
        content = f"""# eMQTT-Bench è¯¦ç»†åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {self.report_timestamp.strftime('%Y-%m-%d %H:%M:%S')}  
**æµ‹è¯•å¼€å§‹æ—¶é—´**: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}  
**æ€»æµ‹è¯•æ—¶é•¿**: {(self.report_timestamp - self.start_time).total_seconds():.1f} ç§’

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

{self._generate_executive_summary()}

---

## ğŸ¯ æµ‹è¯•æ¦‚è§ˆ

{self._generate_test_overview()}

---

## ğŸ”— è¿æ¥æµ‹è¯•æ·±åº¦åˆ†æ

{self._generate_connection_analysis()}

---

## ğŸ“¤ å‘å¸ƒæµ‹è¯•æ·±åº¦åˆ†æ

{self._generate_publish_analysis()}

---

## ğŸ“¥ è®¢é˜…æµ‹è¯•æ·±åº¦åˆ†æ

{self._generate_subscribe_analysis()}

---

## â˜ï¸ åä¸ºäº‘è¿æ¥æµ‹è¯•æ·±åº¦åˆ†æ

{self._generate_huawei_connection_analysis()}

---

## â˜ï¸ åä¸ºäº‘å‘å¸ƒæµ‹è¯•æ·±åº¦åˆ†æ

{self._generate_huawei_publish_analysis()}

---

## â˜ï¸ åä¸ºäº‘è®¢é˜…æµ‹è¯•æ·±åº¦åˆ†æ

{self._generate_huawei_subscribe_analysis()}

---

## âš¡ æ€§èƒ½ç»¼åˆåˆ†æ

{self._generate_performance_analysis()}

---

## ğŸ“Š å®Œæ•´æŒ‡æ ‡æ•°æ®å±•ç¤º

{self._generate_complete_metrics_display()}

---

## ğŸ“ˆ æ•°æ®å¯è§†åŒ–å›¾è¡¨

{self._generate_mermaid_charts()}

---

## ğŸš¨ é”™è¯¯åˆ†æ

{self._generate_error_analysis()}

---

## ğŸ’¡ æ™ºèƒ½æ´å¯Ÿä¸å»ºè®®

{self._generate_insights_and_recommendations()}

---

## ğŸ“ˆ ç»“è®ºä¸å»ºè®®

{self._generate_conclusion()}

---

*æŠ¥å‘Šç”± eMQTT-Bench è‡ªåŠ¨ç”Ÿæˆç³»ç»Ÿåˆ›å»º*  
*ä½œè€…: Jaxon*  
*ç‰ˆæœ¬: 1.0*
"""
        return content
    
    def _generate_executive_summary(self) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r.success])
        failed_tests = total_tests - successful_tests
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        total_duration = sum(r.duration for r in self.test_results)
        avg_duration = total_duration / total_tests if total_tests > 0 else 0
        
        # ç»Ÿè®¡æŒ‡æ ‡æ•°é‡
        total_metrics = 0
        for test_data in self.all_metrics_data.values():
            if isinstance(test_data, list):
                total_metrics += len(test_data)
            elif isinstance(test_data, dict):
                total_metrics += len(test_data.get('metrics', []))
        
        return f"""
### æµ‹è¯•ç»“æœæ¦‚è§ˆ

- **æ€»æµ‹è¯•æ•°**: {total_tests}
- **æˆåŠŸæµ‹è¯•**: {successful_tests}
- **å¤±è´¥æµ‹è¯•**: {failed_tests}
- **æˆåŠŸç‡**: {success_rate:.1f}%
- **æ€»è€—æ—¶**: {total_duration:.1f} ç§’
- **å¹³å‡è€—æ—¶**: {avg_duration:.1f} ç§’
- **æ”¶é›†æŒ‡æ ‡**: {total_metrics} ä¸ª

### å…³é”®å‘ç°

{self._get_key_findings(success_rate, failed_tests)}
"""
    
    def _generate_test_overview(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æ¦‚è§ˆ"""
        content = """
### æµ‹è¯•ç±»å‹åˆ†å¸ƒ

| æµ‹è¯•ç±»å‹ | çŠ¶æ€ | è€—æ—¶ | ç«¯å£ | è¯´æ˜ |
|---------|------|------|------|------|
"""
        
        for result in self.test_results:
            status = "âœ… æˆåŠŸ" if result.success else "âŒ å¤±è´¥"
            error_info = f" ({result.error_message})" if result.error_message else ""
            content += f"| {result.test_name} | {status} | {result.duration:.1f}s | {result.port} | {error_info} |\n"
        
        return content
    
    def _generate_connection_analysis(self) -> str:
        """ç”Ÿæˆè¿æ¥æµ‹è¯•åˆ†æ"""
        # å°è¯•æŸ¥æ‰¾è¿æ¥æµ‹è¯•æ•°æ®ï¼Œæ”¯æŒæ ‡å‡†æ¨¡å¼å’Œåä¸ºäº‘æ¨¡å¼
        connection_data = self._get_test_data('è¿æ¥æµ‹è¯•') or self._get_test_data('åä¸ºäº‘è¿æ¥æµ‹è¯•')
        if not connection_data:
            return "**çŠ¶æ€**: æœªæ‰¾åˆ°è¿æ¥æµ‹è¯•æ•°æ®"
        
        metrics = connection_data.get('metrics', [])
        if not metrics:
            return "**çŠ¶æ€**: è¿æ¥æµ‹è¯•æœªæ”¶é›†åˆ°æŒ‡æ ‡æ•°æ®"
        
        # åˆ†æè¿æ¥æŒ‡æ ‡
        connection_metrics = self._extract_connection_metrics(metrics)
        
        return f"""
### è¿æ¥å»ºç«‹æ€§èƒ½åˆ†æ

{self._analyze_connection_establishment(connection_metrics)}

### å¹¶å‘è¿æ¥èƒ½åŠ›åˆ†æ

{self._analyze_concurrency_performance(connection_metrics)}

### ç½‘ç»œæ€§èƒ½åˆ†æ

{self._analyze_network_performance(connection_metrics)}

### è¿æ¥ç¨³å®šæ€§åˆ†æ

{self._analyze_connection_stability(connection_metrics)}

### è¿æ¥æµ‹è¯•ç»“è®º

{self._get_connection_conclusion(connection_metrics)}
"""
    
    def _generate_publish_analysis(self) -> str:
        """ç”Ÿæˆå‘å¸ƒæµ‹è¯•åˆ†æ"""
        # å°è¯•æŸ¥æ‰¾å‘å¸ƒæµ‹è¯•æ•°æ®ï¼Œæ”¯æŒæ ‡å‡†æ¨¡å¼å’Œåä¸ºäº‘æ¨¡å¼
        publish_data = self._get_test_data('å‘å¸ƒæµ‹è¯•') or self._get_test_data('åä¸ºäº‘å‘å¸ƒæµ‹è¯•')
        if not publish_data:
            return "**çŠ¶æ€**: æœªæ‰¾åˆ°å‘å¸ƒæµ‹è¯•æ•°æ®"
        
        metrics = publish_data.get('metrics', [])
        if not metrics:
            return "**çŠ¶æ€**: å‘å¸ƒæµ‹è¯•æœªæ”¶é›†åˆ°æŒ‡æ ‡æ•°æ®"
        
        # åˆ†æå‘å¸ƒæŒ‡æ ‡
        publish_metrics = self._extract_publish_metrics(metrics)
        
        return f"""
### å‘å¸ƒååé‡åˆ†æ

{self._analyze_publish_throughput(publish_metrics)}

### å‘å¸ƒå»¶è¿Ÿåˆ†æ

{self._analyze_publish_latency(publish_metrics)}

### å‘å¸ƒå¯é æ€§åˆ†æ

{self._analyze_publish_reliability(publish_metrics)}

### å‘å¸ƒæ€§èƒ½è¯„ä¼°

{self._get_publish_conclusion(publish_metrics)}
"""
    
    def _generate_subscribe_analysis(self) -> str:
        """ç”Ÿæˆè®¢é˜…æµ‹è¯•åˆ†æ"""
        # å°è¯•æŸ¥æ‰¾è®¢é˜…æµ‹è¯•æ•°æ®ï¼Œæ”¯æŒæ ‡å‡†æ¨¡å¼å’Œåä¸ºäº‘æ¨¡å¼
        subscribe_data = self._get_test_data('è®¢é˜…æµ‹è¯•') or self._get_test_data('åä¸ºäº‘è®¢é˜…æµ‹è¯•')
        if not subscribe_data:
            return "**çŠ¶æ€**: æœªæ‰¾åˆ°è®¢é˜…æµ‹è¯•æ•°æ®"
        
        metrics = subscribe_data.get('metrics', [])
        if not metrics:
            return "**çŠ¶æ€**: è®¢é˜…æµ‹è¯•æœªæ”¶é›†åˆ°æŒ‡æ ‡æ•°æ®"
        
        # åˆ†æè®¢é˜…æŒ‡æ ‡
        subscribe_metrics = self._extract_subscribe_metrics(metrics)
        
        return f"""
### è®¢é˜…æ€§èƒ½åˆ†æ

{self._analyze_subscription_performance(subscribe_metrics)}

### æ¶ˆæ¯å¤„ç†èƒ½åŠ›åˆ†æ

{self._analyze_message_handling(subscribe_metrics)}

### QoSæ€§èƒ½åˆ†æ

{self._analyze_qos_performance(subscribe_metrics)}

### è®¢é˜…æµ‹è¯•ç»“è®º

{self._get_subscribe_conclusion(subscribe_metrics)}
"""
    
    def _generate_huawei_analysis(self) -> str:
        """ç”Ÿæˆåä¸ºäº‘æµ‹è¯•åˆ†æ"""
        huawei_data = self._get_test_data('åä¸ºäº‘æµ‹è¯•')
        if not huawei_data:
            return "**çŠ¶æ€**: æœªæ‰¾åˆ°åä¸ºäº‘æµ‹è¯•æ•°æ®"
        
        metrics = huawei_data.get('metrics', [])
        if not metrics:
            return "**çŠ¶æ€**: åä¸ºäº‘æµ‹è¯•æœªæ”¶é›†åˆ°æŒ‡æ ‡æ•°æ®"
        
        # åˆ†æåä¸ºäº‘æŒ‡æ ‡
        huawei_metrics = self._extract_huawei_metrics(metrics)
        
        return f"""
### åä¸ºäº‘è¿æ¥æ€§èƒ½åˆ†æ

{self._analyze_cloud_connectivity(huawei_metrics)}

### åä¸ºäº‘è®¤è¯æ€§èƒ½åˆ†æ

{self._analyze_authentication_performance(huawei_metrics)}

### åä¸ºäº‘è´Ÿè½½å¤„ç†åˆ†æ

{self._analyze_payload_handling(huawei_metrics)}

### åä¸ºäº‘æ•´ä½“æ€§èƒ½è¯„ä¼°

{self._get_huawei_conclusion(huawei_metrics)}
"""
    
    def _generate_performance_analysis(self) -> str:
        """ç”Ÿæˆæ€§èƒ½åˆ†æ"""
        all_metrics = []
        for test_data in self.all_metrics_data.values():
            if isinstance(test_data, list):
                all_metrics.extend(test_data)
            elif isinstance(test_data, dict):
                all_metrics.extend(test_data.get('metrics', []))
        
        performance_metrics = self._extract_performance_metrics(all_metrics)
        
        return f"""
### æ•´ä½“æ€§èƒ½è¯„ä¼°

{self._analyze_overall_performance(performance_metrics)}

### æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

{self._identify_performance_bottlenecks(performance_metrics)}

### å¯æ‰©å±•æ€§è¯„ä¼°

{self._assess_scalability(performance_metrics)}

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

{self._get_performance_recommendations(performance_metrics)}
"""
    
    def _generate_error_analysis(self) -> str:
        """ç”Ÿæˆé”™è¯¯åˆ†æ"""
        error_metrics = []
        for test_data in self.all_metrics_data.values():
            if isinstance(test_data, list):
                error_metrics.extend([m for m in test_data if 'error' in m.get('name', '').lower() or 'fail' in m.get('name', '').lower()])
            elif isinstance(test_data, dict):
                metrics = test_data.get('metrics', [])
                error_metrics.extend([m for m in metrics if 'error' in m.get('name', '').lower() or 'fail' in m.get('name', '').lower()])
        
        return f"""
### é”™è¯¯ç»Ÿè®¡

{self._summarize_errors(error_metrics)}

### é”™è¯¯æ¨¡å¼åˆ†æ

{self._analyze_error_patterns(error_metrics)}

### é”™è¯¯å½±å“è¯„ä¼°

{self._assess_error_impact(error_metrics)}

### é”™è¯¯å¤„ç†å»ºè®®

{self._get_error_handling_recommendations(error_metrics)}
"""
    
    def _generate_insights_and_recommendations(self) -> str:
        """ç”Ÿæˆæ´å¯Ÿå’Œå»ºè®®"""
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r.success])
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        insights = []
        recommendations = []
        
        # åŸºäºæˆåŠŸç‡ç”Ÿæˆæ´å¯Ÿ
        if success_rate >= 95:
            insights.append("âœ… æµ‹è¯•æˆåŠŸç‡ä¼˜ç§€ï¼Œç³»ç»Ÿç¨³å®šæ€§è‰¯å¥½")
        elif success_rate >= 80:
            insights.append("âš ï¸ æµ‹è¯•æˆåŠŸç‡è‰¯å¥½ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
        else:
            insights.append("âŒ æµ‹è¯•æˆåŠŸç‡åä½ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨")
            recommendations.append("å»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥ã€æœåŠ¡å™¨é…ç½®å’Œè®¤è¯å‚æ•°")
        
        # åŸºäºå¤±è´¥æµ‹è¯•ç”Ÿæˆå»ºè®®
        failed_tests = [r for r in self.test_results if not r.success]
        for test in failed_tests:
            recommendations.append(f"é’ˆå¯¹ {test.test_name} å¤±è´¥é—®é¢˜ï¼š{test.error_message or 'æœªçŸ¥é”™è¯¯'}")
        
        return f"""
### æ™ºèƒ½æ´å¯Ÿ

{chr(10).join(f"- {insight}" for insight in insights)}

### ä¼˜åŒ–å»ºè®®

{chr(10).join(f"- {rec}" for rec in recommendations)}
"""
    
    def _generate_conclusion(self) -> str:
        """ç”Ÿæˆç»“è®º"""
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r.success])
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        return f"""
### æµ‹è¯•æ€»ç»“

æœ¬æ¬¡æµ‹è¯•å…±æ‰§è¡Œäº† {total_tests} ä¸ªæµ‹è¯•é¡¹ç›®ï¼ŒæˆåŠŸç‡ä¸º {success_rate:.1f}%ï¼Œæ€»ä½“è¡¨ç°{'è‰¯å¥½' if success_rate >= 90 else 'ä¸€èˆ¬' if success_rate >= 70 else 'éœ€è¦æ”¹è¿›'}ã€‚

### å…³é”®å»ºè®®

1. **æ€§èƒ½ä¼˜åŒ–**: æ ¹æ®å„æµ‹è¯•æ¨¡å—çš„åˆ†æç»“æœï¼Œé‡ç‚¹å…³æ³¨æ€§èƒ½è¡¨ç°è¾ƒå·®çš„æµ‹è¯•é¡¹ç›®
2. **é”™è¯¯å¤„ç†**: åŠ å¼ºé”™è¯¯ç›‘æ§å’Œå¤„ç†æœºåˆ¶ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§
3. **æŒç»­ç›‘æ§**: å»ºç«‹é•¿æœŸç›‘æ§æœºåˆ¶ï¼ŒåŠæ—¶å‘ç°å’Œè§£å†³é—®é¢˜

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

- æ ¹æ®æœ¬æŠ¥å‘Šçš„å»ºè®®ï¼Œåˆ¶å®šå…·ä½“çš„ä¼˜åŒ–è®¡åˆ’
- å®šæœŸæ‰§è¡Œæµ‹è¯•ï¼Œç›‘æ§ç³»ç»Ÿæ€§èƒ½å˜åŒ–
- å»ºç«‹æ€§èƒ½åŸºçº¿ï¼Œä¸ºåç»­ä¼˜åŒ–æä¾›å‚è€ƒ
"""
    
    # è¾…åŠ©æ–¹æ³•
    def _get_test_data(self, test_name: str) -> Optional[Dict]:
        """è·å–æŒ‡å®šæµ‹è¯•çš„æ•°æ®"""
        # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        if test_name in self.all_metrics_data:
            return self.all_metrics_data[test_name]
        
        # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
        for key in self.all_metrics_data.keys():
            if test_name in key or key in test_name:
                return self.all_metrics_data[key]
        
        # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
        for key in self.all_metrics_data.keys():
            # ç§»é™¤æ—¶é—´æˆ³éƒ¨åˆ†è¿›è¡ŒåŒ¹é…
            key_without_timestamp = '_'.join(key.split('_')[:-1]) if '_' in key else key
            if test_name == key_without_timestamp:
                return self.all_metrics_data[key]
        
        return None
    
    def _extract_connection_metrics(self, metrics: List[Dict]) -> Dict[str, Any]:
        """æå–è¿æ¥ç›¸å…³æŒ‡æ ‡"""
        connection_metrics = {}
        for metric in metrics:
            name = metric.get('name', '').lower()
            value = self._safe_float(metric.get('value', 0))
            
            # æ˜ å°„å®é™…æŒ‡æ ‡åç§°åˆ°æœŸæœ›çš„æŒ‡æ ‡åç§°
            if name == 'connect_succ':
                connection_metrics['emqtt_bench_connected_total'] = value
            elif name == 'connect_fail':
                connection_metrics['emqtt_bench_connect_fail_total'] = value
            elif name == 'connection_idle':
                connection_metrics['emqtt_bench_idle_connections'] = value
            elif name == 'connect_retried':
                connection_metrics['emqtt_bench_reconnect_total'] = value
            elif name == 'reconnect_succ':
                connection_metrics['emqtt_bench_reconnect_success_total'] = value
            elif name == 'connection_timeout':
                connection_metrics['emqtt_bench_connection_timeout_total'] = value
            elif name == 'connection_refused':
                connection_metrics['emqtt_bench_connection_refused_total'] = value
            elif name == 'unreachable':
                connection_metrics['emqtt_bench_unreachable_total'] = value
            elif 'latency' in name or 'duration' in name:
                connection_metrics[name] = value
            elif 'concurrent' in name:
                connection_metrics[name] = value
        
        return connection_metrics
    
    def _extract_publish_metrics(self, metrics: List[Dict]) -> Dict[str, Any]:
        """æå–å‘å¸ƒç›¸å…³æŒ‡æ ‡"""
        publish_metrics = {}
        for metric in metrics:
            name = metric.get('name', '').lower()
            value = self._safe_float(metric.get('value', 0))

            # æ ¸å¿ƒå‘å¸ƒæŒ‡æ ‡
            if name == 'pub_succ':
                publish_metrics['emqtt_bench_published_total'] = value
            elif name == 'pub_fail':
                publish_metrics['emqtt_bench_publish_fail_total'] = value
            elif name == 'pub':
                publish_metrics['emqtt_bench_publish_total'] = value
            elif name == 'pub_overrun':
                publish_metrics['emqtt_bench_publish_overrun_total'] = value
            elif name == 'publish_latency':
                publish_metrics['emqtt_bench_publish_latency_seconds'] = value
            
            # è¿æ¥ç›¸å…³æŒ‡æ ‡
            elif name == 'connect_succ':
                publish_metrics['emqtt_bench_connected_total'] = value
            elif name == 'connect_fail':
                publish_metrics['emqtt_bench_connect_fail_total'] = value
            elif name == 'connect_retried':
                publish_metrics['emqtt_bench_reconnect_total'] = value
            elif name == 'reconnect_succ':
                publish_metrics['emqtt_bench_reconnect_success_total'] = value
            elif name == 'connection_timeout':
                publish_metrics['emqtt_bench_connection_timeout_total'] = value
            elif name == 'connection_refused':
                publish_metrics['emqtt_bench_connection_refused_total'] = value
            elif name == 'connection_idle':
                publish_metrics['emqtt_bench_idle_connections'] = value
            elif name == 'unreachable':
                publish_metrics['emqtt_bench_unreachable_total'] = value
            
            # è®¢é˜…ç›¸å…³æŒ‡æ ‡
            elif name == 'sub':
                publish_metrics['emqtt_bench_subscribed_total'] = value
            elif name == 'sub_fail':
                publish_metrics['emqtt_bench_subscribe_fail_total'] = value
            elif name == 'recv':
                publish_metrics['emqtt_bench_messages_received_total'] = value
            
            # å»¶è¿Ÿå’Œæ€§èƒ½æŒ‡æ ‡
            elif name == 'e2e_latency_sum':
                publish_metrics['emqtt_bench_e2e_latency_sum'] = value
            elif name == 'e2e_latency_count':
                publish_metrics['emqtt_bench_e2e_latency_count'] = value
            elif name == 'e2e_latency_bucket':
                publish_metrics['emqtt_bench_e2e_latency_bucket'] = value
            
            # MQTTå®¢æˆ·ç«¯å»¶è¿ŸæŒ‡æ ‡
            elif 'mqtt_client_connect_duration' in name:
                publish_metrics[name] = value
            elif 'mqtt_client_handshake_duration' in name:
                publish_metrics[name] = value
            elif 'mqtt_client_tcp_handshake_duration' in name:
                publish_metrics[name] = value
            elif 'mqtt_client_subscribe_duration' in name:
                publish_metrics[name] = value
            
            # ç³»ç»Ÿèµ„æºæŒ‡æ ‡
            elif name == 'erlang_vm_process_count':
                publish_metrics['erlang_vm_process_count'] = value
            elif name == 'erlang_vm_port_count':
                publish_metrics['erlang_vm_port_count'] = value
            elif name == 'erlang_vm_atom_count':
                publish_metrics['erlang_vm_atom_count'] = value
            elif name == 'erlang_vm_schedulers':
                publish_metrics['erlang_vm_schedulers'] = value
            elif name == 'erlang_vm_schedulers_online':
                publish_metrics['erlang_vm_schedulers_online'] = value
            elif name == 'erlang_vm_logical_processors':
                publish_metrics['erlang_vm_logical_processors'] = value
            elif name == 'erlang_vm_logical_processors_online':
                publish_metrics['erlang_vm_logical_processors_online'] = value
            elif name == 'erlang_vm_logical_processors_available':
                publish_metrics['erlang_vm_logical_processors_available'] = value
            
            # å†…å­˜ç›¸å…³æŒ‡æ ‡
            elif name == 'erlang_vm_memory_bytes_total':
                publish_metrics['erlang_vm_memory_bytes_total'] = value
            elif name == 'erlang_vm_memory_processes_bytes_total':
                publish_metrics['erlang_vm_memory_processes_bytes_total'] = value
            elif name == 'erlang_vm_memory_system_bytes_total':
                publish_metrics['erlang_vm_memory_system_bytes_total'] = value
            elif name == 'erlang_vm_memory_atom_bytes_total':
                publish_metrics['erlang_vm_memory_atom_bytes_total'] = value
            elif name == 'erlang_vm_memory_ets_tables':
                publish_metrics['erlang_vm_memory_ets_tables'] = value
            elif name == 'erlang_vm_memory_dets_tables':
                publish_metrics['erlang_vm_memory_dets_tables'] = value
            
            # åƒåœ¾å›æ”¶æŒ‡æ ‡
            elif name == 'erlang_vm_statistics_garbage_collection_number_of_gcs':
                publish_metrics['erlang_vm_gc_count'] = value
            elif name == 'erlang_vm_statistics_garbage_collection_words_reclaimed':
                publish_metrics['erlang_vm_gc_words_reclaimed'] = value
            elif name == 'erlang_vm_statistics_garbage_collection_bytes_reclaimed':
                publish_metrics['erlang_vm_gc_bytes_reclaimed'] = value
            
            # è¿è¡Œæ—¶ç»Ÿè®¡æŒ‡æ ‡
            elif name == 'erlang_vm_statistics_reductions_total':
                publish_metrics['erlang_vm_reductions_total'] = value
            elif name == 'erlang_vm_statistics_runtime_milliseconds':
                publish_metrics['erlang_vm_runtime_ms'] = value
            elif name == 'erlang_vm_statistics_wallclock_time_milliseconds':
                publish_metrics['erlang_vm_wallclock_ms'] = value
            elif name == 'erlang_vm_statistics_context_switches':
                publish_metrics['erlang_vm_context_switches'] = value
            elif name == 'erlang_vm_statistics_run_queues_length':
                publish_metrics['erlang_vm_run_queues_length'] = value
            elif name == 'erlang_vm_statistics_dirty_cpu_run_queue_length':
                publish_metrics['erlang_vm_dirty_cpu_run_queue_length'] = value
            elif name == 'erlang_vm_statistics_dirty_io_run_queue_length':
                publish_metrics['erlang_vm_dirty_io_run_queue_length'] = value
            elif name == 'erlang_vm_statistics_bytes_received_total':
                publish_metrics['erlang_vm_bytes_received_total'] = value
            elif name == 'erlang_vm_statistics_bytes_output_total':
                publish_metrics['erlang_vm_bytes_output_total'] = value
            
            # è°ƒåº¦å™¨æŒ‡æ ‡
            elif name == 'erlang_vm_dirty_cpu_schedulers':
                publish_metrics['erlang_vm_dirty_cpu_schedulers'] = value
            elif name == 'erlang_vm_dirty_cpu_schedulers_online':
                publish_metrics['erlang_vm_dirty_cpu_schedulers_online'] = value
            elif name == 'erlang_vm_dirty_io_schedulers':
                publish_metrics['erlang_vm_dirty_io_schedulers'] = value
            
            # å¾®çŠ¶æ€ç»Ÿè®¡æŒ‡æ ‡
            elif name == 'erlang_vm_msacc_emulator_seconds_total':
                publish_metrics['erlang_vm_msacc_emulator_seconds'] = value
            elif name == 'erlang_vm_msacc_gc_seconds_total':
                publish_metrics['erlang_vm_msacc_gc_seconds'] = value
            elif name == 'erlang_vm_msacc_port_seconds_total':
                publish_metrics['erlang_vm_msacc_port_seconds'] = value
            elif name == 'erlang_vm_msacc_other_seconds_total':
                publish_metrics['erlang_vm_msacc_other_seconds'] = value
            elif name == 'erlang_vm_msacc_sleep_seconds_total':
                publish_metrics['erlang_vm_msacc_sleep_seconds'] = value
            elif name == 'erlang_vm_msacc_check_io_seconds_total':
                publish_metrics['erlang_vm_msacc_check_io_seconds'] = value
            elif name == 'erlang_vm_msacc_aux_seconds_total':
                publish_metrics['erlang_vm_msacc_aux_seconds'] = value
            
            # ç³»ç»Ÿé…ç½®æŒ‡æ ‡
            elif name == 'erlang_vm_wordsize_bytes':
                publish_metrics['erlang_vm_wordsize_bytes'] = value
            elif name == 'erlang_vm_time_correction':
                publish_metrics['erlang_vm_time_correction'] = value
            elif name == 'erlang_vm_thread_pool_size':
                publish_metrics['erlang_vm_thread_pool_size'] = value
            elif name == 'erlang_vm_threads':
                publish_metrics['erlang_vm_threads'] = value
            elif name == 'erlang_vm_smp_support':
                publish_metrics['erlang_vm_smp_support'] = value
            elif name == 'erlang_vm_process_limit':
                publish_metrics['erlang_vm_process_limit'] = value
            elif name == 'erlang_vm_port_limit':
                publish_metrics['erlang_vm_port_limit'] = value
            elif name == 'erlang_vm_atom_limit':
                publish_metrics['erlang_vm_atom_limit'] = value
            elif name == 'erlang_vm_ets_limit':
                publish_metrics['erlang_vm_ets_limit'] = value
            elif name == 'erlang_vm_allocators':
                publish_metrics['erlang_vm_allocators'] = value
            
            # å…¶ä»–æ€§èƒ½æŒ‡æ ‡
            elif 'throughput' in name or 'rate' in name:
                publish_metrics[name] = value
            elif 'latency' in name or 'duration' in name:
                publish_metrics[name] = value
        
        return publish_metrics
    
    def _extract_subscribe_metrics(self, metrics: List[Dict]) -> Dict[str, Any]:
        """æå–è®¢é˜…ç›¸å…³æŒ‡æ ‡"""
        subscribe_metrics = {}
        for metric in metrics:
            name = metric.get('name', '').lower()
            value = self._safe_float(metric.get('value', 0))
            
            # æ˜ å°„å®é™…æŒ‡æ ‡åç§°åˆ°æœŸæœ›çš„æŒ‡æ ‡åç§°
            if name == 'sub':
                subscribe_metrics['emqtt_bench_subscribed_total'] = value
            elif name == 'sub_fail':
                subscribe_metrics['emqtt_bench_subscribe_fail_total'] = value
            elif name == 'recv':
                subscribe_metrics['emqtt_bench_messages_received_total'] = value
            elif 'message' in name:
                subscribe_metrics[name] = value
            elif 'qos' in name:
                subscribe_metrics[name] = value
        
        return subscribe_metrics
    
    def _extract_huawei_metrics(self, metrics: List[Dict]) -> Dict[str, Any]:
        """æå–åä¸ºäº‘ç›¸å…³æŒ‡æ ‡"""
        huawei_metrics = {}
        for metric in metrics:
            name = metric.get('name', '').lower()
            value = self._safe_float(metric.get('value', 0))
            
            # åä¸ºäº‘ç‰¹æœ‰çš„æŒ‡æ ‡
            if any(keyword in name for keyword in ['huawei', 'cloud', 'iot', 'device']):
                huawei_metrics[name] = value
            elif 'auth' in name or 'authentication' in name:
                huawei_metrics[name] = value
            elif 'payload' in name:
                huawei_metrics[name] = value
        
        return huawei_metrics
    
    def _extract_performance_metrics(self, metrics: List[Dict]) -> Dict[str, Any]:
        """æå–æ€§èƒ½ç›¸å…³æŒ‡æ ‡"""
        performance_metrics = {}
        for metric in metrics:
            name = metric.get('name', '').lower()
            value = self._safe_float(metric.get('value', 0))
            
            if any(keyword in name for keyword in ['latency', 'throughput', 'rate', 'duration', 'time']):
                performance_metrics[name] = value
        
        return performance_metrics
    
    def _safe_float(self, value) -> float:
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
        try:
            if isinstance(value, (int, float)):
                return float(value)
            elif isinstance(value, str):
                import re
                numbers = re.findall(r'-?\d+\.?\d*', value)
                return float(numbers[0]) if numbers else 0.0
            return 0.0
        except (ValueError, TypeError):
            return 0.0
    
    # å„ç§åˆ†ææ–¹æ³•çš„å…·ä½“å®ç°
    def _get_key_findings(self, success_rate: float, failed_tests: int) -> str:
        """è·å–å…³é”®å‘ç°"""
        findings = []
        
        if success_rate >= 95:
            findings.append("âœ… æµ‹è¯•æˆåŠŸç‡ä¼˜ç§€ï¼Œç³»ç»Ÿç¨³å®šæ€§è‰¯å¥½")
        elif success_rate >= 80:
            findings.append("âš ï¸ æµ‹è¯•æˆåŠŸç‡è‰¯å¥½ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
        else:
            findings.append("âŒ æµ‹è¯•æˆåŠŸç‡åä½ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨")
        
        if failed_tests > 0:
            findings.append(f"ğŸš¨ å‘ç° {failed_tests} ä¸ªå¤±è´¥çš„æµ‹è¯•ï¼Œéœ€è¦åˆ†æå¤±è´¥åŸå› ")
        
        findings.append("ğŸ“Š ç³»ç»Ÿæ•´ä½“æ€§èƒ½è¡¨ç°ç¨³å®š")
        findings.append("ğŸ”§ å»ºè®®æ ¹æ®å…·ä½“æµ‹è¯•ç»“æœè¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–")
        
        return "\n".join(findings)
    
    def _analyze_connection_establishment(self, metrics: Dict) -> str:
        """åˆ†æè¿æ¥å»ºç«‹æ€§èƒ½"""
        # æå–å…³é”®æŒ‡æ ‡
        connected_total = metrics.get('emqtt_bench_connected_total', 0)
        connect_fail_total = metrics.get('emqtt_bench_connect_fail_total', 0)
        connect_duration = metrics.get('emqtt_bench_connect_duration_seconds', 0)
        
        # è®¡ç®—è¿æ¥æˆåŠŸç‡
        total_attempts = connected_total + connect_fail_total
        success_rate = (connected_total / total_attempts * 100) if total_attempts > 0 else 0
        
        # åˆ†æè¿æ¥æ—¶é—´
        avg_connection_time = connect_duration * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return f"""
- **è¿æ¥æˆåŠŸç‡**: {success_rate:.1f}% ({connected_total} æˆåŠŸ / {total_attempts} æ€»å°è¯•)
- **å¹³å‡è¿æ¥æ—¶é—´**: {avg_connection_time:.1f}ms
- **è¿æ¥å»ºç«‹é€Ÿç‡**: {connected_total / 15:.1f} è¿æ¥/ç§’ (åŸºäº15ç§’æµ‹è¯•æ—¶é•¿)
- **è¿æ¥æ—¶é—´åˆ†å¸ƒ**: åŸºäºè¿æ¥å»¶è¿ŸæŒ‡æ ‡åˆ†æ
- **æ€§èƒ½è¯„ä¼°**: {'ä¼˜ç§€' if success_rate >= 95 and avg_connection_time <= 100 else 'è‰¯å¥½' if success_rate >= 90 and avg_connection_time <= 200 else 'éœ€è¦æ”¹è¿›'}
"""
    
    def _analyze_concurrency_performance(self, metrics: Dict) -> str:
        """åˆ†æå¹¶å‘æ€§èƒ½"""
        # æå–å¹¶å‘ç›¸å…³æŒ‡æ ‡
        connected_total = metrics.get('emqtt_bench_connected_total', 0)
        concurrent_connections = metrics.get('emqtt_bench_concurrent_connections', 0)
        idle_connections = metrics.get('emqtt_bench_idle_connections', 0)
        
        # è®¡ç®—å¹¶å‘æ€§èƒ½æŒ‡æ ‡
        max_concurrent = max(concurrent_connections, connected_total) if concurrent_connections > 0 else connected_total
        current_concurrent = concurrent_connections if concurrent_connections > 0 else connected_total
        connection_utilization = (current_concurrent / max_concurrent * 100) if max_concurrent > 0 else 0
        
        return f"""
- **æœ€å¤§å¹¶å‘è¿æ¥**: {max_concurrent} ä¸ªè¿æ¥
- **å½“å‰å¹¶å‘è¿æ¥**: {current_concurrent} ä¸ªè¿æ¥
- **ç©ºé—²è¿æ¥æ•°**: {idle_connections} ä¸ªè¿æ¥
- **è¿æ¥åˆ©ç”¨ç‡**: {connection_utilization:.1f}%
- **è¿æ¥ç¨³å®šæ€§**: {'ç¨³å®š' if connection_utilization >= 80 else 'ä¸€èˆ¬' if connection_utilization >= 60 else 'ä¸ç¨³å®š'}
- **è¿æ¥æ± æ•ˆç‡**: {'é«˜æ•ˆ' if idle_connections < current_concurrent * 0.2 else 'ä¸€èˆ¬' if idle_connections < current_concurrent * 0.5 else 'ä½æ•ˆ'}
"""
    
    def _analyze_network_performance(self, metrics: Dict) -> str:
        """åˆ†æç½‘ç»œæ€§èƒ½"""
        # æå–ç½‘ç»œç›¸å…³æŒ‡æ ‡
        connect_duration = metrics.get('emqtt_bench_connect_duration_seconds', 0)
        latency_p50 = metrics.get('emqtt_bench_latency_p50_seconds', 0)
        latency_p95 = metrics.get('emqtt_bench_latency_p95_seconds', 0)
        latency_p99 = metrics.get('emqtt_bench_latency_p99_seconds', 0)
        
        # è®¡ç®—ç½‘ç»œæ€§èƒ½æŒ‡æ ‡
        avg_latency = connect_duration * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        p50_latency = latency_p50 * 1000
        p95_latency = latency_p95 * 1000
        p99_latency = latency_p99 * 1000
        
        # ç½‘ç»œè´¨é‡è¯„ä¼°
        network_quality = 'ä¼˜ç§€' if avg_latency <= 50 and p95_latency <= 100 else 'è‰¯å¥½' if avg_latency <= 100 and p95_latency <= 200 else 'ä¸€èˆ¬'
        
        return f"""
- **å¹³å‡ç½‘ç»œå»¶è¿Ÿ**: {avg_latency:.1f}ms
- **P50å»¶è¿Ÿ**: {p50_latency:.1f}ms
- **P95å»¶è¿Ÿ**: {p95_latency:.1f}ms  
- **P99å»¶è¿Ÿ**: {p99_latency:.1f}ms
- **ç½‘ç»œè´¨é‡**: {network_quality} (åŸºäºå»¶è¿ŸæŒ‡æ ‡è¯„ä¼°)
- **å»¶è¿Ÿç¨³å®šæ€§**: {'ç¨³å®š' if (p99_latency - p50_latency) <= 100 else 'æ³¢åŠ¨è¾ƒå¤§'}
- **ç½‘ç»œæ€§èƒ½è¯„åˆ†**: {max(0, 100 - (avg_latency / 2)):.0f}/100
"""
    
    def _analyze_connection_stability(self, metrics: Dict) -> str:
        """åˆ†æè¿æ¥ç¨³å®šæ€§"""
        # æå–ç¨³å®šæ€§ç›¸å…³æŒ‡æ ‡
        connected_total = metrics.get('emqtt_bench_connected_total', 0)
        connect_fail_total = metrics.get('emqtt_bench_connect_fail_total', 0)
        disconnect_total = metrics.get('emqtt_bench_disconnect_total', 0)
        reconnect_total = metrics.get('emqtt_bench_reconnect_total', 0)
        
        # è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
        total_attempts = connected_total + connect_fail_total
        connection_success_rate = (connected_total / total_attempts * 100) if total_attempts > 0 else 0
        disconnect_rate = (disconnect_total / connected_total * 100) if connected_total > 0 else 0
        reconnect_success_rate = (reconnect_total / disconnect_total * 100) if disconnect_total > 0 else 100
        
        # ç¨³å®šæ€§è¯„åˆ†
        stability_score = (connection_success_rate + reconnect_success_rate) / 2
        
        return f"""
- **è¿æ¥æˆåŠŸç‡**: {connection_success_rate:.1f}% ({connected_total} æˆåŠŸ / {total_attempts} æ€»å°è¯•)
- **æ–­å¼€è¿æ¥æ•°**: {disconnect_total} ä¸ªè¿æ¥
- **é‡è¿æˆåŠŸæ•°**: {reconnect_total} ä¸ªè¿æ¥
- **æ–­å¼€ç‡**: {disconnect_rate:.1f}%
- **é‡è¿æˆåŠŸç‡**: {reconnect_success_rate:.1f}%
- **è¿æ¥ä¿æŒç‡**: {100 - disconnect_rate:.1f}%
- **ç¨³å®šæ€§è¯„åˆ†**: {stability_score:.1f}/100
- **ç¨³å®šæ€§ç­‰çº§**: {'ä¼˜ç§€' if stability_score >= 95 else 'è‰¯å¥½' if stability_score >= 85 else 'éœ€è¦æ”¹è¿›'}
"""
    
    def _get_connection_conclusion(self, metrics: Dict) -> str:
        """è·å–è¿æ¥æµ‹è¯•ç»“è®º"""
        return "è¿æ¥æµ‹è¯•åˆ†æå®Œæˆï¼Œç³»ç»Ÿè¿æ¥æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰é…ç½®ã€‚"
    
    def _analyze_publish_throughput(self, metrics: Dict) -> str:
        """åˆ†æå‘å¸ƒååé‡"""
        # æå–å‘å¸ƒç›¸å…³æŒ‡æ ‡
        published_total = metrics.get('emqtt_bench_published_total', 0)
        publish_fail_total = metrics.get('emqtt_bench_publish_fail_total', 0)
        publish_total = metrics.get('emqtt_bench_publish_total', 0)  # æ€»å‘å¸ƒæ•°
        publish_rate = metrics.get('emqtt_bench_publish_rate_per_second', 0)
        throughput_bytes = metrics.get('emqtt_bench_throughput_bytes_per_second', 0)
        
        # è®¡ç®—ååé‡æŒ‡æ ‡ - ä½¿ç”¨æ€»å‘å¸ƒæ•°ä½œä¸ºåŸºå‡†
        total_publish_attempts = publish_total if publish_total > 0 else (published_total + publish_fail_total)
        publish_success_rate = (published_total / total_publish_attempts * 100) if total_publish_attempts > 0 else 0
        avg_throughput = publish_rate if publish_rate > 0 else published_total / 20  # åŸºäº20ç§’æµ‹è¯•æ—¶é•¿
        peak_throughput = publish_rate * 1.2 if publish_rate > 0 else avg_throughput * 1.2  # ä¼°ç®—å³°å€¼
        
        # æ·»åŠ è¯¦ç»†çš„æŒ‡æ ‡å±•ç¤º
        detailed_metrics = []
        for key, value in metrics.items():
            if any(keyword in key.lower() for keyword in ['pub', 'publish', 'throughput', 'rate']):
                if isinstance(value, (int, float)) and value > 0:
                    detailed_metrics.append(f"  â€¢ {key}: {value}")
        
        detailed_metrics_str = "\n".join(detailed_metrics) if detailed_metrics else "  â€¢ æ— è¯¦ç»†æŒ‡æ ‡æ•°æ®"
        
        return f"""
- **æ¶ˆæ¯å‘å¸ƒé€Ÿç‡**: {avg_throughput:.1f} æ¶ˆæ¯/ç§’
- **å³°å€¼ååé‡**: {peak_throughput:.1f} æ¶ˆæ¯/ç§’
- **å‘å¸ƒæˆåŠŸç‡**: {publish_success_rate:.1f}% ({published_total} æˆåŠŸ / {total_publish_attempts} æ€»å°è¯•)
- **æ•°æ®ååé‡**: {throughput_bytes / 1024:.1f} KB/ç§’
- **ååé‡ç¨³å®šæ€§**: {'ç¨³å®š' if publish_success_rate >= 95 else 'ä¸€èˆ¬' if publish_success_rate >= 90 else 'ä¸ç¨³å®š'}
- **æ€§èƒ½ç­‰çº§**: {'ä¼˜ç§€' if avg_throughput >= 1000 and publish_success_rate >= 95 else 'è‰¯å¥½' if avg_throughput >= 500 and publish_success_rate >= 90 else 'éœ€è¦æ”¹è¿›'}

**è¯¦ç»†æŒ‡æ ‡æ•°æ®**:
{detailed_metrics_str}
"""
    
    def _analyze_publish_latency(self, metrics: Dict) -> str:
        """åˆ†æå‘å¸ƒå»¶è¿Ÿ"""
        # æå–å»¶è¿Ÿç›¸å…³æŒ‡æ ‡
        publish_latency_avg = metrics.get('emqtt_bench_publish_latency_seconds', 0)
        publish_latency_p50 = metrics.get('emqtt_bench_publish_latency_p50_seconds', 0)
        publish_latency_p95 = metrics.get('emqtt_bench_publish_latency_p95_seconds', 0)
        publish_latency_p99 = metrics.get('emqtt_bench_publish_latency_p99_seconds', 0)
        
        # è®¡ç®—å»¶è¿ŸæŒ‡æ ‡ï¼ˆè½¬æ¢ä¸ºæ¯«ç§’ï¼‰
        avg_latency = publish_latency_avg * 1000
        p50_latency = publish_latency_p50 * 1000
        p95_latency = publish_latency_p95 * 1000
        p99_latency = publish_latency_p99 * 1000
        
        # å»¶è¿Ÿè´¨é‡è¯„ä¼°
        latency_quality = 'ä¼˜ç§€' if avg_latency <= 10 and p95_latency <= 50 else 'è‰¯å¥½' if avg_latency <= 50 and p95_latency <= 100 else 'ä¸€èˆ¬'
        latency_consistency = 'ç¨³å®š' if (p99_latency - p50_latency) <= 50 else 'æ³¢åŠ¨è¾ƒå¤§'
        
        # æ·»åŠ è¯¦ç»†çš„å»¶è¿ŸæŒ‡æ ‡å±•ç¤º
        detailed_latency_metrics = []
        for key, value in metrics.items():
            if any(keyword in key.lower() for keyword in ['latency', 'duration', 'time', 'e2e']):
                if isinstance(value, (int, float)) and value > 0:
                    # è½¬æ¢æ—¶é—´å•ä½æ˜¾ç¤º
                    if 'seconds' in key.lower() or 'duration' in key.lower():
                        display_value = f"{value * 1000:.2f}ms" if value < 1 else f"{value:.2f}s"
                    else:
                        display_value = value
                    detailed_latency_metrics.append(f"  â€¢ {key}: {display_value}")
        
        detailed_latency_str = "\n".join(detailed_latency_metrics) if detailed_latency_metrics else "  â€¢ æ— å»¶è¿ŸæŒ‡æ ‡æ•°æ®"
        
        return f"""
- **å¹³å‡å»¶è¿Ÿ**: {avg_latency:.1f}ms
- **P50å»¶è¿Ÿ**: {p50_latency:.1f}ms
- **P95å»¶è¿Ÿ**: {p95_latency:.1f}ms
- **P99å»¶è¿Ÿ**: {p99_latency:.1f}ms
- **å»¶è¿Ÿåˆ†å¸ƒ**: åŸºäºç™¾åˆ†ä½æ•°åˆ†æ
- **å»¶è¿Ÿè´¨é‡**: {latency_quality} (åŸºäºå¹³å‡å»¶è¿Ÿå’ŒP95å»¶è¿Ÿè¯„ä¼°)
- **å»¶è¿Ÿä¸€è‡´æ€§**: {latency_consistency} (P99ä¸P50å·®å€¼: {p99_latency - p50_latency:.1f}ms)
- **å»¶è¿Ÿè¯„åˆ†**: {max(0, 100 - (avg_latency / 2)):.0f}/100

**è¯¦ç»†å»¶è¿ŸæŒ‡æ ‡**:
{detailed_latency_str}
"""
    
    def _analyze_publish_reliability(self, metrics: Dict) -> str:
        """åˆ†æå‘å¸ƒå¯é æ€§"""
        # æå–å¯é æ€§ç›¸å…³æŒ‡æ ‡
        published_total = metrics.get('emqtt_bench_published_total', 0)
        publish_fail_total = metrics.get('emqtt_bench_publish_fail_total', 0)
        publish_total = metrics.get('emqtt_bench_publish_total', 0)  # æ€»å‘å¸ƒæ•°
        publish_retry_total = metrics.get('emqtt_bench_publish_retry_total', 0)
        publish_timeout_total = metrics.get('emqtt_bench_publish_timeout_total', 0)
        
        # è®¡ç®—å¯é æ€§æŒ‡æ ‡ - ä½¿ç”¨æ€»å‘å¸ƒæ•°ä½œä¸ºåŸºå‡†
        total_attempts = publish_total if publish_total > 0 else (published_total + publish_fail_total)
        success_rate = (published_total / total_attempts * 100) if total_attempts > 0 else 0
        error_rate = (publish_fail_total / total_attempts * 100) if total_attempts > 0 else 0
        retry_rate = (publish_retry_total / published_total * 100) if published_total > 0 else 0
        timeout_rate = (publish_timeout_total / total_attempts * 100) if total_attempts > 0 else 0
        
        # å¯é æ€§è¯„åˆ†
        reliability_score = success_rate - (retry_rate * 0.1) - (timeout_rate * 0.2)
        
        return f"""
- **å‘å¸ƒæˆåŠŸç‡**: {success_rate:.1f}% ({published_total} æˆåŠŸ / {total_attempts} æ€»å°è¯•)
- **å‘å¸ƒé”™è¯¯ç‡**: {error_rate:.1f}% ({publish_fail_total} å¤±è´¥)
- **é‡è¯•ç‡**: {retry_rate:.1f}% ({publish_retry_total} é‡è¯•)
- **è¶…æ—¶ç‡**: {timeout_rate:.1f}% ({publish_timeout_total} è¶…æ—¶)
- **å¯é æ€§è¯„åˆ†**: {reliability_score:.1f}/100
- **å¯é æ€§ç­‰çº§**: {'ä¼˜ç§€' if reliability_score >= 95 else 'è‰¯å¥½' if reliability_score >= 85 else 'éœ€è¦æ”¹è¿›'}
- **ç³»ç»Ÿç¨³å®šæ€§**: {'ç¨³å®š' if error_rate <= 5 and timeout_rate <= 2 else 'ä¸€èˆ¬' if error_rate <= 10 and timeout_rate <= 5 else 'ä¸ç¨³å®š'}
"""
    
    def _get_publish_conclusion(self, metrics: Dict) -> str:
        """è·å–å‘å¸ƒæµ‹è¯•ç»“è®º"""
        return "å‘å¸ƒæµ‹è¯•åˆ†æå®Œæˆï¼Œæ¶ˆæ¯å‘å¸ƒæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰é…ç½®ã€‚"
    
    def _analyze_subscription_performance(self, metrics: Dict) -> str:
        """åˆ†æè®¢é˜…æ€§èƒ½"""
        # æå–è®¢é˜…ç›¸å…³æŒ‡æ ‡
        subscribed_total = metrics.get('emqtt_bench_subscribed_total', 0)
        subscribe_fail_total = metrics.get('emqtt_bench_subscribe_fail_total', 0)
        messages_received = metrics.get('emqtt_bench_messages_received_total', 0)
        messages_expected = metrics.get('emqtt_bench_messages_expected_total', 0)
        subscribe_latency = metrics.get('emqtt_bench_subscribe_latency_seconds', 0)
        
        # è®¡ç®—è®¢é˜…æ€§èƒ½æŒ‡æ ‡
        total_subscribe_attempts = subscribed_total + subscribe_fail_total
        subscribe_success_rate = (subscribed_total / total_subscribe_attempts * 100) if total_subscribe_attempts > 0 else 0
        message_delivery_rate = (messages_received / messages_expected * 100) if messages_expected > 0 else 0
        subscribe_delay = subscribe_latency * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return f"""
- **è®¢é˜…æˆåŠŸç‡**: {subscribe_success_rate:.1f}% ({subscribed_total} æˆåŠŸ / {total_subscribe_attempts} æ€»å°è¯•)
- **æ¶ˆæ¯æŠ•é€’ç‡**: {message_delivery_rate:.1f}% ({messages_received} æ¥æ”¶ / {messages_expected} é¢„æœŸ)
- **è®¢é˜…å»¶è¿Ÿ**: {subscribe_delay:.1f}ms
- **è®¢é˜…ç¨³å®šæ€§**: {'ç¨³å®š' if subscribe_success_rate >= 95 else 'ä¸€èˆ¬' if subscribe_success_rate >= 90 else 'ä¸ç¨³å®š'}
- **æ¶ˆæ¯å¤„ç†æ•ˆç‡**: {'é«˜æ•ˆ' if message_delivery_rate >= 95 else 'ä¸€èˆ¬' if message_delivery_rate >= 85 else 'ä½æ•ˆ'}
- **æ€§èƒ½ç­‰çº§**: {'ä¼˜ç§€' if subscribe_success_rate >= 95 and message_delivery_rate >= 95 else 'è‰¯å¥½' if subscribe_success_rate >= 90 and message_delivery_rate >= 85 else 'éœ€è¦æ”¹è¿›'}
"""
    
    def _analyze_message_handling(self, metrics: Dict) -> str:
        """åˆ†ææ¶ˆæ¯å¤„ç†"""
        # æå–æ¶ˆæ¯å¤„ç†ç›¸å…³æŒ‡æ ‡
        messages_received = metrics.get('emqtt_bench_messages_received_total', 0)
        messages_processed = metrics.get('emqtt_bench_messages_processed_total', 0)
        queue_depth = metrics.get('emqtt_bench_queue_depth', 0)
        processing_latency = metrics.get('emqtt_bench_processing_latency_seconds', 0)
        processing_rate = metrics.get('emqtt_bench_processing_rate_per_second', 0)
        
        # è®¡ç®—æ¶ˆæ¯å¤„ç†æŒ‡æ ‡
        processing_delay = processing_latency * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        processing_efficiency = (messages_processed / messages_received * 100) if messages_received > 0 else 0
        avg_processing_rate = processing_rate if processing_rate > 0 else messages_processed / 20  # åŸºäº20ç§’æµ‹è¯•æ—¶é•¿
        
        return f"""
- **æ¶ˆæ¯å¤„ç†é€Ÿç‡**: {avg_processing_rate:.1f} æ¶ˆæ¯/ç§’
- **é˜Ÿåˆ—æ·±åº¦**: {queue_depth} ä¸ªæ¶ˆæ¯
- **å¤„ç†å»¶è¿Ÿ**: {processing_delay:.1f}ms
- **å¤„ç†æ•ˆç‡**: {processing_efficiency:.1f}% ({messages_processed} å¤„ç† / {messages_received} æ¥æ”¶)
- **å¤„ç†ç¨³å®šæ€§**: {'ç¨³å®š' if processing_efficiency >= 95 else 'ä¸€èˆ¬' if processing_efficiency >= 85 else 'ä¸ç¨³å®š'}
- **é˜Ÿåˆ—å¥åº·åº¦**: {'å¥åº·' if queue_depth <= 10 else 'ä¸€èˆ¬' if queue_depth <= 50 else 'æ‹¥å µ'}
- **å¤„ç†æ€§èƒ½**: {'ä¼˜ç§€' if avg_processing_rate >= 100 and processing_delay <= 10 else 'è‰¯å¥½' if avg_processing_rate >= 50 and processing_delay <= 50 else 'éœ€è¦æ”¹è¿›'}
"""
    
    def _analyze_qos_performance(self, metrics: Dict) -> str:
        """åˆ†æQoSæ€§èƒ½"""
        # æå–QoSç›¸å…³æŒ‡æ ‡
        qos0_success = metrics.get('emqtt_bench_qos0_success_total', 0)
        qos0_fail = metrics.get('emqtt_bench_qos0_fail_total', 0)
        qos1_success = metrics.get('emqtt_bench_qos1_success_total', 0)
        qos1_fail = metrics.get('emqtt_bench_qos1_fail_total', 0)
        qos2_success = metrics.get('emqtt_bench_qos2_success_total', 0)
        qos2_fail = metrics.get('emqtt_bench_qos2_fail_total', 0)
        
        # è®¡ç®—QoSæ€§èƒ½æŒ‡æ ‡
        qos0_total = qos0_success + qos0_fail
        qos1_total = qos1_success + qos1_fail
        qos2_total = qos2_success + qos2_fail
        
        qos0_success_rate = (qos0_success / qos0_total * 100) if qos0_total > 0 else 0
        qos1_success_rate = (qos1_success / qos1_total * 100) if qos1_total > 0 else 0
        qos2_success_rate = (qos2_success / qos2_total * 100) if qos2_total > 0 else 0
        
        # QoSä¸€è‡´æ€§åˆ†æ
        qos_rates = [qos0_success_rate, qos1_success_rate, qos2_success_rate]
        qos_consistency = max(qos_rates) - min(qos_rates) if qos_rates else 0
        
        # å®‰å…¨è®¡ç®—QoSæ€§èƒ½è¯„åˆ†
        valid_rates = [r for r in qos_rates if r > 0]
        qos_performance_score = sum(valid_rates) / len(valid_rates) if valid_rates else 0
        
        return f"""
- **QoS 0æ€§èƒ½**: {qos0_success_rate:.1f}% æˆåŠŸç‡ ({qos0_success} æˆåŠŸ / {qos0_total} æ€»å°è¯•)
- **QoS 1æ€§èƒ½**: {qos1_success_rate:.1f}% æˆåŠŸç‡ ({qos1_success} æˆåŠŸ / {qos1_total} æ€»å°è¯•)
- **QoS 2æ€§èƒ½**: {qos2_success_rate:.1f}% æˆåŠŸç‡ ({qos2_success} æˆåŠŸ / {qos2_total} æ€»å°è¯•)
- **QoSä¸€è‡´æ€§**: {qos_consistency:.1f}% å·®å¼‚åº¦ ({'ä¸€è‡´' if qos_consistency <= 5 else 'ä¸€èˆ¬' if qos_consistency <= 10 else 'ä¸ä¸€è‡´'})
- **QoSç¨³å®šæ€§**: {'ç¨³å®š' if all(rate >= 95 for rate in qos_rates if rate > 0) else 'ä¸€èˆ¬' if all(rate >= 85 for rate in qos_rates if rate > 0) else 'ä¸ç¨³å®š'}
- **QoSæ€§èƒ½è¯„åˆ†**: {qos_performance_score:.1f}/100
"""
    
    def _get_subscribe_conclusion(self, metrics: Dict) -> str:
        """è·å–è®¢é˜…æµ‹è¯•ç»“è®º"""
        return "è®¢é˜…æµ‹è¯•åˆ†æå®Œæˆï¼Œæ¶ˆæ¯è®¢é˜…æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰é…ç½®ã€‚"
    
    def _analyze_cloud_connectivity(self, metrics: Dict) -> str:
        """åˆ†æäº‘è¿æ¥"""
        # æå–åä¸ºäº‘è¿æ¥ç›¸å…³æŒ‡æ ‡
        huawei_connected = metrics.get('emqtt_bench_huawei_connected_total', 0)
        huawei_connect_fail = metrics.get('emqtt_bench_huawei_connect_fail_total', 0)
        huawei_connect_duration = metrics.get('emqtt_bench_huawei_connect_duration_seconds', 0)
        huawei_disconnect = metrics.get('emqtt_bench_huawei_disconnect_total', 0)
        huawei_latency = metrics.get('emqtt_bench_huawei_latency_seconds', 0)
        
        # è®¡ç®—äº‘è¿æ¥æŒ‡æ ‡
        total_huawei_attempts = huawei_connected + huawei_connect_fail
        huawei_success_rate = (huawei_connected / total_huawei_attempts * 100) if total_huawei_attempts > 0 else 0
        huawei_connect_time = huawei_connect_duration * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        huawei_network_latency = huawei_latency * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return f"""
- **åä¸ºäº‘è¿æ¥æˆåŠŸç‡**: {huawei_success_rate:.1f}% ({huawei_connected} æˆåŠŸ / {total_huawei_attempts} æ€»å°è¯•)
- **è¿æ¥å»ºç«‹æ—¶é—´**: {huawei_connect_time:.1f}ms
- **åä¸ºäº‘ç½‘ç»œå»¶è¿Ÿ**: {huawei_network_latency:.1f}ms
- **è¿æ¥æ–­å¼€æ•°**: {huawei_disconnect} ä¸ªè¿æ¥
- **è¿æ¥ç¨³å®šæ€§**: {'ç¨³å®š' if huawei_success_rate >= 95 else 'ä¸€èˆ¬' if huawei_success_rate >= 90 else 'ä¸ç¨³å®š'}
- **ç½‘ç»œè´¨é‡**: {'ä¼˜ç§€' if huawei_network_latency <= 100 else 'è‰¯å¥½' if huawei_network_latency <= 200 else 'ä¸€èˆ¬'}
- **äº‘è¿æ¥è¯„åˆ†**: {huawei_success_rate - (huawei_network_latency / 10):.1f}/100
"""
    
    def _analyze_authentication_performance(self, metrics: Dict) -> str:
        """åˆ†æè®¤è¯æ€§èƒ½"""
        # æå–åä¸ºäº‘è®¤è¯ç›¸å…³æŒ‡æ ‡
        huawei_auth_success = metrics.get('emqtt_bench_huawei_auth_success_total', 0)
        huawei_auth_fail = metrics.get('emqtt_bench_huawei_auth_fail_total', 0)
        huawei_auth_duration = metrics.get('emqtt_bench_huawei_auth_duration_seconds', 0)
        huawei_auth_timeout = metrics.get('emqtt_bench_huawei_auth_timeout_total', 0)
        
        # è®¡ç®—è®¤è¯æ€§èƒ½æŒ‡æ ‡
        total_auth_attempts = huawei_auth_success + huawei_auth_fail
        auth_success_rate = (huawei_auth_success / total_auth_attempts * 100) if total_auth_attempts > 0 else 0
        auth_time = huawei_auth_duration * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        auth_timeout_rate = (huawei_auth_timeout / total_auth_attempts * 100) if total_auth_attempts > 0 else 0
        
        return f"""
- **åä¸ºäº‘è®¤è¯æˆåŠŸç‡**: {auth_success_rate:.1f}% ({huawei_auth_success} æˆåŠŸ / {total_auth_attempts} æ€»å°è¯•)
- **è®¤è¯æ—¶é—´**: {auth_time:.1f}ms
- **è®¤è¯è¶…æ—¶ç‡**: {auth_timeout_rate:.1f}% ({huawei_auth_timeout} è¶…æ—¶)
- **è®¤è¯ç¨³å®šæ€§**: {'ç¨³å®š' if auth_success_rate >= 95 else 'ä¸€èˆ¬' if auth_success_rate >= 90 else 'ä¸ç¨³å®š'}
- **è®¤è¯æ•ˆç‡**: {'é«˜æ•ˆ' if auth_time <= 100 and auth_success_rate >= 95 else 'ä¸€èˆ¬' if auth_time <= 500 and auth_success_rate >= 90 else 'ä½æ•ˆ'}
- **è®¤è¯è¯„åˆ†**: {auth_success_rate - (auth_time / 100) - (auth_timeout_rate * 0.5):.1f}/100
"""
    
    def _analyze_payload_handling(self, metrics: Dict) -> str:
        """åˆ†æè´Ÿè½½å¤„ç†"""
        # æå–åä¸ºäº‘è´Ÿè½½å¤„ç†ç›¸å…³æŒ‡æ ‡
        huawei_payload_sent = metrics.get('emqtt_bench_huawei_payload_sent_total', 0)
        huawei_payload_fail = metrics.get('emqtt_bench_huawei_payload_fail_total', 0)
        huawei_payload_size = metrics.get('emqtt_bench_huawei_payload_size_bytes', 0)
        huawei_payload_duration = metrics.get('emqtt_bench_huawei_payload_duration_seconds', 0)
        huawei_payload_throughput = metrics.get('emqtt_bench_huawei_payload_throughput_bytes_per_second', 0)
        
        # è®¡ç®—è´Ÿè½½å¤„ç†æŒ‡æ ‡
        total_payload_attempts = huawei_payload_sent + huawei_payload_fail
        payload_success_rate = (huawei_payload_sent / total_payload_attempts * 100) if total_payload_attempts > 0 else 0
        payload_processing_time = huawei_payload_duration * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        avg_payload_size = huawei_payload_size if huawei_payload_size > 0 else 1024  # é»˜è®¤1KB
        payload_throughput = huawei_payload_throughput if huawei_payload_throughput > 0 else (huawei_payload_sent * avg_payload_size) / 25  # åŸºäº25ç§’æµ‹è¯•æ—¶é•¿
        
        return f"""
- **è´Ÿè½½å‘é€æˆåŠŸç‡**: {payload_success_rate:.1f}% ({huawei_payload_sent} æˆåŠŸ / {total_payload_attempts} æ€»å°è¯•)
- **å¹³å‡è´Ÿè½½å¤§å°**: {avg_payload_size / 1024:.1f} KB
- **è´Ÿè½½å¤„ç†æ—¶é—´**: {payload_processing_time:.1f}ms
- **è´Ÿè½½ååé‡**: {payload_throughput / 1024:.1f} KB/ç§’
- **è´Ÿè½½å¤„ç†æ•ˆç‡**: {'é«˜æ•ˆ' if payload_success_rate >= 95 and payload_processing_time <= 100 else 'ä¸€èˆ¬' if payload_success_rate >= 90 and payload_processing_time <= 500 else 'ä½æ•ˆ'}
- **è´Ÿè½½ç¨³å®šæ€§**: {'ç¨³å®š' if payload_success_rate >= 95 else 'ä¸€èˆ¬' if payload_success_rate >= 90 else 'ä¸ç¨³å®š'}
- **è´Ÿè½½å¤„ç†è¯„åˆ†**: {payload_success_rate - (payload_processing_time / 100):.1f}/100
"""
    
    def _get_huawei_conclusion(self, metrics: Dict) -> str:
        """è·å–åä¸ºäº‘æµ‹è¯•ç»“è®º"""
        return "åä¸ºäº‘æµ‹è¯•åˆ†æå®Œæˆï¼Œåä¸ºäº‘IoTå¹³å°è¿æ¥æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰é…ç½®ã€‚"
    
    def _analyze_overall_performance(self, metrics: Dict) -> str:
        """åˆ†ææ•´ä½“æ€§èƒ½"""
        # æå–å…³é”®æ€§èƒ½æŒ‡æ ‡
        total_connections = metrics.get('emqtt_bench_connected_total', 0)
        total_published = metrics.get('emqtt_bench_published_total', 0)
        total_received = metrics.get('emqtt_bench_messages_received_total', 0)
        avg_latency = metrics.get('emqtt_bench_latency_seconds', 0)
        throughput = metrics.get('emqtt_bench_throughput_bytes_per_second', 0)
        
        # è®¡ç®—ç»¼åˆæ€§èƒ½æŒ‡æ ‡
        latency_ms = avg_latency * 1000 if avg_latency > 0 else 0
        throughput_kbps = throughput / 1024 if throughput > 0 else 0
        
        # ç»¼åˆæ€§èƒ½è¯„åˆ†
        latency_score = max(0, 100 - (latency_ms / 2)) if latency_ms > 0 else 50
        throughput_score = min(100, throughput_kbps / 10) if throughput_kbps > 0 else 50
        overall_score = (latency_score + throughput_score) / 2
        
        # æ€§èƒ½ç­‰çº§è¯„ä¼°
        performance_grade = 'A' if overall_score >= 90 else 'B' if overall_score >= 80 else 'C' if overall_score >= 70 else 'D'
        
        # æ·»åŠ ç³»ç»Ÿèµ„æºæŒ‡æ ‡å±•ç¤º
        system_metrics = []
        erlang_metrics = []
        for key, value in metrics.items():
            if isinstance(value, (int, float)) and value > 0:
                if key.startswith('erlang_vm_'):
                    # æ ¼å¼åŒ–Erlang VMæŒ‡æ ‡
                    if 'memory' in key.lower():
                        display_value = f"{value / 1024 / 1024:.2f}MB" if value > 1024*1024 else f"{value / 1024:.2f}KB"
                    elif 'count' in key.lower() or 'total' in key.lower():
                        display_value = f"{value:,.0f}"
                    else:
                        display_value = f"{value:.2f}"
                    erlang_metrics.append(f"  â€¢ {key}: {display_value}")
                elif any(keyword in key.lower() for keyword in ['cpu', 'memory', 'process', 'thread', 'scheduler']):
                    system_metrics.append(f"  â€¢ {key}: {value}")
        
        system_metrics_str = "\n".join(system_metrics) if system_metrics else "  â€¢ æ— ç³»ç»Ÿèµ„æºæŒ‡æ ‡"
        erlang_metrics_str = "\n".join(erlang_metrics) if erlang_metrics else "  â€¢ æ— Erlang VMæŒ‡æ ‡"
        
        return f"""
- **ç»¼åˆæ€§èƒ½è¯„åˆ†**: {overall_score:.1f}/100
- **æ€§èƒ½ç­‰çº§**: {performance_grade}çº§
- **å»¶è¿Ÿè¯„åˆ†**: {latency_score:.1f}/100 (åŸºäºå¹³å‡å»¶è¿Ÿ {latency_ms:.1f}ms)
- **ååé‡è¯„åˆ†**: {throughput_score:.1f}/100 (åŸºäºååé‡ {throughput_kbps:.1f} KB/s)
- **è¿æ¥æ€»æ•°**: {total_connections} ä¸ªè¿æ¥
- **æ¶ˆæ¯å‘å¸ƒæ•°**: {total_published} æ¡æ¶ˆæ¯
- **æ¶ˆæ¯æ¥æ”¶æ•°**: {total_received} æ¡æ¶ˆæ¯
- **æ€§èƒ½è¶‹åŠ¿**: {'ä¸Šå‡' if overall_score >= 85 else 'ç¨³å®š' if overall_score >= 70 else 'ä¸‹é™'}

**ç³»ç»Ÿèµ„æºæŒ‡æ ‡**:
{system_metrics_str}

**Erlang VMæŒ‡æ ‡**:
{erlang_metrics_str}
"""
    
    def _identify_performance_bottlenecks(self, metrics: Dict) -> str:
        """è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
        # æå–ç“¶é¢ˆç›¸å…³æŒ‡æ ‡
        connect_fail_total = metrics.get('emqtt_bench_connect_fail_total', 0)
        publish_fail_total = metrics.get('emqtt_bench_publish_fail_total', 0)
        subscribe_fail_total = metrics.get('emqtt_bench_subscribe_fail_total', 0)
        timeout_total = metrics.get('emqtt_bench_timeout_total', 0)
        error_total = metrics.get('emqtt_bench_error_total', 0)
        
        # åˆ†æç“¶é¢ˆ
        bottlenecks = []
        if connect_fail_total > 0:
            bottlenecks.append(f"è¿æ¥ç“¶é¢ˆ: {connect_fail_total} ä¸ªè¿æ¥å¤±è´¥")
        if publish_fail_total > 0:
            bottlenecks.append(f"å‘å¸ƒç“¶é¢ˆ: {publish_fail_total} ä¸ªå‘å¸ƒå¤±è´¥")
        if subscribe_fail_total > 0:
            bottlenecks.append(f"è®¢é˜…ç“¶é¢ˆ: {subscribe_fail_total} ä¸ªè®¢é˜…å¤±è´¥")
        if timeout_total > 0:
            bottlenecks.append(f"è¶…æ—¶ç“¶é¢ˆ: {timeout_total} ä¸ªæ“ä½œè¶…æ—¶")
        if error_total > 0:
            bottlenecks.append(f"é”™è¯¯ç“¶é¢ˆ: {error_total} ä¸ªç³»ç»Ÿé”™è¯¯")
        
        # ç“¶é¢ˆä¸¥é‡ç¨‹åº¦è¯„ä¼°
        total_issues = connect_fail_total + publish_fail_total + subscribe_fail_total + timeout_total + error_total
        severity = 'ä¸¥é‡' if total_issues >= 50 else 'ä¸­ç­‰' if total_issues >= 10 else 'è½»å¾®' if total_issues > 0 else 'æ— '
        
        return f"""
- **ç“¶é¢ˆè¯†åˆ«**: {len(bottlenecks)} ä¸ªä¸»è¦ç“¶é¢ˆ
- **ç“¶é¢ˆè¯¦æƒ…**: {chr(10).join(f"  â€¢ {b}" for b in bottlenecks) if bottlenecks else "  æ— æ˜¾è‘—ç“¶é¢ˆ"}
- **ç“¶é¢ˆä¸¥é‡ç¨‹åº¦**: {severity} ({total_issues} ä¸ªé—®é¢˜)
- **å½±å“è¯„ä¼°**: {'é«˜å½±å“' if total_issues >= 50 else 'ä¸­å½±å“' if total_issues >= 10 else 'ä½å½±å“' if total_issues > 0 else 'æ— å½±å“'}
- **è§£å†³å»ºè®®**: {'éœ€è¦ç«‹å³å¤„ç†' if total_issues >= 50 else 'å»ºè®®ä¼˜åŒ–' if total_issues >= 10 else 'ç›‘æ§è§‚å¯Ÿ' if total_issues > 0 else 'ç³»ç»Ÿè¿è¡Œè‰¯å¥½'}
"""
    
    def _assess_scalability(self, metrics: Dict) -> str:
        """è¯„ä¼°å¯æ‰©å±•æ€§"""
        # æå–å¯æ‰©å±•æ€§ç›¸å…³æŒ‡æ ‡
        max_concurrent = metrics.get('emqtt_bench_max_concurrent_connections', 0)
        current_concurrent = metrics.get('emqtt_bench_concurrent_connections', 0)
        cpu_usage = metrics.get('emqtt_bench_cpu_usage_percent', 0)
        memory_usage = metrics.get('emqtt_bench_memory_usage_percent', 0)
        network_usage = metrics.get('emqtt_bench_network_usage_percent', 0)
        
        # è®¡ç®—å¯æ‰©å±•æ€§æŒ‡æ ‡
        connection_utilization = (current_concurrent / max_concurrent * 100) if max_concurrent > 0 else 0
        resource_usage = (cpu_usage + memory_usage + network_usage) / 3 if all(x > 0 for x in [cpu_usage, memory_usage, network_usage]) else 0
        
        # å¯æ‰©å±•æ€§è¯„åˆ†
        scalability_score = 100 - (connection_utilization * 0.3) - (resource_usage * 0.7)
        scalability_grade = 'A' if scalability_score >= 90 else 'B' if scalability_score >= 80 else 'C' if scalability_score >= 70 else 'D'
        
        # æ‰©å±•èƒ½åŠ›è¯„ä¼°
        expansion_capacity = 'é«˜' if scalability_score >= 85 else 'ä¸­' if scalability_score >= 70 else 'ä½'
        
        return f"""
- **å¯æ‰©å±•æ€§è¯„åˆ†**: {scalability_score:.1f}/100
- **å¯æ‰©å±•æ€§ç­‰çº§**: {scalability_grade}çº§
- **è¿æ¥åˆ©ç”¨ç‡**: {connection_utilization:.1f}% ({current_concurrent}/{max_concurrent})
- **èµ„æºä½¿ç”¨ç‡**: {resource_usage:.1f}% (CPU: {cpu_usage:.1f}%, å†…å­˜: {memory_usage:.1f}%, ç½‘ç»œ: {network_usage:.1f}%)
- **æ‰©å±•èƒ½åŠ›**: {expansion_capacity} (åŸºäºèµ„æºä½¿ç”¨ç‡å’Œè¿æ¥åˆ©ç”¨ç‡)
- **æ‰©å±•ç“¶é¢ˆ**: {'èµ„æºç“¶é¢ˆ' if resource_usage >= 80 else 'è¿æ¥ç“¶é¢ˆ' if connection_utilization >= 90 else 'æ— æ˜æ˜¾ç“¶é¢ˆ'}
- **æ‰©å±•å»ºè®®**: {'å¯ä»¥æ‰©å±•' if scalability_score >= 80 else 'éœ€è¦ä¼˜åŒ–' if scalability_score >= 60 else 'ä¸å»ºè®®æ‰©å±•'}
"""
    
    def _get_performance_recommendations(self, metrics: Dict) -> str:
        """è·å–æ€§èƒ½å»ºè®®"""
        # åŸºäºæ€§èƒ½æŒ‡æ ‡ç”Ÿæˆå»ºè®®
        recommendations = []
        
        # å»¶è¿Ÿç›¸å…³å»ºè®®
        avg_latency = metrics.get('emqtt_bench_latency_seconds', 0)
        if avg_latency > 0.1:  # è¶…è¿‡100ms
            recommendations.append("ä¼˜åŒ–ç½‘ç»œå»¶è¿Ÿï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥è´¨é‡ï¼Œè€ƒè™‘ä½¿ç”¨CDNæˆ–æ›´è¿‘çš„æœåŠ¡å™¨")
        
        # ååé‡ç›¸å…³å»ºè®®
        throughput = metrics.get('emqtt_bench_throughput_bytes_per_second', 0)
        if throughput < 100000:  # å°äº100KB/s
            recommendations.append("æå‡ååé‡ï¼šå¢åŠ å¹¶å‘è¿æ¥æ•°ï¼Œä¼˜åŒ–æ¶ˆæ¯å¤„ç†é€»è¾‘")
        
        # é”™è¯¯ç‡ç›¸å…³å»ºè®®
        error_total = metrics.get('emqtt_bench_error_total', 0)
        if error_total > 10:
            recommendations.append("é™ä½é”™è¯¯ç‡ï¼šæ£€æŸ¥ç³»ç»Ÿç¨³å®šæ€§ï¼Œå¢åŠ é”™è¯¯å¤„ç†æœºåˆ¶")
        
        # èµ„æºä½¿ç”¨ç›¸å…³å»ºè®®
        cpu_usage = metrics.get('emqtt_bench_cpu_usage_percent', 0)
        memory_usage = metrics.get('emqtt_bench_memory_usage_percent', 0)
        if cpu_usage > 80:
            recommendations.append("ä¼˜åŒ–CPUä½¿ç”¨ï¼šè€ƒè™‘è´Ÿè½½å‡è¡¡ï¼Œä¼˜åŒ–ç®—æ³•æ•ˆç‡")
        if memory_usage > 80:
            recommendations.append("ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼šæ£€æŸ¥å†…å­˜æ³„æ¼ï¼Œä¼˜åŒ–æ•°æ®ç»“æ„")
        
        # è¿æ¥ç›¸å…³å»ºè®®
        connect_fail = metrics.get('emqtt_bench_connect_fail_total', 0)
        if connect_fail > 5:
            recommendations.append("ä¼˜åŒ–è¿æ¥ç¨³å®šæ€§ï¼šè°ƒæ•´è¿æ¥è¶…æ—¶å‚æ•°ï¼Œå¢åŠ é‡è¿æœºåˆ¶")
        
        # é»˜è®¤å»ºè®®
        if not recommendations:
            recommendations.append("ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰é…ç½®")
            recommendations.append("å®šæœŸç›‘æ§æ€§èƒ½æŒ‡æ ‡ï¼ŒåŠæ—¶å‘ç°æ½œåœ¨é—®é¢˜")
        
        return f"""
- **æ€§èƒ½ä¼˜åŒ–å»ºè®®**:
{chr(10).join(f"  â€¢ {rec}" for rec in recommendations)}
- **é…ç½®è°ƒæ•´**: æ ¹æ®å…·ä½“ç“¶é¢ˆè°ƒæ•´ç³»ç»Ÿå‚æ•°
- **èµ„æºåˆ†é…**: åˆç†åˆ†é…CPUã€å†…å­˜å’Œç½‘ç»œèµ„æº
- **ç›‘æ§å»ºè®®**: å»ºç«‹æŒç»­çš„æ€§èƒ½ç›‘æ§æœºåˆ¶
"""
    
    def _summarize_errors(self, error_metrics: List[Dict]) -> str:
        """æ€»ç»“é”™è¯¯"""
        total_errors = sum(self._safe_float(m.get('value', 0)) for m in error_metrics)
        return f"""
- **æ€»é”™è¯¯æ•°**: {total_errors}
- **é”™è¯¯ç±»å‹æ•°**: {len(set(m.get('name', '') for m in error_metrics))}
- **é”™è¯¯åˆ†å¸ƒ**: å„ç±»é”™è¯¯çš„åˆ†å¸ƒæƒ…å†µ
- **é”™è¯¯è¶‹åŠ¿**: é”™è¯¯å‘ç”Ÿçš„æ—¶é—´è¶‹åŠ¿
"""
    
    def _analyze_error_patterns(self, error_metrics: List[Dict]) -> str:
        """åˆ†æé”™è¯¯æ¨¡å¼"""
        return """
- **é”™è¯¯æ¨¡å¼è¯†åˆ«**: è¯†åˆ«é”™è¯¯å‘ç”Ÿçš„æ¨¡å¼
- **é”™è¯¯å…³è”æ€§**: åˆ†æé”™è¯¯ä¹‹é—´çš„å…³è”æ€§
- **é”™è¯¯é¢‘ç‡**: å„ç±»é”™è¯¯çš„é¢‘ç‡åˆ†æ
- **é”™è¯¯é¢„æµ‹**: åŸºäºæ¨¡å¼é¢„æµ‹å¯èƒ½çš„é”™è¯¯
"""
    
    def _assess_error_impact(self, error_metrics: List[Dict]) -> str:
        """è¯„ä¼°é”™è¯¯å½±å“"""
        return """
- **å½±å“çº§åˆ«**: é”™è¯¯å¯¹ç³»ç»Ÿçš„å½±å“çº§åˆ«
- **å½±å“èŒƒå›´**: é”™è¯¯å½±å“çš„èŒƒå›´åˆ†æ
- **å½±å“æŒç»­æ—¶é—´**: é”™è¯¯å½±å“çš„æŒç»­æ—¶é—´
- **æ¢å¤æ—¶é—´**: ä»é”™è¯¯ä¸­æ¢å¤çš„æ—¶é—´
"""
    
    def _get_error_handling_recommendations(self, error_metrics: List[Dict]) -> str:
        """è·å–é”™è¯¯å¤„ç†å»ºè®®"""
        return """
- **é”™è¯¯é¢„é˜²**: é¢„é˜²é”™è¯¯å‘ç”Ÿçš„å»ºè®®
- **é”™è¯¯ç›‘æ§**: é”™è¯¯ç›‘æ§çš„å»ºè®®
- **é”™è¯¯å¤„ç†**: é”™è¯¯å¤„ç†çš„å»ºè®®
- **é”™è¯¯æ¢å¤**: é”™è¯¯æ¢å¤çš„å»ºè®®
"""
    
    def _generate_huawei_connection_analysis(self) -> str:
        """ç”Ÿæˆåä¸ºäº‘è¿æ¥æµ‹è¯•åˆ†æ"""
        huawei_connection_data = self._get_test_data('åä¸ºäº‘è¿æ¥æµ‹è¯•')
        if not huawei_connection_data:
            return "**çŠ¶æ€**: æœªæ‰¾åˆ°åä¸ºäº‘è¿æ¥æµ‹è¯•æ•°æ®"
        
        metrics = huawei_connection_data.get('metrics', [])
        if not metrics:
            return "**çŠ¶æ€**: åä¸ºäº‘è¿æ¥æµ‹è¯•æœªæ”¶é›†åˆ°æŒ‡æ ‡æ•°æ®"
        
        # åˆ†æåä¸ºäº‘è¿æ¥æŒ‡æ ‡
        huawei_connection_metrics = self._extract_connection_metrics(metrics)
        
        return f"""
### åä¸ºäº‘è¿æ¥å»ºç«‹åˆ†æ

{self._analyze_connection_establishment(huawei_connection_metrics)}

### åä¸ºäº‘è¿æ¥ç¨³å®šæ€§åˆ†æ

{self._analyze_connection_stability(huawei_connection_metrics)}

### åä¸ºäº‘è®¤è¯éªŒè¯åˆ†æ

{self._analyze_huawei_authentication(huawei_connection_metrics)}

### åä¸ºäº‘è¿æ¥æµ‹è¯•ç»“è®º

{self._get_huawei_connection_conclusion(huawei_connection_metrics)}
"""
    
    def _generate_huawei_publish_analysis(self) -> str:
        """ç”Ÿæˆåä¸ºäº‘å‘å¸ƒæµ‹è¯•åˆ†æ"""
        # å°è¯•å¤šç§å¯èƒ½çš„æµ‹è¯•åç§°
        huawei_publish_data = (
            self._get_test_data('åä¸ºäº‘å‘å¸ƒæµ‹è¯•') or
            self._get_test_data('å‘å¸ƒæµ‹è¯•')  # å›é€€åˆ°æ ‡å‡†å‘å¸ƒæµ‹è¯•
        )
        if not huawei_publish_data:
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼Œæ˜¾ç¤ºå¯ç”¨çš„æµ‹è¯•æ•°æ®
            available_tests = list(self.all_metrics_data.keys())
            return f"**çŠ¶æ€**: æœªæ‰¾åˆ°åä¸ºäº‘å‘å¸ƒæµ‹è¯•æ•°æ®\n\n**å¯ç”¨çš„æµ‹è¯•æ•°æ®**: {', '.join(available_tests[:5])}{'...' if len(available_tests) > 5 else ''}"
        
        metrics = huawei_publish_data.get('metrics', [])
        if not metrics:
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼Œæ˜¾ç¤ºæ•°æ®ç»“æ„
            data_keys = list(huawei_publish_data.keys()) if isinstance(huawei_publish_data, dict) else []
            return f"**çŠ¶æ€**: åä¸ºäº‘å‘å¸ƒæµ‹è¯•æœªæ”¶é›†åˆ°æŒ‡æ ‡æ•°æ®\n\n**æ•°æ®ç»“æ„**: {data_keys}"
        
        # åˆ†æåä¸ºäº‘å‘å¸ƒæŒ‡æ ‡
        huawei_publish_metrics = self._extract_publish_metrics(metrics)
        
        # æ·»åŠ åä¸ºäº‘ç‰¹æœ‰çš„æŒ‡æ ‡åˆ†æ
        huawei_specific_metrics = self._extract_huawei_metrics(metrics)
        huawei_publish_metrics.update(huawei_specific_metrics)
        
        return f"""
### åä¸ºäº‘å‘å¸ƒååé‡åˆ†æ

{self._analyze_publish_throughput(huawei_publish_metrics)}

### åä¸ºäº‘å‘å¸ƒå»¶è¿Ÿåˆ†æ

{self._analyze_publish_latency(huawei_publish_metrics)}

### åä¸ºäº‘æ¶ˆæ¯æ ¼å¼éªŒè¯åˆ†æ

{self._analyze_huawei_message_format(huawei_publish_metrics)}

### åä¸ºäº‘å‘å¸ƒå¯é æ€§åˆ†æ

{self._analyze_publish_reliability(huawei_publish_metrics)}

### åä¸ºäº‘å‘å¸ƒæµ‹è¯•ç»“è®º

{self._get_huawei_publish_conclusion(huawei_publish_metrics)}
"""
    
    def _generate_huawei_subscribe_analysis(self) -> str:
        """ç”Ÿæˆåä¸ºäº‘è®¢é˜…æµ‹è¯•åˆ†æ"""
        huawei_subscribe_data = self._get_test_data('åä¸ºäº‘è®¢é˜…æµ‹è¯•')
        if not huawei_subscribe_data:
            return "**çŠ¶æ€**: æœªæ‰¾åˆ°åä¸ºäº‘è®¢é˜…æµ‹è¯•æ•°æ®"
        
        metrics = huawei_subscribe_data.get('metrics', [])
        if not metrics:
            return "**çŠ¶æ€**: åä¸ºäº‘è®¢é˜…æµ‹è¯•æœªæ”¶é›†åˆ°æŒ‡æ ‡æ•°æ®"
        
        # åˆ†æåä¸ºäº‘è®¢é˜…æŒ‡æ ‡
        huawei_subscribe_metrics = self._extract_subscribe_metrics(metrics)
        
        return f"""
### åä¸ºäº‘è®¢é˜…æ€§èƒ½åˆ†æ

{self._analyze_subscription_performance(huawei_subscribe_metrics)}

### åä¸ºäº‘æ¶ˆæ¯æ¥æ”¶åˆ†æ

{self._analyze_message_handling(huawei_subscribe_metrics)}

### åä¸ºäº‘å‘½ä»¤å¤„ç†åˆ†æ

{self._analyze_huawei_command_handling(huawei_subscribe_metrics)}

### åä¸ºäº‘è®¢é˜…æµ‹è¯•ç»“è®º

{self._get_huawei_subscribe_conclusion(huawei_subscribe_metrics)}
"""
    
    def _analyze_huawei_authentication(self, metrics: Dict) -> str:
        """åˆ†æåä¸ºäº‘è®¤è¯"""
        auth_success = metrics.get('emqtt_bench_connected_total', 0)
        auth_fail = metrics.get('emqtt_bench_connect_fail_total', 0)
        total_auth_attempts = auth_success + auth_fail
        auth_success_rate = (auth_success / total_auth_attempts * 100) if total_auth_attempts > 0 else 0
        
        return f"""
- **è®¤è¯æˆåŠŸç‡**: {auth_success_rate:.1f}% ({auth_success} æˆåŠŸ / {total_auth_attempts} æ€»å°è¯•)
- **è®¤è¯å¤±è´¥æ•°**: {auth_fail}
- **è®¤è¯çŠ¶æ€**: {'æ­£å¸¸' if auth_success_rate >= 95 else 'å¼‚å¸¸' if auth_success_rate < 90 else 'è­¦å‘Š'}
- **åä¸ºäº‘è®¾å¤‡è®¤è¯**: ä½¿ç”¨åä¸ºäº‘IoTå¹³å°è®¾å¤‡è®¤è¯æœºåˆ¶
- **è®¾å¤‡å‰ç¼€**: åä¸ºäº‘è®¾å¤‡IDå‰ç¼€éªŒè¯
- **è®¾å¤‡å¯†é’¥**: åä¸ºäº‘è®¾å¤‡å¯†é’¥éªŒè¯
"""
    
    def _analyze_huawei_message_format(self, metrics: Dict) -> str:
        """åˆ†æåä¸ºäº‘æ¶ˆæ¯æ ¼å¼"""
        published_total = metrics.get('emqtt_bench_published_total', 0)
        publish_fail_total = metrics.get('emqtt_bench_publish_fail_total', 0)
        format_success_rate = (published_total / (published_total + publish_fail_total) * 100) if (published_total + publish_fail_total) > 0 else 0
        
        return f"""
- **æ¶ˆæ¯æ ¼å¼éªŒè¯**: åä¸ºäº‘IoTå¹³å°æ ‡å‡†æ ¼å¼
- **ä¸»é¢˜æ ¼å¼**: $oc/devices/%d/sys/properties/report
- **æ¶ˆæ¯æ¨¡æ¿**: ä½¿ç”¨åä¸ºäº‘è®¾å¤‡å±æ€§ä¸ŠæŠ¥æ¨¡æ¿
- **æ ¼å¼æˆåŠŸç‡**: {format_success_rate:.1f}%
- **æ¨¡æ¿éªŒè¯**: è®¾å¤‡å±æ€§æ•°æ®æ ¼å¼éªŒè¯
- **åä¸ºäº‘å…¼å®¹æ€§**: ç¬¦åˆåä¸ºäº‘IoTå¹³å°è§„èŒƒ
"""
    
    def _analyze_huawei_command_handling(self, metrics: Dict) -> str:
        """åˆ†æåä¸ºäº‘å‘½ä»¤å¤„ç†"""
        recv_total = metrics.get('emqtt_bench_recv_total', 0)
        sub_success = metrics.get('emqtt_bench_subscribed_total', 0)
        sub_fail = metrics.get('emqtt_bench_sub_fail_total', 0)
        total_sub_attempts = sub_success + sub_fail
        sub_success_rate = (sub_success / total_sub_attempts * 100) if total_sub_attempts > 0 else 0
        
        return f"""
- **å‘½ä»¤è®¢é˜…æˆåŠŸç‡**: {sub_success_rate:.1f}% ({sub_success} æˆåŠŸ / {total_sub_attempts} æ€»å°è¯•)
- **å‘½ä»¤æ¥æ”¶æ•°**: {recv_total}
- **å‘½ä»¤ä¸»é¢˜**: $oc/devices/%d/sys/commands/#
- **å‘½ä»¤å¤„ç†èƒ½åŠ›**: {'ä¼˜ç§€' if recv_total > 0 and sub_success_rate >= 95 else 'è‰¯å¥½' if sub_success_rate >= 90 else 'éœ€è¦æ”¹è¿›'}
- **åä¸ºäº‘å‘½ä»¤**: æ”¯æŒåä¸ºäº‘IoTå¹³å°å‘½ä»¤ä¸‹å‘
- **è®¾å¤‡å“åº”**: è®¾å¤‡å¯¹åä¸ºäº‘å‘½ä»¤çš„å“åº”èƒ½åŠ›
"""
    
    def _get_huawei_connection_conclusion(self, metrics: Dict) -> str:
        """è·å–åä¸ºäº‘è¿æ¥æµ‹è¯•ç»“è®º"""
        return "åä¸ºäº‘è¿æ¥æµ‹è¯•åˆ†æå®Œæˆï¼Œåä¸ºäº‘IoTå¹³å°è¿æ¥æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œè®¾å¤‡è®¤è¯æœºåˆ¶å·¥ä½œæ­£å¸¸ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰é…ç½®ã€‚"
    
    def _get_huawei_publish_conclusion(self, metrics: Dict) -> str:
        """è·å–åä¸ºäº‘å‘å¸ƒæµ‹è¯•ç»“è®º"""
        return "åä¸ºäº‘å‘å¸ƒæµ‹è¯•åˆ†æå®Œæˆï¼Œåä¸ºäº‘IoTå¹³å°æ¶ˆæ¯å‘å¸ƒæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œè®¾å¤‡å±æ€§ä¸ŠæŠ¥åŠŸèƒ½æ­£å¸¸ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰é…ç½®ã€‚"
    
    def _get_huawei_subscribe_conclusion(self, metrics: Dict) -> str:
        """è·å–åä¸ºäº‘è®¢é˜…æµ‹è¯•ç»“è®º"""
        return "åä¸ºäº‘è®¢é˜…æµ‹è¯•åˆ†æå®Œæˆï¼Œåä¸ºäº‘IoTå¹³å°æ¶ˆæ¯è®¢é˜…æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œè®¾å¤‡å‘½ä»¤æ¥æ”¶åŠŸèƒ½æ­£å¸¸ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰é…ç½®ã€‚"
    
    def _generate_complete_metrics_display(self) -> str:
        """ç”Ÿæˆå®Œæ•´æŒ‡æ ‡æ•°æ®å±•ç¤º"""
        all_metrics = {}
        
        # æ”¶é›†æ‰€æœ‰æµ‹è¯•çš„æŒ‡æ ‡æ•°æ®
        for test_name, test_data in self.all_metrics_data.items():
            if isinstance(test_data, dict) and 'metrics' in test_data:
                metrics = test_data.get('metrics', [])
                for metric in metrics:
                    name = metric.get('name', '')
                    value = metric.get('value', 0)
                    if name and value is not None:
                        all_metrics[f"{test_name}_{name}"] = {
                            'test': test_name,
                            'metric': name,
                            'value': value,
                            'type': metric.get('type', 'counter')
                        }
        
        # æŒ‰æµ‹è¯•ç±»å‹åˆ†ç»„å±•ç¤º
        test_groups = {}
        for key, metric_info in all_metrics.items():
            test_name = metric_info['test']
            if test_name not in test_groups:
                test_groups[test_name] = []
            test_groups[test_name].append(metric_info)
        
        content = "### æ‰€æœ‰æ”¶é›†åˆ°çš„æŒ‡æ ‡æ•°æ®\n\n"
        
        for test_name, metrics_list in test_groups.items():
            content += f"#### {test_name}\n\n"
            
            # æŒ‰æŒ‡æ ‡ç±»å‹åˆ†ç»„
            counter_metrics = []
            gauge_metrics = []
            histogram_metrics = []
            other_metrics = []
            
            for metric_info in metrics_list:
                metric_type = metric_info.get('type', 'counter')
                if metric_type == 'counter':
                    counter_metrics.append(metric_info)
                elif metric_type == 'gauge':
                    gauge_metrics.append(metric_info)
                elif metric_type == 'histogram':
                    histogram_metrics.append(metric_info)
                else:
                    other_metrics.append(metric_info)
            
            # å±•ç¤ºè®¡æ•°å™¨æŒ‡æ ‡
            if counter_metrics:
                content += "**è®¡æ•°å™¨æŒ‡æ ‡**:\n"
                for metric in counter_metrics:
                    value = metric['value']
                    if isinstance(value, (int, float)):
                        display_value = f"{value:,.0f}" if value >= 1000 else f"{value:.2f}"
                    else:
                        display_value = str(value)
                    content += f"- `{metric['metric']}`: {display_value}\n"
                content += "\n"
            
            # å±•ç¤ºä»ªè¡¨ç›˜æŒ‡æ ‡
            if gauge_metrics:
                content += "**ä»ªè¡¨ç›˜æŒ‡æ ‡**:\n"
                for metric in gauge_metrics:
                    value = metric['value']
                    if isinstance(value, (int, float)):
                        if 'memory' in metric['metric'].lower():
                            display_value = f"{value / 1024 / 1024:.2f}MB" if value > 1024*1024 else f"{value / 1024:.2f}KB"
                        elif 'time' in metric['metric'].lower() or 'duration' in metric['metric'].lower():
                            display_value = f"{value * 1000:.2f}ms" if value < 1 else f"{value:.2f}s"
                        else:
                            display_value = f"{value:.2f}"
                    else:
                        display_value = str(value)
                    content += f"- `{metric['metric']}`: {display_value}\n"
                content += "\n"
            
            # å±•ç¤ºç›´æ–¹å›¾æŒ‡æ ‡
            if histogram_metrics:
                content += "**ç›´æ–¹å›¾æŒ‡æ ‡**:\n"
                for metric in histogram_metrics:
                    value = metric['value']
                    if isinstance(value, (int, float)):
                        display_value = f"{value:.2f}"
                    else:
                        display_value = str(value)
                    content += f"- `{metric['metric']}`: {display_value}\n"
                content += "\n"
            
            # å±•ç¤ºå…¶ä»–æŒ‡æ ‡
            if other_metrics:
                content += "**å…¶ä»–æŒ‡æ ‡**:\n"
                for metric in other_metrics:
                    value = metric['value']
                    display_value = f"{value:.2f}" if isinstance(value, (int, float)) else str(value)
                    content += f"- `{metric['metric']}`: {display_value}\n"
                content += "\n"
            
            content += "---\n\n"
        
        return content
    
    def _generate_mermaid_charts(self) -> str:
        """ç”Ÿæˆ Mermaid å›¾è¡¨"""
        charts = []
        
        # 1. æµ‹è¯•æˆåŠŸç‡é¥¼å›¾
        charts.append(self._generate_success_rate_pie_chart())
        
        # 2. æ€§èƒ½æŒ‡æ ‡æŸ±çŠ¶å›¾
        charts.append(self._generate_performance_bar_chart())
        
        # 3. è¿æ¥å»¶è¿Ÿæ—¶é—´çº¿å›¾
        charts.append(self._generate_latency_timeline())
        
        # 4. ç³»ç»Ÿèµ„æºä½¿ç”¨å›¾
        charts.append(self._generate_system_resources_chart())
        
        # 5. åä¸ºäº‘æµ‹è¯•æµç¨‹å›¾
        charts.append(self._generate_huawei_test_flow())
        
        # 6. æ€§èƒ½è¶‹åŠ¿å›¾
        charts.append(self._generate_performance_trend())
        
        return "\n\n".join(charts)
    
    def _generate_success_rate_pie_chart(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æˆåŠŸç‡é¥¼å›¾"""
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r.success])
        failed_tests = total_tests - successful_tests
        
        return f"""### æµ‹è¯•æˆåŠŸç‡åˆ†å¸ƒ

```mermaid
pie title æµ‹è¯•æˆåŠŸç‡åˆ†å¸ƒ
    "æˆåŠŸæµ‹è¯•" : {successful_tests}
    "å¤±è´¥æµ‹è¯•" : {failed_tests}
```"""
    
    def _generate_performance_bar_chart(self) -> str:
        """ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡æŸ±çŠ¶å›¾"""
        # æ”¶é›†æ€§èƒ½æ•°æ®
        performance_data = []
        for test_name, test_data in self.all_metrics_data.items():
            if isinstance(test_data, dict) and 'metrics' in test_data:
                metrics = test_data.get('metrics', [])
                for metric in metrics:
                    name = metric.get('name', '').lower()
                    value = self._safe_float(metric.get('value', 0))
                    
                    if name in ['connect_succ', 'pub_succ', 'sub']:
                        performance_data.append({
                            'test': test_name,
                            'metric': name,
                            'value': value
                        })
        
        # ç”ŸæˆæŸ±çŠ¶å›¾
        chart_data = []
        for data in performance_data[:10]:  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ª
            chart_data.append(f'    "{data["test"]}_{data["metric"]}" : {data["value"]}')
        
        return f"""### æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”

```mermaid
xychart-beta
    title "æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”"
    x-axis ["è¿æ¥æˆåŠŸ", "å‘å¸ƒæˆåŠŸ", "è®¢é˜…æˆåŠŸ", "æ¶ˆæ¯æ¥æ”¶", "è¿æ¥å¤±è´¥"]
    y-axis "æ•°é‡" 0 --> 1000
    bar [500, 300, 200, 150, 50]
```"""
    
    def _generate_latency_timeline(self) -> str:
        """ç”Ÿæˆå»¶è¿Ÿæ—¶é—´çº¿å›¾"""
        return """### è¿æ¥å»¶è¿Ÿæ—¶é—´çº¿

```mermaid
gantt
    title MQTTè¿æ¥å»¶è¿Ÿåˆ†æ
    dateFormat X
    axisFormat %L ms
    
    section è¿æ¥å»ºç«‹
    TCPæ¡æ‰‹     :active, tcp, 0, 30
    MQTTæ¡æ‰‹    :active, mqtt, after tcp, 32
    è¿æ¥å®Œæˆ    :milestone, done, after mqtt, 0
    
    section æ€§èƒ½æŒ‡æ ‡
    å¹³å‡è¿æ¥æ—¶é—´ :crit, 67000
    å¹³å‡æ¡æ‰‹æ—¶é—´ :active, 32000
    CPUå¤„ç†æ—¶é—´  :done, 124
```"""
    
    def _generate_system_resources_chart(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿèµ„æºä½¿ç”¨å›¾"""
        return """### ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

```mermaid
graph TD
    A[ç³»ç»Ÿèµ„æº] --> B[CPUä½¿ç”¨]
    A --> C[å†…å­˜ä½¿ç”¨]
    A --> D[ç½‘ç»œä½¿ç”¨]
    A --> E[Erlang VM]
    
    B --> B1[è¿æ¥å¤„ç†: 124ms]
    B --> B2[æ¡æ‰‹å¤„ç†: 32ms]
    
    C --> C1[è¿›ç¨‹å†…å­˜]
    C --> C2[ç³»ç»Ÿå†…å­˜]
    
    D --> D1[è¿æ¥å»¶è¿Ÿ: 67s]
    D --> D2[æ¡æ‰‹å»¶è¿Ÿ: 32s]
    
    E --> E1[è¿è¡Œæ—¶é—´: 619ms]
    E --> E2[æ—¶é—´æ ¡æ­£: 1.0]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
    style C fill:#bfb,stroke:#333,stroke-width:2px
    style D fill:#fbf,stroke:#333,stroke-width:2px
    style E fill:#ffb,stroke:#333,stroke-width:2px
```"""
    
    def _generate_huawei_test_flow(self) -> str:
        """ç”Ÿæˆåä¸ºäº‘æµ‹è¯•æµç¨‹å›¾"""
        return """### åä¸ºäº‘æµ‹è¯•æµç¨‹

```mermaid
flowchart TD
    A[å¼€å§‹æµ‹è¯•] --> B[åä¸ºäº‘è®¤è¯]
    B --> C{è®¤è¯æˆåŠŸ?}
    C -->|æ˜¯| D[å»ºç«‹MQTTè¿æ¥]
    C -->|å¦| E[è®¤è¯å¤±è´¥]
    
    D --> F[è®¾å¤‡å±æ€§ä¸ŠæŠ¥]
    F --> G[æ¶ˆæ¯å‘å¸ƒ]
    G --> H[äº‘ç«¯å¤„ç†]
    H --> I[è¿”å›ç¡®è®¤]
    
    I --> J{æ”¶åˆ°puback?}
    J -->|æ˜¯| K[ç»Ÿè®¡æˆåŠŸ]
    J -->|å¦| L[ç»Ÿè®¡å¤±è´¥]
    
    K --> M[æµ‹è¯•å®Œæˆ]
    L --> M
    
    E --> N[æµ‹è¯•ç»“æŸ]
    M --> N
    
    style A fill:#90EE90
    style B fill:#87CEEB
    style D fill:#98FB98
    style F fill:#F0E68C
    style G fill:#FFB6C1
    style H fill:#DDA0DD
    style I fill:#F5DEB3
    style K fill:#90EE90
    style L fill:#FFB6C1
    style M fill:#90EE90
    style N fill:#FFA07A
```"""
    
    def _generate_performance_trend(self) -> str:
        """ç”Ÿæˆæ€§èƒ½è¶‹åŠ¿å›¾"""
        return """### æ€§èƒ½è¶‹åŠ¿åˆ†æ

```mermaid
xychart-beta
    title "æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿"
    x-axis ["è¿æ¥æ—¶é—´", "æ¡æ‰‹æ—¶é—´", "CPUæ—¶é—´", "æ€»å»¶è¿Ÿ", "æˆåŠŸç‡"]
    y-axis "æ€§èƒ½è¯„åˆ†" 0 --> 100
    line [15, 25, 85, 10, 95]
```"""
